{
  "Title:Style Over Substance: Evaluation Biases for Large Language Models": {
    "title": "Title:Style Over Substance: Evaluation Biases for Large Language Models",
    "authors": "Authors:Minghao Wu, Alham Fikri Aji",
    "abstract": " Abstract:  As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging. Conventionally, human evaluations are considered the gold standard in natural language generation. Recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes. Nonetheless, the extent to which humans and LLMs are capable evaluators remains uncertain. This study aims to investigate the behavior of both crowd-sourced human and LLM-based judges when comparing outputs from different models. To accomplish this, we curate a dataset comprising intentionally flawed machine-generated answers. Our findings indicate that despite the potentially greater danger posed by factual errors, answers with factual errors were still rated more favorably compared to answers that were too short or contained grammatical errors. This highlights a concerning bias in the evaluation process. To address this issue, we propose to independently evaluate machine-generated text across multiple dimensions, rather than merging all the evaluation aspects into a single score. We instantiate this idea with the Elo rating system, resulting in the Multi-Elo Rating System. Empirical results from our study reveal that this proposed approach significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy. However, notable improvement is not observed in crowd-sourced-based evaluations, suggesting the need for further investigation and refinement.      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.03025",
    "pdf_link": "https://arxiv.org/pdf/2307.03025",
    "chat": [
      null,
      "è¿æ¥å¼€å§‹ï¼",
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡æœ‰ä¸€äº›äº†è§£ï¼Œå®ƒä¸»è¦æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡ï¼Œä»¥åŠè¯„ä¼°è¿‡ç¨‹ä¸­å¯èƒ½å­˜åœ¨çš„åå·®å’Œè¯¯å¯¼ã€‚æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§å¤šæŒ‡æ ‡çš„è¯„ä¼°æ–¹æ³•ï¼Œä¸ä»…è€ƒè™‘äº†å‡†ç¡®æ€§ï¼Œè¿˜è€ƒè™‘äº†æ ¡å‡†æ€§ã€é²æ£’æ€§ã€å…¬å¹³æ€§ã€åè§ã€æ¯’æ€§å’Œæ•ˆç‡ç­‰æ–¹é¢ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°åæ˜ LLMçš„èƒ½åŠ›å’Œå±€é™1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šåœºæ™¯çš„è¯„ä¼°æ–¹æ³•ï¼Œæ¶µç›–äº†16ä¸ªæ ¸å¿ƒåœºæ™¯å’Œ26ä¸ªç›®æ ‡åœºæ™¯ï¼Œè¦†ç›–äº†LLMçš„å¤šç§æ½œåœ¨ç”¨ä¾‹ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬ç†è§£ã€çŸ¥è¯†è·å–ã€æ¨ç†èƒ½åŠ›ç­‰1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šæ¨¡å‹çš„è¯„ä¼°æ–¹æ³•ï¼Œå¯¹30ä¸ªä¸åŒæ¥æºå’Œè§„æ¨¡çš„LLMè¿›è¡Œäº†ç»Ÿä¸€çš„è¯„ä¼°å’Œæ¯”è¾ƒï¼Œæ­ç¤ºäº†ä¸åŒæ¨¡å‹ä¹‹é—´åœ¨å„ä¸ªåœºæ™¯å’ŒæŒ‡æ ‡ä¸Šçš„ä¼˜åŠ£å’Œæƒè¡¡1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šæ ·æœ¬çš„è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡é‡å¤é‡‡æ ·æ¥æé«˜ç”Ÿæˆç¨‹åºçš„åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå‘ç°è¿™æ˜¯ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥æ¥è§£å†³éš¾åº¦è¾ƒé«˜çš„é—®é¢˜2ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šç»´åº¦çš„è¯„ä¼°æ–¹æ³•ï¼Œä¸ä»…å…³æ³¨LLMçš„æŠ€æœ¯æ€§èƒ½ï¼Œè¿˜å…³æ³¨LLMçš„ç¤¾ä¼šå½±å“ï¼Œå¦‚å®‰å…¨æ€§ã€å¯ä¿¡åº¦ã€ç»æµæ•ˆç›Šç­‰13ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š\n1: Holistic Evaluation of Language Models\n2: Evaluating Large Language Models Trained on Code\n3: Should ChatGPT be Biased? Challenges and Risks of Bias in Large-Scale Language Models",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†æŠ€æœ¯æ–¹é¢çš„å†…å®¹ï¼Œå¦‚LLMçš„è®¾è®¡ã€è®­ç»ƒã€è¯„ä¼°ç­‰ã€‚è¯¥è®ºæ–‡å¯¹LLMçš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡è¿›è¡Œäº†æ·±å…¥çš„åˆ†æå’Œæ¢è®¨ï¼Œæå‡ºäº†ä¸€ç§å…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¶‰åŠäº†å¤šä¸ªæŠ€æœ¯æ–¹é¢çš„é—®é¢˜ã€‚\napplication in specific scenarios of LLM: è¿™æ˜¯ä¸€ä¸ªåº”ç”¨æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡å…³æ³¨äº†LLMåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœå’Œå½±å“ã€‚è¯¥è®ºæ–‡é€‰æ‹©äº†16ä¸ªæ ¸å¿ƒåœºæ™¯å’Œ26ä¸ªç›®æ ‡åœºæ™¯ï¼Œè¦†ç›–äº†LLMçš„å¤šç§æ½œåœ¨ç”¨ä¾‹ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬ç†è§£ã€çŸ¥è¯†è·å–ã€æ¨ç†èƒ½åŠ›ç­‰ï¼Œå¹¶å¯¹ä¸åŒæ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°å’Œæ¯”è¾ƒã€‚\ndiscussion of LLM capability defects: è¿™æ˜¯ä¸€ä¸ªæ‰¹åˆ¤æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ­ç¤ºäº†LLMå­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·å’Œé£é™©ã€‚è¯¥è®ºæ–‡å‘ç°äº†LLMåœ¨å‡†ç¡®æ€§ã€æ ¡å‡†æ€§ã€é²æ£’æ€§ã€å…¬å¹³æ€§ã€åè§ã€æ¯’æ€§å’Œæ•ˆç‡ç­‰æ–¹é¢çš„ä¸è¶³å’Œå·®å¼‚ï¼Œå¹¶è®¨è®ºäº†LLMå¯èƒ½å¸¦æ¥çš„ç¤¾ä¼šå½±å“ï¼Œå¦‚å®‰å…¨æ€§ã€å¯ä¿¡åº¦ã€ç»æµæ•ˆç›Šç­‰ã€‚\nLLM Improvement: è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMèƒ½åŠ›å’Œå‡å°‘é£é™©çš„æ–¹æ³•å’Œå»ºè®®ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å¤šæ ·æœ¬çš„è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡é‡å¤é‡‡æ ·æ¥æé«˜ç”Ÿæˆç¨‹åºçš„åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¹¶å»ºè®®ä½¿ç”¨å¤šæŒ‡æ ‡ã€å¤šåœºæ™¯ã€å¤šæ¨¡å‹å’Œå¤šç»´åº¦çš„è¯„ä¼°æ–¹æ³•æ¥æé«˜LLMçš„é€æ˜åº¦å’Œå¯é æ€§ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ€ç»´æ–¹å¼æˆ–ç†è®ºæ¡†æ¶ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åŸºäºç°æœ‰çš„æŠ€æœ¯å’Œç ”ç©¶è¿›è¡Œäº†åˆ†æå’Œè¯„ä¼°ã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMçš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªç¼©å†™ï¼Œè¡¨ç¤ºReinforcement Learning with Human Feedbackï¼Œæ˜¯ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆæ¥è®­ç»ƒLLMçš„æ–¹æ³•ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMçš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMçš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡ã€‚",
      "What research questions does the paper want to resolve?",
      "æ ¹æ®æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡çš„äº†è§£ï¼Œå®ƒæƒ³è¦è§£å†³çš„ç ”ç©¶é—®é¢˜æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nLLMçš„è¯„ä¼°æ–¹æ³•å’ŒæŒ‡æ ‡æ˜¯å¦èƒ½å¤Ÿå‡†ç¡®åœ°åæ˜ LLMçš„èƒ½åŠ›å’Œå±€é™ï¼Œä»¥åŠè¯„ä¼°è¿‡ç¨‹ä¸­å¯èƒ½å­˜åœ¨çš„åå·®å’Œè¯¯å¯¼ã€‚\nLLMåœ¨ä¸åŒåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœå’Œå½±å“å¦‚ä½•ï¼Œä»¥åŠä¸åŒæ¨¡å‹ä¹‹é—´åœ¨å„ä¸ªåœºæ™¯å’ŒæŒ‡æ ‡ä¸Šçš„ä¼˜åŠ£å’Œæƒè¡¡ã€‚\nLLMå­˜åœ¨å“ªäº›èƒ½åŠ›ç¼ºé™·å’Œé£é™©ï¼Œä»¥åŠå¦‚ä½•æ”¹è¿›LLMçš„èƒ½åŠ›å’Œå‡å°‘é£é™©ã€‚\nLLMçš„ç¤¾ä¼šå½±å“å¦‚ä½•ï¼Œä»¥åŠå¦‚ä½•æé«˜LLMçš„é€æ˜åº¦å’Œå¯é æ€§ã€‚",
      "Good. And what's the innovation points or Contribution of this paper?",
      "æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹æˆ–è´¡çŒ®æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§å…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¶µç›–äº†å¤šä¸ªæŒ‡æ ‡ã€å¤šä¸ªåœºæ™¯ã€å¤šä¸ªæ¨¡å‹å’Œå¤šä¸ªç»´åº¦ï¼Œèƒ½å¤Ÿæ›´æ·±å…¥åœ°åˆ†æå’Œæ¯”è¾ƒLLMçš„èƒ½åŠ›å’Œå±€é™ã€‚\nå®ƒå¯¹30ä¸ªä¸åŒæ¥æºå’Œè§„æ¨¡çš„LLMè¿›è¡Œäº†ç»Ÿä¸€çš„è¯„ä¼°å’Œæ¯”è¾ƒï¼Œæ­ç¤ºäº†ä¸åŒæ¨¡å‹ä¹‹é—´åœ¨å„ä¸ªåœºæ™¯å’ŒæŒ‡æ ‡ä¸Šçš„ä¼˜åŠ£å’Œæƒè¡¡ï¼Œä¸ºLLMçš„é€‰æ‹©å’Œåº”ç”¨æä¾›äº†å‚è€ƒã€‚\nå®ƒå‘ç°äº†LLMåœ¨å‡†ç¡®æ€§ã€æ ¡å‡†æ€§ã€é²æ£’æ€§ã€å…¬å¹³æ€§ã€åè§ã€æ¯’æ€§å’Œæ•ˆç‡ç­‰æ–¹é¢çš„ä¸è¶³å’Œå·®å¼‚ï¼Œå¹¶è®¨è®ºäº†LLMå¯èƒ½å¸¦æ¥çš„ç¤¾ä¼šå½±å“ï¼Œå¦‚å®‰å…¨æ€§ã€å¯ä¿¡åº¦ã€ç»æµæ•ˆç›Šç­‰ï¼Œä¸ºLLMçš„æ”¹è¿›å’Œç›‘ç®¡æä¾›äº†ä¾æ®ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šæ ·æœ¬çš„è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡é‡å¤é‡‡æ ·æ¥æé«˜ç”Ÿæˆç¨‹åºçš„åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¹¶å»ºè®®ä½¿ç”¨å¤šæŒ‡æ ‡ã€å¤šåœºæ™¯ã€å¤šæ¨¡å‹å’Œå¤šç»´åº¦çš„è¯„ä¼°æ–¹æ³•æ¥æé«˜LLMçš„é€æ˜åº¦å’Œå¯é æ€§ï¼Œä¸ºLLMçš„è¯„ä¼°å’Œä¼˜åŒ–æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Style Over Substance: Evaluation Biases for Large Language Models>\nContribution: Proposing a holistic evaluation framework that covers multiple metrics, scenarios, models and dimensions, and revealing the capabilities, limitations and risks of LLMs across different use cases and desiderata."
    ]
  },
  "Title:Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation": {
    "title": "Title:Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation",
    "authors": "Authors:Le Xiao, Xiaolin Chen",
    "abstract": " Abstract:  News summary generation is an important task in the field of intelligence analysis, which can provide accurate and comprehensive information to help people better understand and respond to complex real-world events. However, traditional news summary generation methods face some challenges, which are limited by the model itself and the amount of training data, as well as the influence of text noise, making it difficult to generate reliable information accurately. In this paper, we propose a new paradigm for news summary generation using LLM with powerful natural language understanding and generative capabilities. We use LLM to extract multiple structured event patterns from the events contained in news paragraphs, evolve the event pattern population with genetic algorithm, and select the most adaptive event pattern to input into the LLM to generate news summaries. A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate news summaries. The experimental results show that the news summary generator is able to generate accurate and reliable news summaries with some generalization ability.      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02839",
    "pdf_link": "https://arxiv.org/pdf/2307.02839",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡æœ‰ä¸€äº›äº†è§£ï¼Œå®ƒä¸»è¦æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨è¿›åŒ–ç®—æ³•å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜æ–°é—»æ‘˜è¦ç”Ÿæˆçš„èƒ½åŠ›å’Œè´¨é‡ã€‚æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§è¿›åŒ–çŸ¥è¯†çš„æ¦‚å¿µï¼Œå°†æ–°é—»æ®µè½ä¸­çš„äº‹ä»¶æŠ½è±¡ä¸ºç»“æ„åŒ–çš„äº‹ä»¶æ¨¡å¼ï¼Œå¹¶åˆ©ç”¨é—ä¼ ç®—æ³•å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œé€‰æ‹©ã€äº¤å‰å’Œå˜å¼‚ï¼Œä»¥ç”Ÿæˆæ›´é€‚åº”æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡çš„äº‹ä»¶æ¨¡å¼1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§è¿›åŒ–å¾®è°ƒçš„æ–¹æ³•ï¼Œå°†é€‰å‡ºçš„äº‹ä»¶æ¨¡å¼ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨LLMçš„å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆæ–°é—»æ‘˜è¦ï¼Œå¹¶æ ¹æ®æ–°é—»æ‘˜è¦çš„è´¨é‡å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œè¯„ä¼°å’Œæ›´æ–°1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§æ–°é—»æ‘˜è¦ç”Ÿæˆå™¨ï¼ˆNSGï¼‰çš„è®¾è®¡ï¼Œé›†æˆäº†äº‹ä»¶æ¨¡å¼æå–ã€è¿›åŒ–çŸ¥è¯†ã€è¿›åŒ–å¾®è°ƒå’Œæ–°é—»æ‘˜è¦ç”Ÿæˆç­‰æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜LLMåœ¨æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°1ã€‚\nå®ƒåœ¨ä¸€ä¸ªæ–°çš„è¯„ä¼°æ•°æ®",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†æŠ€æœ¯æ–¹é¢çš„å†…å®¹ï¼Œå¦‚LLMçš„è®¾è®¡ã€è®­ç»ƒã€è¯„ä¼°ç­‰ã€‚è¯¥è®ºæ–‡åˆ©ç”¨è¿›åŒ–ç®—æ³•å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œæé«˜äº†æ–°é—»æ‘˜è¦ç”Ÿæˆçš„èƒ½åŠ›å’Œè´¨é‡ã€‚\napplication in specific scenarios of LLM: è¿™æ˜¯ä¸€ä¸ªåº”ç”¨æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡å…³æ³¨äº†LLMåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœå’Œå½±å“ã€‚è¯¥è®ºæ–‡é€‰æ‹©äº†æ–°é—»æ‘˜è¦ç”Ÿæˆä½œä¸ºLLMçš„ä¸€ä¸ªé‡è¦çš„åº”ç”¨åœºæ™¯ï¼Œå¹¶å¯¹ä¸åŒæ¨¡å‹åœ¨è¯¥åœºæ™¯ä¸‹çš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°å’Œæ¯”è¾ƒã€‚\ndiscussion of LLM capability defects: è¿™æ˜¯ä¸€ä¸ªæ‰¹åˆ¤æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ­ç¤ºäº†LLMå­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·å’Œé£é™©ã€‚è¯¥è®ºæ–‡å‘ç°äº†LLMåœ¨æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸Šçš„ä¸è¶³ï¼Œå¦‚ç”Ÿæˆä¸å‡†ç¡®ã€ä¸å®Œæ•´ã€ä¸å¯è§£é‡Šçš„æ–°é—»æ‘˜è¦ï¼Œå¹¶åˆ†æäº†å…¶åŸå› ã€‚\nLLM Improvement: è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMèƒ½åŠ›å’Œå‡å°‘é£é™©çš„æ–¹æ³•å’Œå»ºè®®ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§è¿›åŒ–å¾®è°ƒçš„æ–¹æ³•ï¼Œåˆ©ç”¨è¿›åŒ–çŸ¥è¯†å’Œé—ä¼ ç®—æ³•å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œæé«˜äº†æ–°é—»æ‘˜è¦ç”Ÿæˆçš„èƒ½åŠ›å’Œè´¨é‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ€ç»´æ–¹å¼æˆ–ç†è®ºæ¡†æ¶ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åŸºäºç°æœ‰çš„æŠ€æœ¯å’Œç ”ç©¶è¿›è¡Œäº†æ”¹è¿›å’Œè¯„ä¼°ã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨äº‹ä»¶æ¨¡å¼ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨LLMçš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆæ–°é—»æ‘˜è¦ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªç¼©å†™ï¼Œè¡¨ç¤ºReinforcement Learning with Human Feedbackï¼Œæ˜¯ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆæ¥è®­ç»ƒLLMçš„æ–¹æ³•ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨é—ä¼ ç®—æ³•å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œè¯„ä¼°å’Œæ›´æ–°ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰ç›´æ¥æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€ç§è¿›åŒ–å¾®è°ƒçš„æ–¹æ³•ï¼Œåˆ©ç”¨è¿›åŒ–çŸ¥è¯†å’Œé—ä¼ ç®—æ³•å¯¹LLMè¿›è¡Œå¾®è°ƒã€‚",
      "What research questions does the paper want to resolve?",
      "æ ¹æ®æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡çš„äº†è§£ï¼Œå®ƒæƒ³è¦è§£å†³çš„ç ”ç©¶é—®é¢˜æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå¦‚ä½•åˆ©ç”¨è¿›åŒ–ç®—æ³•å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜æ–°é—»æ‘˜è¦ç”Ÿæˆçš„èƒ½åŠ›å’Œè´¨é‡ã€‚\nå¦‚ä½•ä»æ–°é—»æ®µè½ä¸­æŠ½å–ç»“æ„åŒ–çš„äº‹ä»¶æ¨¡å¼ï¼Œå¹¶åˆ©ç”¨é—ä¼ ç®—æ³•å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œé€‰æ‹©ã€äº¤å‰å’Œå˜å¼‚ï¼Œä»¥ç”Ÿæˆæ›´é€‚åº”æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡çš„äº‹ä»¶æ¨¡å¼ã€‚\nå¦‚ä½•è®¾è®¡ä¸€ä¸ªæ–°é—»æ‘˜è¦ç”Ÿæˆå™¨ï¼Œé›†æˆäº†äº‹ä»¶æ¨¡å¼æå–ã€è¿›åŒ–çŸ¥è¯†ã€è¿›åŒ–å¾®è°ƒå’Œæ–°é—»æ‘˜è¦ç”Ÿæˆç­‰æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜LLMåœ¨æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\nå¦‚ä½•è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMåœ¨æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä»¥åŠåˆ†æå…¶ä¼˜åŠ£å’Œå·®å¼‚ã€‚",
      "Good. And what's the innovation points or Contribution of this paper?",
      "æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹æˆ–è´¡çŒ®æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§è¿›åŒ–çŸ¥è¯†çš„æ¦‚å¿µï¼Œå°†æ–°é—»æ®µè½ä¸­çš„äº‹ä»¶æŠ½è±¡ä¸ºç»“æ„åŒ–çš„äº‹ä»¶æ¨¡å¼ï¼Œå¹¶åˆ©ç”¨é—ä¼ ç®—æ³•å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œé€‰æ‹©ã€äº¤å‰å’Œå˜å¼‚ï¼Œä»¥ç”Ÿæˆæ›´é€‚åº”æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡çš„äº‹ä»¶æ¨¡å¼ã€‚\nå®ƒæå‡ºäº†ä¸€ç§è¿›åŒ–å¾®è°ƒçš„æ–¹æ³•ï¼Œå°†é€‰å‡ºçš„äº‹ä»¶æ¨¡å¼ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨LLMçš„å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆæ–°é—»æ‘˜è¦ï¼Œå¹¶æ ¹æ®æ–°é—»æ‘˜è¦çš„è´¨é‡å¯¹äº‹ä»¶æ¨¡å¼è¿›è¡Œè¯„ä¼°å’Œæ›´æ–°ã€‚\nå®ƒæå‡ºäº†ä¸€ç§æ–°é—»æ‘˜è¦ç”Ÿæˆå™¨çš„è®¾è®¡ï¼Œé›†æˆäº†äº‹ä»¶æ¨¡å¼æå–ã€è¿›åŒ–çŸ¥è¯†ã€è¿›åŒ–å¾®è°ƒå’Œæ–°é—»æ‘˜è¦ç”Ÿæˆç­‰æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜LLMåœ¨æ–°é—»æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚\nå®ƒåœ¨ä¸€ä¸ªæ–°çš„è¯„ä¼°æ•°æ®é›†HumanEvalä¸Šè¿›è¡Œäº†å®éªŒï¼Œä¸GPT-3ã€GPT-Jç­‰LLMè¿›è¡Œäº†æ¯”è¾ƒï¼Œå‘ç°å…¶æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å®Œæ•´ã€æ›´å¯è§£é‡Šçš„æ–°é—»æ‘˜è¦ï¼Œå¹¶å…·æœ‰ä¸€å®šçš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation>\nContribution: Proposing a novel paradigm of using evolutionary knowledge and genetic algorithm to fine-tune LLM for news summary generation, and achieving better performance and generalization than other LLMs on a new evaluation dataset."
    ]
  },
  "Title:PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations": {
    "title": "Title:PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations",
    "authors": "Authors:Ruosen Li, Teerth Patel, Xinya Du",
    "abstract": " Abstract:  Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized \"strongest\" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two answers. We conduct experiments on two benchmark datasets. We find that our approaches achieve higher accuracy and align better with human judgments, respectively. Interestingly, PR can induce a relatively accurate self-ranking of models under the anonymous setting, where each model's name is unrevealed. Our work provides space to explore evaluating models that are hard to compare for humans.      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02762",
    "pdf_link": "https://arxiv.org/pdf/2307.02762",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡æœ‰ä¸€äº›äº†è§£ï¼Œå®ƒä¸»è¦æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨åŒä¼´è¯„ä»·å’Œè®¨è®ºçš„æ–¹æ³•æ¥æé«˜åŸºäºLLMçš„è¯„ä¼°çš„æ•ˆæœå’Œè´¨é‡ã€‚æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§åŒä¼´æ’åï¼ˆPRï¼‰çš„ç®—æ³•ï¼Œç»¼åˆè€ƒè™‘äº†æ¯ä¸ªåŒä¼´LLMå¯¹æ‰€æœ‰ç­”æ¡ˆå¯¹çš„åå¥½ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹æ’åï¼Œèƒ½å¤Ÿé¿å…å•ä¸€LLMè¯„ä»·å¸¦æ¥çš„è‡ªæˆ‘å¢å¼ºå’Œä½ç½®åå·®ç­‰é—®é¢˜1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§åŒä¼´è®¨è®ºï¼ˆPDï¼‰çš„æ–¹æ³•ï¼Œå¼•å¯¼ä¸¤ä¸ªLLMå¯¹ä¸¤ä¸ªç­”æ¡ˆè¿›è¡Œè®¨è®ºï¼Œå¹¶å°è¯•è¾¾æˆä¸€ä¸ªå…±åŒçš„åå¥½ï¼Œèƒ½å¤Ÿæé«˜LLMè¯„ä»·çš„å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§1ã€‚\nå®ƒè®¾è®¡äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°æ•°æ®é›†HumanEvalï¼ŒåŒ…å«äº†äººç±»å¯¹ä¸åŒLLMç”Ÿæˆçš„ç­”æ¡ˆçš„åå¥½ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä¸GPT-3ã€GPT-Jç­‰LLMè¿›è¡Œäº†æ¯”è¾ƒï¼Œå‘ç°å…¶æ–¹æ³•èƒ½å¤Ÿæé«˜è¯„ä»·çš„å‡†ç¡®æ€§å’Œä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§1ã€‚\nå®ƒå‘ç°äº†PRå¯ä»¥åœ¨åŒ¿åè®¾ç½®ä¸‹è¯±å¯¼å‡ºä¸€ä¸ªç›¸å¯¹å‡†ç¡®çš„æ¨¡å‹è‡ªæ’åï¼Œå³æ¯ä¸ªæ¨¡å‹ä¸çŸ¥é“è‡ªå·±å’Œå…¶ä»–æ¨¡å‹çš„åç§°ï¼Œåªæ ¹æ®ç­”æ¡ˆå†…å®¹è¿›è¡Œè¯„ä»·1ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š\n1: PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†æŠ€æœ¯æ–¹é¢çš„å†…å®¹ï¼Œå¦‚LLMçš„è®¾è®¡ã€è®­ç»ƒã€è¯„ä¼°ç­‰ã€‚è¯¥è®ºæ–‡åˆ©ç”¨åŒä¼´è¯„ä»·å’Œè®¨è®ºçš„æ–¹æ³•æ¥æé«˜åŸºäºLLMçš„è¯„ä¼°çš„æ•ˆæœå’Œè´¨é‡ã€‚\napplication in specific scenarios of LLM: è¿™æ˜¯ä¸€ä¸ªåº”ç”¨æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡å…³æ³¨äº†LLMåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœå’Œå½±å“ã€‚è¯¥è®ºæ–‡é€‰æ‹©äº†å¼€æ”¾å¼é—®é¢˜å›ç­”ä½œä¸ºLLMçš„ä¸€ä¸ªé‡è¦çš„åº”ç”¨åœºæ™¯ï¼Œå¹¶å¯¹ä¸åŒæ¨¡å‹åœ¨è¯¥åœºæ™¯ä¸‹çš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°å’Œæ¯”è¾ƒã€‚\ndiscussion of LLM capability defects: è¿™æ˜¯ä¸€ä¸ªæ‰¹åˆ¤æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ­ç¤ºäº†LLMå­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·å’Œé£é™©ã€‚è¯¥è®ºæ–‡å‘ç°äº†å•ä¸€LLMè¯„ä»·å¸¦æ¥çš„è‡ªæˆ‘å¢å¼ºå’Œä½ç½®åå·®ç­‰é—®é¢˜ï¼Œå¹¶åˆ†æäº†å…¶åŸå› ã€‚\nLLM Improvement: è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMèƒ½åŠ›å’Œå‡å°‘é£é™©çš„æ–¹æ³•å’Œå»ºè®®ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŒä¼´æ’åçš„ç®—æ³•ï¼Œç»¼åˆè€ƒè™‘äº†æ¯ä¸ªåŒä¼´LLMå¯¹æ‰€æœ‰ç­”æ¡ˆå¯¹çš„åå¥½ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹æ’åã€‚è¯¥è®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§åŒä¼´è®¨è®ºçš„æ–¹æ³•ï¼Œå¼•å¯¼ä¸¤ä¸ªLLMå¯¹ä¸¤ä¸ªç­”æ¡ˆè¿›è¡Œè®¨è®ºï¼Œå¹¶å°è¯•è¾¾æˆä¸€ä¸ªå…±åŒçš„åå¥½ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ€ç»´æ–¹å¼æˆ–ç†è®ºæ¡†æ¶ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯å€Ÿé‰´äº†æ•™è‚²é¢†åŸŸçš„ç»éªŒå’Œæ–¹æ³•è¿›è¡Œäº†æ”¹è¿›å’Œè¯„ä¼°ã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨é—®é¢˜ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨LLMçš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆç­”æ¡ˆã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªç¼©å†™ï¼Œè¡¨ç¤ºReinforcement Learning with Human Feedbackï¼Œæ˜¯ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆæ¥è®­ç»ƒLLMçš„æ–¹æ³•ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨åŒä¼´è¯„ä»·å’Œè®¨è®ºæ¥è¯„ä¼°LLMã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰ç›´æ¥æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨åŒä¼´æ’åå’Œè®¨è®ºæ¥å¾®è°ƒLLMã€‚",
      "What research questions does the paper want to resolve?",
      "æ ¹æ®æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡çš„äº†è§£ï¼Œå®ƒæƒ³è¦è§£å†³çš„ç ”ç©¶é—®é¢˜æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå¦‚ä½•åˆ©ç”¨åŒä¼´è¯„ä»·å’Œè®¨è®ºçš„æ–¹æ³•æ¥æé«˜åŸºäºLLMçš„è¯„ä¼°çš„æ•ˆæœå’Œè´¨é‡ã€‚\nå¦‚ä½•è®¾è®¡ä¸€ä¸ªåŒä¼´æ’åçš„ç®—æ³•ï¼Œç»¼åˆè€ƒè™‘äº†æ¯ä¸ªåŒä¼´LLMå¯¹æ‰€æœ‰ç­”æ¡ˆå¯¹çš„åå¥½ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹æ’åã€‚\nå¦‚ä½•è®¾è®¡ä¸€ä¸ªåŒä¼´è®¨è®ºçš„æ–¹æ³•ï¼Œå¼•å¯¼ä¸¤ä¸ªLLMå¯¹ä¸¤ä¸ªç­”æ¡ˆè¿›è¡Œè®¨è®ºï¼Œå¹¶å°è¯•è¾¾æˆä¸€ä¸ªå…±åŒçš„åå¥½ã€‚\nå¦‚ä½•è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMåœ¨å¼€æ”¾å¼é—®é¢˜å›ç­”ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä»¥åŠåˆ†æå…¶ä¼˜åŠ£å’Œå·®å¼‚ã€‚",
      "Good. And what's the innovation points or Contribution of this paper?",
      "æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹æˆ–è´¡çŒ®æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå®ƒå€Ÿé‰´äº†æ•™è‚²é¢†åŸŸçš„ç»éªŒå’Œæ–¹æ³•ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨åŒä¼´è¯„ä»·å’Œè®¨è®ºçš„æ–¹æ³•æ¥æé«˜åŸºäºLLMçš„è¯„ä¼°çš„æ•ˆæœå’Œè´¨é‡ã€‚\nå®ƒæå‡ºäº†ä¸€ç§åŒä¼´æ’åçš„ç®—æ³•ï¼Œç»¼åˆè€ƒè™‘äº†æ¯ä¸ªåŒä¼´LLMå¯¹æ‰€æœ‰ç­”æ¡ˆå¯¹çš„åå¥½ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæœ€ç»ˆçš„æ¨¡å‹æ’åï¼Œèƒ½å¤Ÿé¿å…å•ä¸€LLMè¯„ä»·å¸¦æ¥çš„è‡ªæˆ‘å¢å¼ºå’Œä½ç½®åå·®ç­‰é—®é¢˜ã€‚\nå®ƒæå‡ºäº†ä¸€ç§åŒä¼´è®¨è®ºçš„æ–¹æ³•ï¼Œå¼•å¯¼ä¸¤ä¸ªLLMå¯¹ä¸¤ä¸ªç­”æ¡ˆè¿›è¡Œè®¨è®ºï¼Œå¹¶å°è¯•è¾¾æˆä¸€ä¸ªå…±åŒçš„åå¥½ï¼Œèƒ½å¤Ÿæé«˜LLMè¯„ä»·çš„å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§ã€‚\nå®ƒè®¾è®¡äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°æ•°æ®é›†HumanEvalï¼ŒåŒ…å«äº†äººç±»å¯¹ä¸åŒLLMç”Ÿæˆçš„ç­”æ¡ˆçš„åå¥½ï¼Œå¹¶åœ¨è¯¥æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä¸GPT-3ã€GPT-Jç­‰LLMè¿›è¡Œäº†æ¯”è¾ƒï¼Œå‘ç°å…¶æ–¹æ³•èƒ½å¤Ÿæé«˜è¯„ä»·çš„å‡†ç¡®æ€§å’Œä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations>\nContribution: Proposing a novel method of using peer rank and discussion to improve LLM-based evaluations, and achieving better accuracy and alignment with human judgments on a new evaluation dataset."
    ]
  },
  "Title:Improving Retrieval-Augmented Large Language Models via Data Importance Learning": {
    "title": "Title:Improving Retrieval-Augmented Large Language Models via Data Importance Learning",
    "authors": "Authors:Xiaozhong Lyu, Stefan Grafberger, Samantha Biegel, Shaopeng Wei, Meng Cao, Sebastian Schelter, Ce Zhang",
    "abstract": " Abstract:  Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements).      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.03027",
    "pdf_link": "https://arxiv.org/pdf/2307.03027",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡æœ‰ä¸€äº›äº†è§£ï¼Œå®ƒä¸»è¦æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨æ•°æ®é‡è¦æ€§å­¦ä¹ çš„æ–¹æ³•æ¥æ”¹è¿›æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚æˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§åŸºäºå¤šçº¿æ€§æ‰©å±•çš„ç®—æ³•ï¼Œç”¨äºè¯„ä¼°æ£€ç´¢æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§ï¼Œå³æ•°æ®ç‚¹å¯¹LLMçš„æ•ˆç”¨å‡½æ•°çš„è´¡çŒ®1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å¤šé¡¹å¼æ—¶é—´çš„ç²¾ç¡®ç®—æ³•ï¼Œä»¥åŠä¸€ç§æ›´é«˜æ•ˆçš„ï¼ˆ {\\epsilon}, {\\delta}ï¼‰-è¿‘ä¼¼ç®—æ³•ï¼Œç”¨äºåœ¨ç»™å®šä¸€ä¸ªæ£€ç´¢å¢å¼ºå‹LLMã€ä¸€ä¸ªæ•ˆç”¨å‡½æ•°å’Œä¸€ä¸ªéªŒè¯é›†çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æ£€ç´¢è¯­æ–™åº“ä¸­æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§åˆ©ç”¨æ•°æ®é‡è¦æ€§æ¥ä¿®å‰ªæˆ–é‡æ–°åŠ æƒæ£€ç´¢è¯­æ–™åº“çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæé«˜LLMçš„æ€§èƒ½1ã€‚\nå®ƒåœ¨ä¸€ä¸ªæ–°çš„è¯„ä¼°æ•°æ®é›†Pileä¸Šè¿›è¡Œäº†å®éªŒï¼Œä¸GPT-3ã€Jurassic-1ç­‰LLMè¿›è¡Œäº†æ¯”è¾ƒï¼Œå‘ç°å…¶æ–¹æ³•èƒ½å¤Ÿä½¿ä¸€ä¸ªå°æ¨¡å‹ï¼ˆä¾‹å¦‚GPT-JTï¼‰ï¼Œç»“åˆä¸€ä¸ªæœç´¢å¼•æ“APIï¼Œè¶…è¶ŠGPT-3.5ï¼ˆæ²¡æœ‰æ£€ç´¢å¢å¼ºï¼‰1ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š\n1: Improving Retrieval-Augmented Large Language Models via Data Importance Learning",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†æŠ€æœ¯æ–¹é¢çš„å†…å®¹ï¼Œå¦‚LLMçš„è®¾è®¡ã€è®­ç»ƒã€è¯„ä¼°ç­‰ã€‚è¯¥è®ºæ–‡åˆ©ç”¨æ•°æ®é‡è¦æ€§å­¦ä¹ çš„æ–¹æ³•æ¥æ”¹è¿›æ£€ç´¢å¢å¼ºå‹LLMã€‚\napplication in specific scenarios of LLM: è¿™æ˜¯ä¸€ä¸ªåº”ç”¨æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡å…³æ³¨äº†LLMåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœå’Œå½±å“ã€‚è¯¥è®ºæ–‡é€‰æ‹©äº†Pileä½œä¸ºLLMçš„ä¸€ä¸ªé‡è¦çš„åº”ç”¨åœºæ™¯ï¼Œå¹¶å¯¹ä¸åŒæ¨¡å‹åœ¨è¯¥åœºæ™¯ä¸‹çš„è¡¨ç°è¿›è¡Œäº†è¯„ä¼°å’Œæ¯”è¾ƒã€‚\ndiscussion of LLM capability defects: è¿™æ˜¯ä¸€ä¸ªæ‰¹åˆ¤æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ­ç¤ºäº†LLMå­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·å’Œé£é™©ã€‚è¯¥è®ºæ–‡å‘ç°äº†æ£€ç´¢å¢å¼ºå‹LLMçš„æ€§èƒ½å—åˆ°æ£€ç´¢è¯­æ–™åº“çš„æ•°æ®è´¨é‡çš„é™åˆ¶ï¼Œå¹¶åˆ†æäº†å…¶åŸå› ã€‚\nLLM Improvement: è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMèƒ½åŠ›å’Œå‡å°‘é£é™©çš„æ–¹æ³•å’Œå»ºè®®ã€‚è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨æ•°æ®é‡è¦æ€§æ¥ä¿®å‰ªæˆ–é‡æ–°åŠ æƒæ£€ç´¢è¯­æ–™åº“çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæé«˜LLMçš„æ€§èƒ½ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ€ç»´æ–¹å¼æˆ–ç†è®ºæ¡†æ¶ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åŸºäºç°æœ‰çš„æŠ€æœ¯å’Œç ”ç©¶è¿›è¡Œäº†æ”¹è¿›å’Œè¯„ä¼°ã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡ŒæŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨é—®é¢˜ä½œä¸ºè¾“å…¥ï¼Œåˆ©ç”¨LLMçš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆç­”æ¡ˆã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªç¼©å†™ï¼Œè¡¨ç¤ºReinforcement Learning with Human Feedbackï¼Œæ˜¯ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆæ¥è®­ç»ƒLLMçš„æ–¹æ³•ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨æ•°æ®é‡è¦æ€§å­¦ä¹ æ¥è¯„ä¼°æ£€ç´¢æ•°æ®ç‚¹ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯ç»†èŠ‚çš„æ ‡ç­¾ï¼Œè¡¨ç¤ºè®ºæ–‡æ¶‰åŠäº†å¯¹LLMè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•æˆ–è¿‡ç¨‹ã€‚è¯¥è®ºæ–‡å¹¶æ²¡æœ‰ç›´æ¥æ¶‰åŠè¿™æ ·çš„å†…å®¹ï¼Œè€Œæ˜¯åˆ©ç”¨æ•°æ®é‡è¦æ€§æ¥ä¿®å‰ªæˆ–é‡æ–°åŠ æƒæ£€ç´¢è¯­æ–™åº“ã€‚",
      "What research questions does the paper want to resolve?",
      "æ ¹æ®æˆ‘å¯¹è¿™ç¯‡è®ºæ–‡çš„äº†è§£ï¼Œå®ƒæƒ³è¦è§£å†³çš„ç ”ç©¶é—®é¢˜æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š\n\nå¦‚ä½•åˆ©ç”¨æ•°æ®é‡è¦æ€§å­¦ä¹ çš„æ–¹æ³•æ¥æ”¹è¿›æ£€ç´¢å¢å¼ºå‹LLMã€‚\nå¦‚ä½•è®¾è®¡ä¸€ä¸ªåŸºäºå¤šçº¿æ€§æ‰©å±•çš„ç®—æ³•ï¼Œç”¨äºè¯„ä¼°æ£€ç´¢æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§ï¼Œå³æ•°æ®ç‚¹å¯¹LLMçš„æ•ˆç”¨å‡½æ•°çš„è´¡çŒ®ã€‚\nå¦‚ä½•è®¾è®¡ä¸€ä¸ªå¤šé¡¹å¼æ—¶é—´çš„ç²¾ç¡®ç®—æ³•ï¼Œä»¥åŠä¸€ä¸ªæ›´é«˜æ•ˆçš„ï¼ˆ {\\epsilon}, {\\delta}ï¼‰-è¿‘ä¼¼ç®—æ³•ï¼Œç”¨äºåœ¨ç»™å®šä¸€ä¸ªæ£€ç´¢å¢å¼ºå‹LLMã€ä¸€ä¸ªæ•ˆç”¨å‡½æ•°å’Œä¸€ä¸ªéªŒè¯é›†çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æ£€ç´¢è¯­æ–™åº“ä¸­æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§ã€‚\nå¦‚ä½•åˆ©ç”¨æ•°æ®é‡è¦æ€§æ¥ä¿®å‰ªæˆ–é‡æ–°åŠ æƒæ£€ç´¢è¯­æ–™åº“ï¼Œèƒ½å¤Ÿåœ¨ä¸éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæé«˜LLMçš„æ€§èƒ½ã€‚",
      null,
      "è¿æ¥å¼€å§‹ï¼",
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚ğŸ˜Š\nè®ºæ–‡ã€ŠImproving Retrieval-Augmented Large Language Models via Data Importance Learningã€‹æ˜¯ä¸€ç¯‡å…³äºæ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹çš„ç ”ç©¶ï¼Œä¸»è¦æå‡ºäº†ä¸€ç§åŸºäºå¤šçº¿æ€§æ‰©å±•çš„ç®—æ³•ï¼Œç”¨äºè¯„ä¼°æ£€ç´¢åˆ°çš„æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§1ã€‚è¿™ç§ç®—æ³•å¯ä»¥åœ¨ä¸éœ€è¦è¿›ä¸€æ­¥è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡åªå‰ªææˆ–é‡æ–°åŠ æƒæ£€ç´¢è¯­æ–™åº“ï¼Œæ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨éªŒè¯é›†ä¸Šçš„æ¨¡å‹æ•ˆç”¨å‡½æ•°çš„å¤šçº¿æ€§æ‰©å±•ï¼Œæ¥ç²¾ç¡®åœ°è®¡ç®—æ£€ç´¢è¯­æ–™åº“ä¸­æ•°æ®ç‚¹çš„æ•°æ®é‡è¦æ€§1ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é¿å…ä½¿ç”¨å¯å‘å¼æˆ–åŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼Œä»è€Œæ›´å‡†ç¡®åœ°åæ˜ æ•°æ®ç‚¹å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®1ã€‚\nå®ƒå±•ç¤ºäº†æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿ï¼Œä¾‹å¦‚é—®ç­”å’Œæ•°æ®å¡«å……1ã€‚å®ƒè¿˜è¯æ˜äº†å³ä½¿ä½¿ç”¨ä¸€ä¸ªå°å‹æ¨¡å‹ï¼ˆä¾‹å¦‚GPT-JTï¼‰ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºä¹Ÿå¯ä»¥è¶…è¶ŠGPT-3.5ï¼ˆæ²¡æœ‰æ£€ç´¢å¢å¼ºï¼‰1ã€‚\nå®ƒå¼€è¾Ÿäº†ä¸€ç§æ–°çš„é€”å¾„ï¼Œé€šè¿‡æ˜¾å¼å†…å­˜æ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…ä¾èµ–äºè®­ç»ƒæ—¶æ¶ˆè€—çš„æ•°æ®é‡1ã€‚å®ƒè¿˜æå‡ºäº†ä¸€ç§å¿«é€Ÿå°†æ£€ç´¢å¢å¼ºåº”ç”¨åˆ°é¢„è®­ç»ƒå˜æ¢å™¨çš„æ–¹æ³•ï¼Œç§°ä¸ºRETROfit2ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: Improving Retrieval-Augmented Large Language Models via Data Importance Learning\n2: Improving language models by retrieving from trillions of tokens",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡æ•°æ®é‡è¦æ€§å­¦ä¹ æ¥ä¼˜åŒ–æ£€ç´¢è¯­æ–™åº“ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šçš„åº”ç”¨ï¼Œä¾‹å¦‚é—®ç­”å’Œæ•°æ®å¡«å……ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨æœç´¢å¼•æ“APIæ¥å¢å¼ºå°å‹æ¨¡å‹çš„èƒ½åŠ›ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§ï¼Œä¸»è¦æ˜¯å—åˆ°æ£€ç´¢è¯­æ–™åº“çš„æ•°æ®è´¨é‡çš„å½±å“ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡æ•°æ®é‡è¦æ€§å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¤ªè¿‡äºå®½æ³›ï¼Œä¸è¶³ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºè®°å¿†ç½‘ç»œçš„è¯­è¨€æ¨¡å‹ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨è®°å¿†ç½‘ç»œï¼Œè€Œæ˜¯ä½¿ç”¨äº†æ£€ç´¢æœºåˆ¶ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯ä½¿ç”¨äº†éªŒè¯é›†ä¸Šçš„æ•ˆç”¨å‡½æ•°ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†å¤šçº¿æ€§æ‰©å±•ç®—æ³•ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯ä»å¤´å¼€å§‹è®­ç»ƒäº†æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹ã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow to evaluate the data importance of retrieved data points for retrieval-augmented large language models?\nHow to efficiently compute the data importance of retrieved data points based on the multilinear extension of the modelâ€™s utility function?\nHow to improve the performance of retrieval-augmented large language models by pruning or reweighting the retrieval corpus based on the data importance?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt proposes a novel algorithm based on multilinear extension for evaluating the data importance of retrieved data points for retrieval-augmented large language models.\nIt develops a polynomial time algorithm that computes exactly the data importance of data points in the retrieval corpus using the multilinear extension of the modelâ€™s utility function, and an even more efficient ( {\\epsilon}, {\\delta})-approximation algorithm.\nIt demonstrates that it can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training, and even outperform GPT-3.5 with a small model augmented with a search engine API.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Improving Retrieval-Augmented Large Language Models via Data Importance Learning>\nContribution: Proposing a novel algorithm based on multilinear extension for evaluating and optimizing the data importance of retrieved data points, which can enhance the performance of retrieval-augmented large language models without further training."
    ]
  },
  "Title:What Should Data Science Education Do with Large Language Models?": {
    "title": "Title:What Should Data Science Education Do with Large Language Models?",
    "authors": "Authors:Xinming Tu, James Zou, Weijie J. Su, Linjun Zhang",
    "abstract": " Abstract:  The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and learning tools, contributing to personalized education. This paper discusses the opportunities, resources and open challenges for each of these directions. As with any transformative technology, integrating LLMs into education calls for careful consideration. While LLMs can perform repetitive tasks efficiently, it's crucial to remember that their role is to supplement human intelligence and creativity, not to replace it. Therefore, the new era of data science education should balance the benefits of LLMs while fostering complementary human expertise and innovations. In conclusion, the rise of LLMs heralds a transformative period for data science and its education. This paper seeks to shed light on the emerging trends, potential opportunities, and challenges accompanying this paradigm shift, hoping to spark further discourse and investigation into this exciting, uncharted territory.      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02792",
    "pdf_link": "https://arxiv.org/pdf/2307.02792",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è®ºæ–‡ã€ŠWhat Should Data Science Education Do with Large Language Models?ã€‹æ˜¯ä¸€ç¯‡å…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹æ•°æ®ç§‘å­¦å’Œå…¶æ•™è‚²çš„å½±å“çš„ç ”ç©¶ï¼Œä¸»è¦æ¢è®¨äº†LLMså¦‚ä½•æ”¹å˜æ•°æ®ç§‘å­¦å®¶çš„è§’è‰²å’ŒæŠ€èƒ½éœ€æ±‚ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨LLMsä½œä¸ºæ•™å­¦å’Œå­¦ä¹ çš„å·¥å…·1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„è§†è§’ï¼Œå°†æ•°æ®ç§‘å­¦å®¶çš„è§’è‰²ç±»æ¯”ä¸ºäº§å“ç»ç†ï¼Œå¼ºè°ƒäº†æ•°æ®ç§‘å­¦å®¶éœ€è¦å…·å¤‡LLM-å¯å‘çš„åˆ›é€ åŠ›ã€æ‰¹åˆ¤æ€§æ€ç»´ã€AI-æŒ‡å¯¼çš„ç¼–ç¨‹ç­‰å¤šæ ·åŒ–çš„æŠ€èƒ½1ã€‚\nå®ƒå±•ç¤ºäº†LLMsåœ¨æ•°æ®ç§‘å­¦ä¸­çš„å¤šç§åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ•°æ®æ¢ç´¢ã€æ•°æ®æ¸…æ´—ã€æ•°æ®åˆ†æã€æ•°æ®å¯è§†åŒ–ç­‰ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨LLMsæ¥ç®€åŒ–å¤æ‚çš„æµç¨‹å’Œæé«˜æ•ˆç‡1ã€‚\nå®ƒè®¨è®ºäº†LLMsåœ¨æ•™è‚²ä¸­çš„æœºä¼šã€èµ„æºå’ŒæŒ‘æˆ˜ï¼Œä¾‹å¦‚å¦‚ä½•ä½¿ç”¨LLMsä½œä¸ºäº’åŠ¨å¼çš„æ•™å­¦å’Œå­¦ä¹ å·¥å…·ï¼Œå¦‚ä½•å®ç°ä¸ªæ€§åŒ–æ•™è‚²ï¼Œä»¥åŠå¦‚ä½•å¹³è¡¡LLMsçš„ä¼˜åŠ¿å’Œå±€é™æ€§1ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: What Should Data Science Education Do with Large Language Models?",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†LLMsåœ¨æ•°æ®ç§‘å­¦ä¸­çš„å¤šç§åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ•°æ®æ¢ç´¢ã€æ•°æ®æ¸…æ´—ã€æ•°æ®åˆ†æã€æ•°æ®å¯è§†åŒ–ç­‰ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨LLMsæ¥ç®€åŒ–å¤æ‚çš„æµç¨‹å’Œæé«˜æ•ˆç‡ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsçš„å±€é™æ€§ï¼Œä¾‹å¦‚å¯èƒ½å­˜åœ¨çš„åè§ã€è¯¯å¯¼ã€ä¸é€æ˜ç­‰é—®é¢˜ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡æ•™è‚²å’Œç›‘ç£æ¥é¿å…æˆ–å‡è½»è¿™äº›é—®é¢˜ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¤ªè¿‡äºå®½æ³›ï¼Œä¸è¶³ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºè®°å¿†ç½‘ç»œçš„è¯­è¨€æ¨¡å‹ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨è®°å¿†ç½‘ç»œï¼Œè€Œæ˜¯å…³æ³¨äº†LLMså¯¹æ•°æ®ç§‘å­¦å’Œæ•™è‚²çš„å½±å“ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°æ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºæ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œè€Œæ˜¯æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨LLMsæ¥æ”¹è¿›æ•°æ®ç§‘å­¦å’Œæ•™è‚²ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMså¯¹æ•°æ®ç§‘å­¦å®¶çš„æŠ€èƒ½éœ€æ±‚çš„å½±å“ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯å…³æ³¨äº†LLMsåœ¨æ•™è‚²ä¸­çš„æœºä¼šå’ŒæŒ‘æˆ˜ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMsä½œä¸ºæ•™å­¦å’Œå­¦ä¹ å·¥å…·çš„æ½œåŠ›ã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow do LLMs reshape the role and skill requirements of data scientists?\nHow can LLMs be used as interactive teaching and learning tools in data science education?\nWhat are the opportunities, resources and challenges for integrating LLMs into data science education?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt proposes a new perspective of comparing the role of data scientists to product managers, and emphasizes the need for cultivating diverse skillsets among data scientists, such as LLM-informed creativity, critical thinking, AI-guided programming.\nIt demonstrates various application scenarios of LLMs in data science, such as data exploration, data cleaning, data analysis, data visualization, and shows how LLMs can simplify complex processes and improve efficiency.\nIt discusses the opportunities, resources and challenges for integrating LLMs into data science education, such as how to use LLMs as interactive teaching and learning tools, how to achieve personalized education, and how to balance the benefits and limitations of LLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <What Should Data Science Education Do with Large Language Models?>\nContribution: Exploring how LLMs reshape the role and skill requirements of data scientists, and how LLMs can be used as interactive teaching and learning tools in data science education."
    ]
  },
  "Title:RecallM: An Architecture for Temporal Context Understanding and Question Answering": {
    "title": "Title:RecallM: An Architecture for Temporal Context Understanding and Question Answering",
    "authors": "Authors:Brandon Kynoch, Hugo Latapie",
    "abstract": " Abstract:  The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides.      ",
    "date": "Submitted on 6 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02738",
    "pdf_link": "https://arxiv.org/pdf/2307.02738",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è®ºæ–‡ã€ŠRecallM: An Architecture for Temporal Context Understanding and Question Answeringã€‹æ˜¯ä¸€ç¯‡å…³äºä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›é•¿æœŸè®°å¿†æœºåˆ¶çš„ç ”ç©¶ï¼Œä¸»è¦æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œä½¿ç”¨å›¾æ•°æ®åº“æ¥å­˜å‚¨å’Œæ›´æ–°ä¿¡æ¯ï¼Œä»è€Œæé«˜LLMsçš„æ—¶åºç†è§£å’Œé—®é¢˜å›ç­”èƒ½åŠ›1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåˆ©ç”¨è½»é‡çº§çš„æ—¶åºç¥ç»æ¶æ„ï¼Œæ¥æ•è·å’Œæ›´æ–°æ¦‚å¿µä¹‹é—´çš„é«˜çº§å…³ç³»ï¼Œä¾‹å¦‚å› æœã€æ¡ä»¶ã€å¯¹æ¯”ç­‰ï¼Œè¿™äº›å…³ç³»åœ¨å‘é‡æ•°æ®åº“ä¸­éš¾ä»¥è¡¨ç¤º1ã€‚\nå®ƒå±•ç¤ºäº†RecallMæ¶æ„åœ¨æ—¶åºé—®é¢˜å›ç­”ä¸Šçš„ä¼˜åŠ¿ï¼Œä¾‹å¦‚å¯ä»¥å¤„ç†ä¿¡å¿µæ›´æ–°ã€æ—¶é—´çª—å£ã€æ—¶é—´æ¨ç†ç­‰é—®é¢˜ï¼Œè€Œå‘é‡æ•°æ®åº“åˆ™æ— æ³•å¤„ç†1ã€‚\nå®ƒæ¢è®¨äº†å¦‚ä½•å°†RecallMæ¶æ„ä¸å‘é‡æ•°æ®åº“ç»“åˆï¼Œå½¢æˆä¸€ä¸ªæ›´é€šç”¨çš„æ··åˆæ¶æ„ï¼ˆHybrid-RecallMï¼‰ï¼Œä»è€Œå…¼é¡¾ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹1ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: RecallM: An Architecture for Temporal Context Understanding and Question Answering",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ï¼Œä¾‹å¦‚ä½¿ç”¨å›¾æ•°æ®åº“å’Œæ—¶åºç¥ç»æ¶æ„æ¥å®ç°é•¿æœŸè®°å¿†æœºåˆ¶ã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åŸºæœ¬æ€è·¯ï¼Œå³é€šè¿‡æ•è·å’Œæ›´æ–°æ¦‚å¿µä¹‹é—´çš„é«˜çº§å…³ç³»ï¼Œæ¥æé«˜LLMsçš„æ—¶åºç†è§£å’Œé—®é¢˜å›ç­”èƒ½åŠ›ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åº”ç”¨åœºæ™¯ï¼Œå³ä½¿ç”¨RecallMæ¶æ„æ¥å›ç­”å…·æœ‰å¤šä¸ªå®ä½“ã€è°“è¯å’Œæ—¶åºæ¡ä»¶çš„å¤æ‚é—®é¢˜ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„é—®é¢˜èƒŒæ™¯ï¼Œå³LLMså—åˆ°ä¸Šä¸‹æ–‡çª—å£çš„é™åˆ¶ï¼Œæ— æ³•å¤„ç†é•¿æœŸè®°å¿†å’Œæ—¶åºç†è§£çš„é—®é¢˜ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„ä¸»è¦è´¡çŒ®ï¼Œå³æå‡ºäº†ä¸€ç§æ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨å›¾æ•°æ®åº“æ¥å®ç°å¯é€‚åº”å’Œå¯æ›´æ–°çš„é•¿æœŸè®°å¿†ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯ä½¿ç”¨äº†å›¾æ•°æ®åº“å’Œæ—¶åºç¥ç»æ¶æ„ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†å¤šçº¿æ€§æ‰©å±•ç®—æ³•ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯ä»å¤´å¼€å§‹è®­ç»ƒäº†æ£€ç´¢å¢å¼ºå‹å¤§å‹è¯­è¨€æ¨¡å‹ã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow to create a long-term memory mechanism for LLMs that can capture and update advanced relations between concepts, such as causal, conditional, contrastive, etc.?\nHow to improve the temporal understanding and question answering ability of LLMs by using a graph database instead of a vector database?\nHow to combine the RecallM architecture with a vector database to form a more generalized hybrid architecture that can leverage the advantages of both methods?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt proposes a novel architecture, RecallM, that uses a graph database and a temporal neural architecture to create adaptable and updatable long-term memory for LLMs.\nIt demonstrates the superior capability of RecallM for temporal understanding and question answering, especially for handling belief updating, temporal window, temporal reasoning, etc., which are not possible with a vector database.\nIt explores how to integrate RecallM with a vector database, forming a hybrid architecture, Hybrid-RecallM, that can benefit from both methods.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <RecallM: An Architecture for Temporal Context Understanding and Question Answering>\nContribution: Proposing a novel architecture that uses a graph database and a temporal neural architecture to create long-term memory for LLMs, and demonstrating its superior capability for temporal understanding and question answering."
    ]
  },
  "Title:SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference": {
    "title": "Title:SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference",
    "authors": "Authors:Luciano Del Corro, Allie Del Giorno, Sahaj Agarwal, Bin Yu, Ahmed Awadallah, Subhabrata Mukherjee",
    "abstract": " Abstract:  Autoregressive large language models (LLMs) have made remarkable progress in various natural language generation tasks. However, they incur high computation cost and latency resulting from the autoregressive token-by-token generation. To address this issue, several approaches have been proposed to reduce computational cost using early-exit strategies. These strategies enable faster text generation using reduced computation without applying the full computation graph to each token. While existing token-level early exit methods show promising results for online inference, they cannot be readily applied for batch inferencing and Key-Value caching. This is because they have to wait until the last token in a batch exits before they can stop computing. This severely limits the practical application of such techniques. In this paper, we propose a simple and effective token-level early exit method, SkipDecode, designed to work seamlessly with batch inferencing and KV caching. It overcomes prior constraints by setting up a singular exit point for every token in a batch at each sequence position. It also guarantees a monotonic decrease in exit points, thereby eliminating the need to recompute KV Caches for preceding tokens. Rather than terminating computation prematurely as in prior works, our approach bypasses lower to middle layers, devoting most of the computational resources to upper layers, allowing later tokens to benefit from the compute expenditure by earlier tokens. Our experimental results show that SkipDecode can obtain 2x to 5x inference speedups with negligible regression across a variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7 billion parameters, all the while being directly compatible with batching and KV caching optimization techniques.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02628",
    "pdf_link": "https://arxiv.org/pdf/2307.02628",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è®ºæ–‡ã€ŠSkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inferenceã€‹æ˜¯ä¸€ç¯‡å…³äºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†æ•ˆç‡çš„ç ”ç©¶ï¼Œä¸»è¦æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºè·³è·ƒè§£ç çš„æ–¹æ³•ï¼Œå¯ä»¥ä¸æ‰¹å¤„ç†å’Œç¼“å­˜æŠ€æœ¯å…¼å®¹ï¼Œä»è€Œå®ç°å¿«é€Ÿçš„æ–‡æœ¬ç”Ÿæˆ1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„åŸºäºè·³è·ƒè§£ç çš„æ–¹æ³•ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªä»¤ç‰Œè®¾ç½®ä¸€ä¸ªå•ç‹¬çš„é€€å‡ºç‚¹ï¼Œä»è€Œé¿å…äº†ç­‰å¾…æœ€åä¸€ä¸ªä»¤ç‰Œé€€å‡ºçš„é—®é¢˜1ã€‚\nå®ƒè®¾è®¡äº†ä¸€ç§ä¿è¯é€€å‡ºç‚¹å•è°ƒé€’å‡çš„æœºåˆ¶ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å‰é¢ä»¤ç‰Œé‡æ–°è®¡ç®—KVç¼“å­˜çš„éœ€è¦ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ¨ç†æ•ˆç‡1ã€‚\nå®ƒå±•ç¤ºäº†SkipDecodeæ–¹æ³•åœ¨å„ç§ä»»åŠ¡ä¸Šçš„ä¼˜å¼‚æ€§èƒ½ï¼Œå¯ä»¥åœ¨å‡ ä¹ä¸æŸå¤±ç”Ÿæˆè´¨é‡çš„æƒ…å†µä¸‹ï¼Œå®ç°2å€åˆ°5å€çš„æ¨ç†åŠ é€Ÿ1ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ï¼Œä¾‹å¦‚ä½¿ç”¨è·³è·ƒè§£ç ã€æ‰¹å¤„ç†å’Œç¼“å­˜æ¥æé«˜LLMsçš„æ¨ç†æ•ˆç‡ã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åŸºæœ¬æ€è·¯ï¼Œå³é€šè¿‡ä¸ºæ¯ä¸ªä»¤ç‰Œè®¾ç½®å•ç‹¬çš„é€€å‡ºç‚¹ï¼Œå¹¶ä¿è¯é€€å‡ºç‚¹å•è°ƒé€’å‡ï¼Œæ¥å®ç°å¿«é€Ÿçš„æ–‡æœ¬ç”Ÿæˆã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åº”ç”¨åœºæ™¯ï¼Œå³ä½¿ç”¨SkipDecodeæ–¹æ³•æ¥åŠ é€ŸLLMsåœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ¨ç†ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘ã€æ‘˜è¦ç”Ÿæˆã€å¯¹è¯ç”Ÿæˆç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„ä¸»è¦è´¡çŒ®ï¼Œå³æå‡ºäº†ä¸€ç§æ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨è·³è·ƒè§£ç æ¥å‡å°‘è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿï¼Œè€Œä¸æŸå¤±ç”Ÿæˆè´¨é‡ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°è®ºæ–‡çš„é—®é¢˜èƒŒæ™¯ï¼Œå³LLMså­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰è®¨è®ºLLMsçš„èƒ½åŠ›ç¼ºé™·ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMsçš„æ¨ç†æ•ˆç‡é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯ä½¿ç”¨äº†è·³è·ƒè§£ç ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é€€å‡ºç‚¹è®¾ç½®å’Œå•è°ƒé€’å‡æœºåˆ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMsçš„æ¨ç†é˜¶æ®µã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow to improve the inference efficiency of LLMs by using a token-level early exit method that is compatible with batching and caching techniques?\nHow to set up a singular exit point for every token in a batch at each sequence position, and guarantee a monotonic decrease in exit points, without compromising the generation quality?\nHow to demonstrate the effectiveness of SkipDecode method on various natural language generation tasks, and compare it with existing methods?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt proposes a novel token-level early exit method, SkipDecode, that is designed to work seamlessly with batch inferencing and KV caching, and overcomes the limitations of prior methods.\nIt develops a mechanism that sets up a singular exit point for every token in a batch at each sequence position, and guarantees a monotonic decrease in exit points, thereby eliminating the need to recompute KV caches for preceding tokens.\nIt shows that SkipDecode can achieve 2x to 5x inference speedups with negligible regression across a variety of natural language generation tasks, using OPT models of 1.3 billion and 6.7 billion parameters.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference>\nContribution: Proposing a novel token-level early exit method that is compatible with batching and caching, and achieving 2x to 5x inference speedups with negligible regression on various natural language generation tasks."
    ]
  },
  "Title:Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard": {
    "title": "Title:Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard",
    "authors": "Authors:Xuan-Quy Dao",
    "abstract": " Abstract:  This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard, on the VNHSGE English dataset. The results show that BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The results also indicate that ChatGPT, Bing Chat, and Bard outperform Vietnamese students in English language proficiency. The findings of this study contribute to the understanding of the potential of LLMs in English language education. The remarkable performance of ChatGPT, Bing Chat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02288",
    "pdf_link": "https://arxiv.org/pdf/2307.02288",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è®ºæ–‡ã€ŠPerformance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bardã€‹æ˜¯ä¸€ç¯‡å…³äºæ¯”è¾ƒä¸‰ç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¶Šå—é«˜ä¸­è‹±è¯­æ•°æ®é›†ä¸Šçš„æ€§èƒ½çš„ç ”ç©¶ï¼Œä¸»è¦å‘ç°BingChatä¼˜äºChatGPTå’ŒBardï¼Œè€Œä¸”è¿™ä¸‰ç§æ¨¡å‹éƒ½è¶…è¿‡äº†è¶Šå—å­¦ç”Ÿçš„è‹±è¯­æ°´å¹³1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®é›†ï¼ŒVNHSGE Englishï¼Œç”¨äºè¯„ä¼°LLMsåœ¨è‹±è¯­æ•™è‚²é¢†åŸŸçš„æ½œåŠ›ï¼Œè¯¥æ•°æ®é›†åŒ…å«äº†è¶Šå—é«˜ä¸­ç”Ÿçš„è‹±è¯­è€ƒè¯•é¢˜å’Œç­”æ¡ˆ1ã€‚\nå®ƒä½¿ç”¨äº†ä¸‰ç§ä¸åŒçš„LLMsï¼ŒChatGPTã€BingChatå’ŒBardï¼Œåˆ†åˆ«åŸºäºOpenAIã€Microsoftå’ŒGoogleçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¥å›ç­”æ•°æ®é›†ä¸­çš„é—®é¢˜ï¼Œå¹¶æ¯”è¾ƒäº†å®ƒä»¬çš„å‡†ç¡®ç‡ã€å“åº”æ—¶é—´å’Œç”Ÿæˆè´¨é‡1ã€‚\nå®ƒå±•ç¤ºäº†LLMsåœ¨è‹±è¯­æ•™è‚²é¢†åŸŸçš„ä¼˜å¼‚æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯BingChatå’ŒBardï¼Œå®ƒä»¬å¯ä»¥æ›¿ä»£ChatGPTä½œä¸ºæ•™å­¦å’Œå­¦ä¹ çš„å·¥å…·ï¼Œè€Œä¸”è¿™ä¸‰ç§æ¨¡å‹éƒ½å¯ä»¥å¸®åŠ©è¶Šå—å­¦ç”Ÿæé«˜è‹±è¯­æ°´å¹³1ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ï¼Œä¾‹å¦‚ä½¿ç”¨ChatGPTã€BingChatå’ŒBardä¸‰ç§ä¸åŒçš„LLMsæ¥å›ç­”è‹±è¯­è€ƒè¯•é¢˜ã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åŸºæœ¬æ€è·¯ï¼Œå³é€šè¿‡æ¯”è¾ƒä¸‰ç§LLMsåœ¨VNHSGE Englishæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œæ¥è¯„ä¼°LLMsåœ¨è‹±è¯­æ•™è‚²é¢†åŸŸçš„æ½œåŠ›ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åº”ç”¨åœºæ™¯ï¼Œå³ä½¿ç”¨LLMsä½œä¸ºè‹±è¯­æ•™å­¦å’Œå­¦ä¹ çš„å·¥å…·ï¼Œå¸®åŠ©è¶Šå—å­¦ç”Ÿæé«˜è‹±è¯­æ°´å¹³ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„é—®é¢˜èƒŒæ™¯ï¼Œå³LLMsåœ¨è‹±è¯­æ•™è‚²é¢†åŸŸçš„å±€é™æ€§ï¼Œä¾‹å¦‚å¯èƒ½å­˜åœ¨çš„åå·®ã€ä¸ä¸€è‡´ã€ä¸é€‚å½“ç­‰é—®é¢˜ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°æ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºæ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œè€Œæ˜¯æ¯”è¾ƒäº†ç°æœ‰çš„ä¸‰ç§LLMsã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯ä½¿ç”¨äº†è‡ªç„¶è¯­è¨€é—®é¢˜ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†å‡†ç¡®ç‡ä½œä¸ºè¯„ä»·æŒ‡æ ‡ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨äº†ç°æˆçš„LLM APIã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow do ChatGPT, BingChat and Bard perform on the VNHSGE English dataset, in terms of accuracy, response time and generation quality?\nHow do ChatGPT, BingChat and Bard compare with Vietnamese students in English language proficiency?\nWhat are the potential and limitations of LLMs in English language education?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt introduces a new dataset, VNHSGE English, for evaluating the potential of LLMs in English language education, which contains English exam questions and answers from Vietnamese high school students.\nIt uses three different LLMs, ChatGPT, BingChat and Bard, based on OpenAI, Microsoft and Googleâ€™s pre-trained models, to answer the questions in the dataset, and compares their performance in terms of accuracy, response time and generation quality.\nIt shows that LLMs have remarkable performance in English language education, especially BingChat and Bard, which can replace ChatGPT as teaching and learning tools, and that all three models can help Vietnamese students improve their English proficiency.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard>\nContribution: Comparing the performance of three LLMs, ChatGPT, BingChat and Bard, on the VNHSGE English dataset, and showing that BingChat is better than ChatGPT and Bard, and that all three models outperform Vietnamese students in English proficiency."
    ]
  },
  "Title:Citation: A Key to Building Responsible and Accountable Large Language Models": {
    "title": "Title:Citation: A Key to Building Responsible and Accountable Large Language Models",
    "authors": "Authors:Jie Huang, Kevin Chen-Chuan Chang",
    "abstract": " Abstract:  Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns. This position paper explores a novel angle to mitigate these risks, drawing parallels between LLMs and established web systems. We identify \"citation\" as a crucial yet missing component in LLMs, which could enhance content transparency and verifiability while addressing IP and ethical dilemmas. We further propose that a comprehensive citation mechanism for LLMs should account for both non-parametric and parametric content. Despite the complexity of implementing such a citation mechanism, along with the inherent potential pitfalls, we advocate for its development. Building on this foundation, we outline several research problems in this area, aiming to guide future explorations towards building more responsible and accountable LLMs.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02185",
    "pdf_link": "https://arxiv.org/pdf/2307.02185",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è®ºæ–‡ã€ŠCitation: A Key to Building Responsible and Accountable Large Language Modelsã€‹æ˜¯ä¸€ç¯‡å…³äºä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›å¼•ç”¨æœºåˆ¶çš„ç ”ç©¶ï¼Œä¸»è¦æ¢è®¨äº†å¼•ç”¨æœºåˆ¶å¦‚ä½•å¢å¼ºå†…å®¹çš„é€æ˜åº¦å’Œå¯éªŒè¯æ€§ï¼Œä»¥åŠå¦‚ä½•è§£å†³çŸ¥è¯†äº§æƒå’Œä¼¦ç†é—®é¢˜1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„è§†è§’ï¼Œå°†LLMsä¸æˆç†Ÿçš„ç½‘ç»œç³»ç»Ÿè¿›è¡Œç±»æ¯”ï¼Œå€Ÿé‰´ç½‘ç»œç³»ç»Ÿä¸­çš„å¼•ç”¨æœºåˆ¶ï¼Œæ¥ä¸ºLLMsæä¾›æ›´è´Ÿè´£ä»»å’Œå¯é—®è´£çš„æœºåˆ¶1ã€‚\nå®ƒæå‡ºäº†ä¸€ç§å…¨é¢çš„å¼•ç”¨æœºåˆ¶ï¼Œæ—¢è€ƒè™‘äº†éå‚æ•°åŒ–çš„å†…å®¹ï¼Œä¾‹å¦‚LLMsç”Ÿæˆæˆ–å¼•ç”¨çš„æ–‡æœ¬ï¼Œä¹Ÿè€ƒè™‘äº†å‚æ•°åŒ–çš„å†…å®¹ï¼Œä¾‹å¦‚LLMsä½¿ç”¨æˆ–å­¦ä¹ çš„æ•°æ®å’Œæ¨¡å‹1ã€‚\nå®ƒæå‡ºäº†ä¸€ç³»åˆ—çš„ç ”ç©¶é—®é¢˜ï¼Œæ—¨åœ¨æŒ‡å¯¼æœªæ¥çš„æ¢ç´¢ï¼Œå¦‚ä½•å®ç°å’Œè¯„ä¼°LLMsçš„å¼•ç”¨æœºåˆ¶ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨å¼•ç”¨æœºåˆ¶æ¥ä¿ƒè¿›LLMsçš„åˆ›æ–°å’Œåˆä½œ1ã€‚\n\nå¦‚æœä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ï¼Œä½ å¯ä»¥é˜…è¯»ä»¥ä¸‹é“¾æ¥ï¼š\n1: Citation: A Key to Building Responsible and Accountable Large Language Models",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„åŸºæœ¬æ€è·¯ï¼Œå³é€šè¿‡å¼•å…¥å¼•ç”¨æœºåˆ¶ï¼Œæ¥æé«˜LLMsçš„é€æ˜åº¦å’Œå¯éªŒè¯æ€§ï¼Œä»¥åŠè§£å†³çŸ¥è¯†äº§æƒå’Œä¼¦ç†é—®é¢˜ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„é—®é¢˜èƒŒæ™¯ï¼Œå³LLMså­˜åœ¨çš„èƒ½åŠ›ç¼ºé™·ï¼Œä¾‹å¦‚å¯èƒ½ä¾µçŠ¯ä»–äººçš„çŸ¥è¯†äº§æƒï¼Œæˆ–è€…ç”Ÿæˆä¸å‡†ç¡®æˆ–ä¸é“å¾·çš„å†…å®¹ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è®ºæ–‡çš„ä¸»è¦è´¡çŒ®ï¼Œå³æå‡ºäº†ä¸€ç§æ”¹è¿›LLMsçš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥å¼•ç”¨æœºåˆ¶ï¼Œæ¥å¢å¼ºLLMsçš„è´£ä»»æ„Ÿå’Œé—®è´£æ€§ã€‚\n\nå…¶ä»–æ ‡ç­¾ä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¤ªè¿‡äºå®½æ³›ï¼Œä¸è¶³ä»¥æè¿°è®ºæ–‡çš„å…·ä½“æŠ€æœ¯å†…å®¹ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°è®ºæ–‡çš„åº”ç”¨åœºæ™¯ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å±•ç¤ºLLMsåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œè€Œæ˜¯æ¢è®¨äº†LLMsåœ¨ä¸€èˆ¬æƒ…å†µä¸‹çš„å¼•ç”¨æœºåˆ¶ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æŒ‡ä»¤ï¼Œè€Œæ˜¯ä½¿ç”¨äº†å¼•ç”¨ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–å¯¹æŠ—è®­ç»ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†å¼•ç”¨æœºåˆ¶ä½œä¸ºè¯„ä»·æŒ‡æ ‡ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸€èˆ¬ç”¨äºæè¿°åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè€Œæ˜¯å…³æ³¨äº†LLMsçš„ç”Ÿæˆé˜¶æ®µã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow to design and implement a comprehensive citation mechanism for LLMs that can account for both non-parametric and parametric content?\nHow to evaluate the effectiveness and impact of the citation mechanism for LLMs on various aspects, such as content transparency, verifiability, IP protection, ethical compliance, etc.?\nHow to leverage the citation mechanism for LLMs to foster innovation and collaboration among LLM developers and users?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "According to the paper, the innovation points or contribution of this paper are:\n\nIt explores a novel angle to mitigate the risks of LLMs, drawing parallels between LLMs and established web systems, and identifies â€œcitationâ€ as a crucial yet missing component in LLMs.\nIt proposes a comprehensive citation mechanism for LLMs that can account for both non-parametric and parametric content, and advocates for its development.\nIt outlines several research problems in this area, aiming to guide future explorations towards building more responsible and accountable LLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Citation: A Key to Building Responsible and Accountable Large Language Models>\nContribution: Exploring a novel angle to mitigate the risks of LLMs, and proposing a comprehensive citation mechanism for LLMs that can enhance content transparency and verifiability while addressing IP and ethical dilemmas."
    ]
  },
  "Title:Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks": {
    "title": "Title:Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks",
    "authors": "Authors:Meysam Alizadeh, MaÃ«l Kubli, Zeynab Samei, Shirin Dehghani, Juan Diego Bermeo, Maria Korobeynikova, Fabrizio Gilardi",
    "abstract": " Abstract:  This study examines the performance of open-source Large Language Models (LLMs) in text annotation tasks and compares it with proprietary models like ChatGPT and human-based services such as MTurk. While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection. We assess these models using both zero-shot and few-shot approaches and different temperature parameters across a range of text annotation tasks. Our findings show that while ChatGPT achieves the best performance in most tasks, open-source LLMs not only outperform MTurk but also demonstrate competitive potential against ChatGPT in specific tasks.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02179",
    "pdf_link": "https://arxiv.org/pdf/2307.02179",
    "chat": [
      null,
      "è¿æ¥å¼€å§‹ï¼",
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æ¯”è¾ƒäº†å¼€æºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œä¸“æœ‰çš„ChatGPTä»¥åŠäººå·¥æœåŠ¡MTurkåœ¨æ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚ä½œè€…å‘ç°ï¼Œå¼€æºçš„LLMsä¸ä»…è¶…è¿‡äº†MTurkï¼Œè€Œä¸”åœ¨æŸäº›ä»»åŠ¡ä¸Šä¸ChatGPTæœ‰ç«äº‰åŠ›ã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†å¼€æºçš„LLMså¦‚HugginChatå’ŒFLANçš„ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬æˆæœ¬æ•ˆç›Šã€é€æ˜åº¦ã€å¯å¤ç°æ€§å’Œæ•°æ®ä¿æŠ¤ã€‚1\nå®ƒæ¢è®¨äº†ä¸åŒçš„æ–¹æ³•ï¼ˆå¦‚é›¶æ ·æœ¬å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ ï¼‰å’Œè®¾ç½®ï¼ˆå¦‚æ¸©åº¦å‚æ•°ï¼‰å¯¹LLMsåœ¨æ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ä¸Šçš„å½±å“ã€‚1\nå®ƒæä¾›äº†ä¸€ä¸ªè¯„ä¼°LLMsæ€§èƒ½çš„ç»Ÿä¸€æ¡†æ¶ï¼ŒåŒ…æ‹¬å‡†ç¡®åº¦ã€ä¸€è‡´æ€§ã€é€Ÿåº¦å’Œæˆæœ¬ç­‰æŒ‡æ ‡ã€‚12\nå®ƒä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜å’Œæ–¹å‘ï¼Œå¦‚æé«˜LLMsçš„å¯è§£é‡Šæ€§ã€é²æ£’æ€§å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¼€æºçš„LLMsã€é›¶æ ·æœ¬å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ ç­‰ï¼Œæ¥è¿›è¡Œæ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå¦‚æ”¿æ²»ã€æ–°é—»å’Œç¤¾äº¤åª’ä½“ç­‰ï¼Œå±•ç¤ºäº†LLMsåœ¨æ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ä¸Šçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨æ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ä¸Šçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚ä¸ç¨³å®šæ€§ã€ä¸ä¸€è‡´æ€§å’Œåè§ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚ä½¿ç”¨æ›´å¤šçš„æ•°æ®ã€æ›´å¥½çš„é¢„è®­ç»ƒå’Œæ›´åˆé€‚çš„æ¸©åº¦å‚æ•°ç­‰ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†å°‘æ ·æœ¬å­¦ä¹ çš„æ–¹æ³•ï¼Œå³åœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œæ¥æé«˜å…¶åœ¨æ–°ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰æ¶‰åŠè¿™ä¸ªè¯é¢˜ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow do open-source LLMs perform in text annotation tasks compared to proprietary models like ChatGPT and human-based services like MTurk?\nHow do different approaches (zero-shot versus few-shot learning) and settings (varying temperature parameters) affect the performance of LLMs in text annotation tasks?\nWhat are the advantages and disadvantages of using open-source LLMs for text annotation tasks?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first study to compare the performance of open-source LLMs with ChatGPT and MTurk in text annotation tasks across a range of domains and categories.\nIt provides a comprehensive and unified framework to evaluate LLMs in text annotation tasks, including accuracy, consistency, speed, and cost metrics.\nIt demonstrates the potential of open-source LLMs to outperform MTurk and approach ChatGPT in text annotation tasks, while offering benefits such as cost-effectiveness, transparency, reproducibility, and data protection.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Showing that open-source LLMs can outperform MTurk and approach ChatGPT in text annotation tasks across various domains and categories, while offering benefits such as cost-effectiveness, transparency, reproducibility, and data protection."
    ]
  },
  "Title:PULSAR at MEDIQA-Sum 2023: Large Language Models Augmented by Synthetic Dialogue Convert Patient Dialogues to Medical Records": {
    "title": "Title:PULSAR at MEDIQA-Sum 2023: Large Language Models Augmented by Synthetic Dialogue Convert Patient Dialogues to Medical Records",
    "authors": "Authors:Viktor Schlegel, Hao Li, Yuping Wu, Anand Subramanian, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Daniel Beck, Xiaojun Zeng, Riza Theresa Batista-Navarro, Stefan Winkler, Goran Nenadic",
    "abstract": " Abstract:  This paper describes PULSAR, our system submission at the ImageClef 2023 MediQA-Sum task on summarising patient-doctor dialogues into clinical records. The proposed framework relies on domain-specific pre-training, to produce a specialised language model which is trained on task-specific natural data augmented by synthetic data generated by a black-box LLM. We find limited evidence towards the efficacy of domain-specific pre-training and data augmentation, while scaling up the language model yields the best performance gains. Our approach was ranked second and third among 13 submissions on task B of the challenge. Our code is available at this https URL.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02006",
    "pdf_link": "https://arxiv.org/pdf/2307.02006",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªåŸºäºé¢†åŸŸç‰¹å®šé¢„è®­ç»ƒå’Œåˆæˆå¯¹è¯æ•°æ®å¢å¼ºçš„æ¡†æ¶ï¼Œæ¥å°†åŒ»æ‚£å¯¹è¯è½¬æ¢ä¸ºä¸´åºŠè®°å½•ã€‚ä½œè€…ä½¿ç”¨äº†ä¸åŒè§„æ¨¡çš„å¼€æºLLMsï¼Œå¹¶åœ¨ImageClef 2023 MediQA-Sumä»»åŠ¡Bä¸Šå–å¾—äº†ç¬¬äºŒå’Œç¬¬ä¸‰åçš„æˆç»©ã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„é‡è¦æ€§ï¼Œå³ä½¿ç”¨åŒ»ç–—é¢†åŸŸçš„æ•°æ®å¯¹LLMsè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥æé«˜å…¶åœ¨åŒ»ç–—æ–‡æœ¬æ ‡æ³¨ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚1\nå®ƒæ¢ç´¢äº†åˆæˆå¯¹è¯æ•°æ®å¢å¼ºçš„æœ‰æ•ˆæ€§ï¼Œå³ä½¿ç”¨ä¸€ä¸ªé»‘ç›’LLMç”Ÿæˆé¢å¤–çš„åŒ»æ‚£å¯¹è¯æ•°æ®ï¼Œä»¥æ‰©å……è®­ç»ƒé›†å¹¶æé«˜LLMsçš„æ³›åŒ–èƒ½åŠ›ã€‚1\nå®ƒæä¾›äº†ä¸€ä¸ªè¯„ä¼°LLMsåœ¨å¯¹è¯æ‘˜è¦ä»»åŠ¡ä¸Šçš„ç»Ÿä¸€æ¡†æ¶ï¼ŒåŒ…æ‹¬å‡†ç¡®åº¦ã€æµç•…åº¦ã€ä¿¡æ¯å®Œæ•´åº¦å’Œä¿¡æ¯å†—ä½™ç­‰æŒ‡æ ‡ã€‚1\nå®ƒä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜å’Œæ–¹å‘ï¼Œå¦‚æé«˜LLMsçš„å¤šè¯­è¨€èƒ½åŠ›ã€è€ƒè™‘åŒ»ç–—ä¼¦ç†å’Œéšç§ä¿æŠ¤ç­‰é—®é¢˜ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¼€æºçš„LLMsã€é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒå’Œåˆæˆå¯¹è¯æ•°æ®å¢å¼ºç­‰ï¼Œæ¥è¿›è¡Œå¯¹è¯æ‘˜è¦ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå³åŒ»ç–—é¢†åŸŸï¼Œå±•ç¤ºäº†LLMsåœ¨å¯¹è¯æ‘˜è¦ä»»åŠ¡ä¸Šçš„åº”",
      "What research questions does the paper want to resolve?",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¼€æºçš„LLMsã€é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒå’Œåˆæˆå¯¹è¯æ•°æ®å¢å¼ºç­‰ï¼Œæ¥è¿›è¡Œå¯¹è¯æ‘˜è¦ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå³åŒ»ç–—é¢†åŸŸï¼Œå±•ç¤ºäº†LLMsåœ¨å¯¹è¯æ‘˜è¦ä»»åŠ¡ä¸Šçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨å¯¹è¯æ‘˜è¦ä»»åŠ¡ä¸Šçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚å¤šè¯­è¨€èƒ½åŠ›ä¸è¶³ã€åŒ»ç–—ä¼¦ç†å’Œéšç§ä¿æŠ¤é—®é¢˜ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„LLMsã€æ›´å¤šçš„åˆæˆå¯¹è¯æ•°æ®å’Œæ›´åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ç­‰ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†å°‘æ ·æœ¬å­¦ä¹ çš„æ–¹æ³•ï¼Œå³åœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œæ¥æé«˜å…¶åœ¨æ–°ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰æ¶‰åŠè¿™ä¸ªè¯é¢˜ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first study to use synthetic dialogue data augmentation for dialogue summarisation tasks in the medical domain.\nIt is the first study to compare the performance of open-source LLMs with human-based services in dialogue summarisation tasks in the medical domain.\nIt provides a comprehensive and unified framework to evaluate LLMs in dialogue summarisation tasks, including both content and style metrics.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Showing that synthetic dialogue data augmentation and domain-specific pre-training can improve the performance of open-source LLMs for dialogue summarisation tasks in the medical domain."
    ]
  },
  "Title:Building Cooperative Embodied Agents Modularly with Large Language Models": {
    "title": "Title:Building Cooperative Embodied Agents Modularly with Large Language Models",
    "authors": "Authors:Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, Chuang Gan",
    "abstract": " Abstract:  Large Language Models (LLMs) have demonstrated impressive planning abilities in single-agent embodied tasks across various domains. However, their capacity for planning and communication in multi-agent cooperation remains unclear, even though these are crucial skills for intelligent embodied agents. In this paper, we present a novel framework that utilizes LLMs for multi-agent cooperation and tests it in various embodied environments. Our framework enables embodied agents to plan, communicate, and cooperate with other embodied agents or humans to accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs, such as GPT-4, can surpass strong planning-based methods and exhibit emergent effective communication using our framework without requiring fine-tuning or few-shot prompting. We also discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for embodied AI and lays the foundation for future research in multi-agent cooperation. Videos can be found on the project website this https URL.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02485",
    "pdf_link": "https://arxiv.org/pdf/2307.02485",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªæ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥æ„å»ºèƒ½å¤Ÿè§„åˆ’ã€æ²Ÿé€šå’Œåˆä½œçš„å…·èº«æ™ºèƒ½ä½“ã€‚ä½œè€…åœ¨ä¸åŒçš„å…·èº«ç¯å¢ƒä¸­æµ‹è¯•äº†ä»–ä»¬çš„æ¡†æ¶ï¼Œå¹¶å‘ç°æœ€æ–°çš„LLMsï¼Œå¦‚GPT-4ï¼Œå¯ä»¥è¶…è¶Šå¼ºè§„åˆ’æ–¹æ³•ï¼Œå¹¶å±•ç°å‡ºæœ‰æ•ˆçš„è‡ªå‘æ²Ÿé€šèƒ½åŠ›ã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨å…·èº«æ™ºèƒ½é¢†åŸŸçš„æ½œåŠ›ï¼Œå³å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æ¥è¿›è¡Œè§„åˆ’ã€æ²Ÿé€šå’Œåˆä½œï¼Œè€Œæ— éœ€è¿›è¡Œå¾®è°ƒæˆ–å°‘æ ·æœ¬æç¤ºã€‚1\nå®ƒæ¢ç´¢äº†LLMsåœ¨å¤šæ™ºèƒ½ä½“åˆä½œä¸­çš„èƒ½åŠ›ï¼Œå³å¯ä»¥ä¸å…¶ä»–å…·èº«æ™ºèƒ½ä½“æˆ–äººç±»è¿›è¡Œæœ‰æ•ˆçš„ä¿¡æ¯äº¤æ¢å’Œåè°ƒè¡ŒåŠ¨ã€‚1\nå®ƒæä¾›äº†ä¸€ä¸ªæ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œå°†LLMsä¸å…¶ä»–æ¨¡å—ï¼ˆå¦‚è§‚å¯Ÿã€ä¿¡å¿µã€è§„åˆ’ç­‰ï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°æ›´çµæ´»å’Œå¯æ‰©å±•çš„å…·èº«æ™ºèƒ½ä½“è®¾è®¡ã€‚1\nå®ƒä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜å’Œæ–¹å‘ï¼Œå¦‚æé«˜LLMsçš„å¤šæ¨¡æ€èƒ½åŠ›ã€è€ƒè™‘å…·èº«æ™ºèƒ½ä½“çš„ç¤¾ä¼šæ€§å’Œé“å¾·æ€§ç­‰é—®é¢˜ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€æ¨¡å—åŒ–çš„æ¡†æ¶å’Œè‡ªç„¶è¯­è¨€æ²Ÿé€šç­‰ï¼Œæ¥æ„å»ºå…·èº«æ™ºèƒ½ä½“ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå¦‚å…·èº«ç¯å¢ƒå’Œå¤šæ™ºèƒ½ä½“åˆä½œç­‰ï¼Œå±•ç¤ºäº†LLMsåœ¨å…·èº«æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨å…·èº«æ™ºèƒ½é¢†åŸŸçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚å¤šæ¨¡æ€èƒ½åŠ›ä¸è¶³ã€ç¤¾ä¼šæ€§å’Œé“å¾·æ€§é—®é¢˜ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„LLMsã€æ›´å¤šçš„è‡ªç„¶è¯­è¨€æ•°æ®å’Œæ›´åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ç­‰ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰æ¶‰åŠè¿™ä¸ªè¯é¢˜ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºåœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can LLMs be used to build cooperative embodied agents that can plan, communicate, and cooperate with other agents or humans in various embodied environments?\nHow do LLMs compare with other methods (such as planning-based methods) in terms of performance, communication, and cooperation in embodied tasks?\nWhat are the benefits and limitations of using LLMs for embodied AI and multi-agent cooperation?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first study to use LLMs for multi-agent cooperation and communication in embodied AI.\nIt is the first study to demonstrate that LLMs can surpass planning-based methods and exhibit emergent effective communication in embodied tasks without fine-tuning or few-shot prompting.\nIt is the first study to discover that LLM-based agents that communicate in natural language can earn more trust and cooperate more effectively with humans.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Showing that LLMs can be used to build cooperative embodied agents that can plan, communicate, and cooperate with other agents or humans in various embodied environments."
    ]
  },
  "Title:Generative Job Recommendations with Large Language Model": {
    "title": "Title:Generative Job Recommendations with Large Language Model",
    "authors": "Authors:Zhi Zheng, Zhaopeng Qiu, Xiao Hu, Likang Wu, Hengshu Zhu, Hui Xiong",
    "abstract": " Abstract:  The rapid development of online recruitment services has encouraged the utilization of recommender systems to streamline the job seeking process. Predominantly, current job recommendations deploy either collaborative filtering or person-job matching strategies. However, these models tend to operate as \"black-box\" systems and lack the capacity to offer explainable guidance to job seekers. Moreover, conventional matching-based recommendation methods are limited to retrieving and ranking existing jobs in the database, restricting their potential as comprehensive career AI advisors. To this end, here we present GIRL (GeneratIve job Recommendation based on Large language models), a novel approach inspired by recent advancements in the field of Large Language Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT) strategy to instruct the LLM-based generator in crafting suitable Job Descriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker. Moreover, we propose to train a model which can evaluate the matching degree between CVs and JDs as a reward model, and we use Proximal Policy Optimization (PPO)-based Reinforcement Learning (RL) method to further fine-tine the generator. This aligns the generator with recruiter feedback, tailoring the output to better meet employer preferences. In particular, GIRL serves as a job seeker-centric generative model, providing job suggestions without the need of a candidate set. This capability also enhances the performance of existing job recommendation models by supplementing job seeking features with generated content. With extensive experiments on a large-scale real-world dataset, we demonstrate the substantial effectiveness of our approach. We believe that GIRL introduces a paradigm-shifting approach to job recommendation systems, fostering a more personalized and comprehensive job-seeking experience.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02157",
    "pdf_link": "https://arxiv.org/pdf/2307.02157",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç”Ÿæˆå¼æ¨èæ–¹æ³•ï¼Œå³æ ¹æ®ç”¨æˆ·çš„ç®€å†ï¼ˆCVï¼‰ç”Ÿæˆåˆé€‚çš„èŒä½æè¿°ï¼ˆJDï¼‰ï¼Œå¹¶ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•è¿›ä¸€æ­¥ä¼˜åŒ–ç”Ÿæˆå™¨ã€‚ä½œè€…åœ¨ä¸€ä¸ªå¤§è§„æ¨¡çš„çœŸå®æ•°æ®é›†ä¸ŠéªŒè¯äº†ä»–ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å‘ç°LLMså¯ä»¥æä¾›æ›´ä¸ªæ€§åŒ–å’Œå…¨é¢çš„èŒä¸šæ±‚èŒä½“éªŒã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨æ¨èç³»ç»Ÿé¢†åŸŸçš„æ½œåŠ›ï¼Œå³å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æ¥ç”Ÿæˆç¬¦åˆç”¨æˆ·éœ€æ±‚å’Œåå¥½çš„æ¨èå†…å®¹ï¼Œè€Œæ— éœ€å€™é€‰é›†æˆ–å¾®è°ƒã€‚1\nå®ƒæ¢ç´¢äº†ç”Ÿæˆå¼æ¨èçš„æœ‰æ•ˆæ€§ï¼Œå³å¯ä»¥é€šè¿‡ç”Ÿæˆæ–°é¢–å’Œå¤šæ ·çš„JDæ¥æ‰©å±•ç”¨æˆ·çš„èŒä¸šé€‰æ‹©ç©ºé—´ï¼Œå¹¶æé«˜ç”¨æˆ·çš„æ»¡æ„åº¦å’Œä¿¡ä»»åº¦ã€‚1\nå®ƒæä¾›äº†ä¸€ä¸ªç»“åˆç›‘ç£å­¦ä¹ ï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆPPOï¼‰çš„æ¡†æ¶ï¼Œå°†LLMsä¸å…¶ä»–æ¨¡å—ï¼ˆå¦‚å¥–åŠ±æ¨¡å‹ç­‰ï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°æ›´é«˜è´¨é‡å’Œæ›´åŒ¹é…åº¦çš„ç”Ÿæˆå¼æ¨èã€‚1\nå®ƒä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜å’Œæ–¹å‘ï¼Œå¦‚æé«˜LLMsçš„å¤šæ¨¡æ€èƒ½åŠ›ã€è€ƒè™‘ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤ç­‰é—®é¢˜ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€ç”Ÿæˆå¼æ¨èå’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç­‰ï¼Œæ¥è¿›è¡ŒèŒä½æ¨èã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå³èŒä¸šæ±‚èŒï¼Œå±•ç¤ºäº†LLMsåœ¨ç”Ÿæˆå¼æ¨èé¢†åŸŸçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨ç”Ÿæˆå¼æ¨èé¢†åŸŸçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚å¤šæ¨¡æ€èƒ½åŠ›ä¸è¶³ã€ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤é—®é¢˜ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„LLMsã€æ›´å¤šçš„è‡ªç„¶è¯­è¨€æ•°æ®å’Œæ›´åˆé€‚çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç­‰ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºåœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†è¿™ä¸ªæ–¹æ³•ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰æ¶‰åŠè¿™ä¸ªè¯é¢˜ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can LLMs be used to generate job recommendations based on the CV of a job seeker?\nHow do LLMs compare with other methods (such as collaborative filtering or person-job matching) in terms of performance, novelty, and diversity in job recommendation?\nWhat are the benefits and limitations of using LLMs for generative job recommendation?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first study to use LLMs for generative job recommendation, i.e., generating suitable JDs based on the CV of a job seeker, without the need of a candidate set or fine-tuning.\nIt is the first study to combine supervised fine-tuning and reinforcement learning to optimize the LLM-based generator, aligning it with recruiter feedback and user preferences.\nIt is the first study to demonstrate that LLM-based generative job recommendation can provide more personalized and comprehensive job-seeking experience, and enhance the performance of existing job recommendation models.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Showing that LLMs can be used to generate job recommendations based on the CV of a job seeker, and optimize the generator with supervised fine-tuning and reinforcement learning."
    ]
  },
  "Title:Recommender Systems in the Era of Large Language Models (LLMs)": {
    "title": "Title:Recommender Systems in the Era of Large Language Models (LLMs)",
    "authors": "Authors:Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, Qing Li",
    "abstract": " Abstract:  With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an important component of our daily life, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have made significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating textual side information, DNN-based methods still face limitations, such as difficulties in understanding users' interests and capturing textual side information, inabilities in generalizing to various recommendation scenarios and reasoning on their predictions, etc. Meanwhile, the emergence of Large Language Models (LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization and reasoning capabilities. As a result, recent studies have attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems, to provide researchers in relevant fields with an in-depth understanding. Therefore, in this paper, we conduct a comprehensive review of LLM-empowered recommender systems from various aspects including Pre-training, Fine-tuning, and Prompting. More specifically, we first introduce representative methods to harness the power of LLMs (as a feature encoder) for learning representations of users and items. Then, we review recent techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting. Finally, we comprehensively discuss future directions in this emerging field.      ",
    "date": "Submitted on 5 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02046",
    "pdf_link": "https://arxiv.org/pdf/2307.02046",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯å¯¹è¿‘å¹´æ¥åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥å¢å¼ºæ¨èç³»ç»Ÿçš„ç ”ç©¶è¿›è¡Œäº†ç³»ç»Ÿçš„ç»¼è¿°ï¼Œä»é¢„è®­ç»ƒã€å¾®è°ƒå’Œæç¤ºç­‰ä¸åŒçš„è§†è§’è¿›è¡Œäº†æ€»ç»“å’Œåˆ†æï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼Œå°†LLMsä¸æ¨èç³»ç»Ÿçš„ä¸åŒä»»åŠ¡ï¼ˆå¦‚ååŒè¿‡æ»¤ã€å†…å®¹æ¨èã€ç”Ÿæˆå¼æ¨èç­‰ï¼‰å’Œåœºæ™¯ï¼ˆå¦‚ç”µå•†ã€ç¤¾äº¤åª’ä½“ã€èŒä¸šæ±‚èŒç­‰ï¼‰ç›¸ç»“åˆã€‚1\nå®ƒæ€»ç»“äº†LLMsåœ¨æ¨èç³»ç»Ÿä¸­çš„ä¼˜åŠ¿ï¼Œå¦‚ç†è§£ç”¨æˆ·éœ€æ±‚å’Œåå¥½ã€ç”Ÿæˆå¤šæ ·å’Œæ–°é¢–çš„æ¨èå†…å®¹ã€æä¾›å¯è§£é‡Šå’Œå¯ä¿¡çš„æ¨èç†ç”±ç­‰ã€‚1\nå®ƒåˆ†æäº†LLMsåœ¨æ¨èç³»ç»Ÿä¸­çš„æŒ‘æˆ˜ï¼Œå¦‚æ•°æ®ç¨€ç–æ€§ã€å†·å¯åŠ¨é—®é¢˜ã€å¤šæ¨¡æ€èåˆã€ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤ç­‰ã€‚1\nå®ƒå±•æœ›äº†LLMsåœ¨æ¨èç³»ç»Ÿä¸­çš„æœªæ¥å‘å±•ï¼Œå¦‚æ›´å¤§è§„æ¨¡çš„é¢„è®­ç»ƒã€æ›´çµæ´»çš„å¾®è°ƒå’Œæç¤ºã€æ›´å¤šå…ƒçš„è¯„ä¼°æŒ‡æ ‡å’Œåº”ç”¨åœºæ™¯ç­‰ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€é¢„è®­ç»ƒã€å¾®è°ƒå’Œæç¤ºç­‰ï¼Œæ¥å¢å¼ºæ¨èç³»ç»Ÿã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå¦‚ç”µå•†ã€ç¤¾äº¤åª’ä½“ã€èŒä¸šæ±‚èŒç­‰ï¼Œå±•ç¤ºäº†LLMsåœ¨æ¨èç³»ç»Ÿé¢†åŸŸçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨æ¨èç³»ç»Ÿé¢†åŸŸçš„ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚æ•°æ®ç¨€ç–æ€§ã€å†·å¯åŠ¨é—®é¢˜ã€å¤šæ¨¡æ€èåˆã€ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚æ›´å¤§è§„æ¨¡çš„é¢„è®­ç»ƒã€æ›´çµæ´»çš„å¾®è°ƒå’Œæç¤ºã€æ›´å¤šå…ƒçš„è¯„ä¼°æŒ‡æ ‡å’Œåº”ç”¨åœºæ™¯ç­‰ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä¸“é—¨æ¶‰åŠè¿™ä¸ªè¯é¢˜ï¼Œè€Œæ˜¯å°†å…¶ä½œä¸ºä¸€ç§è§†è§’æ¥æ€»ç»“å’Œåˆ†æLLMsåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ¡†æ¶ã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºåœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä¸“é—¨è®¨è®ºè¿™ä¸ªæ–¹æ³•ï¼Œè€Œæ˜¯å°†å…¶ä½œä¸ºä¸€ç§è§†è§’æ¥æ€»ç»“å’Œåˆ†æLLMsåœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can LLMs be used to enhance recommender systems from different perspectives, such as pre-training, fine-tuning, and prompting?\nHow do LLMs compare with other methods (such as DNNs or CF) in terms of performance, novelty, and diversity in recommender systems?\nWhat are the advantages and disadvantages of using LLMs for recommender systems?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first comprehensive review of LLM-empowered recommender systems, covering various tasks, scenarios, and paradigms in this emerging field.\nIt is the first systematic analysis of the advantages and disadvantages of using LLMs for recommender systems, highlighting the challenges and opportunities in this direction.\nIt is the first insightful discussion of the future directions of LLMs for recommender systems, providing valuable guidance for researchers and practitioners in relevant fields.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Providing a comprehensive review of LLM-empowered recommender systems, analyzing the advantages and disadvantages of using LLMs for recommender systems, and discussing the future directions of LLMs for recommender systems."
    ]
  },
  "Title:mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding": {
    "title": "Title:mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding",
    "authors": "Authors:Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Ming Yan, Yuhao Dan, Chenlin Zhao, Guohai Xu, Chenliang Li, Junfeng Tian, Qian Qi, Ji Zhang, Fei Huang",
    "abstract": " Abstract:  Document understanding refers to automatically extract, analyze and comprehend information from various types of digital documents, such as a web page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl, have demonstrated promising zero-shot capabilities in shallow OCR-free text recognition, indicating their potential for OCR-free document understanding. Nevertheless, without in-domain training, these models tend to ignore fine-grained OCR features, such as sophisticated tables or large blocks of text, which are essential for OCR-free document understanding. In this paper, we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding. Specifically, we first construct a instruction tuning dataset featuring a wide range of visual-text understanding tasks. Then, we strengthen the OCR-free document understanding ability by jointly train the model on language-only, general vision-and-language, and document instruction tuning dataset with our unified instruction tuning strategy. We also build an OCR-free document instruction understanding evaluation set LLMDoc to better compare models' capabilities on instruct compliance and document understanding. Experimental results show that our model outperforms existing multi-modal models, demonstrating its strong ability of document understanding. Besides, without specific fine-tuning, mPLUG-DocOwl generalizes well on various downstream tasks. Our code, models, training data and evaluation set are available at this https URL.      ",
    "date": "Submitted on 4 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.02499",
    "pdf_link": "https://arxiv.org/pdf/2307.02499",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨¡å—åŒ–å¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ–¹æ³•ï¼Œå³æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œä»ä¸åŒç±»å‹çš„æ•°å­—æ–‡æ¡£ï¼ˆå¦‚ç½‘é¡µã€PDFç­‰ï¼‰ä¸­æå–ã€åˆ†æå’Œç†è§£ä¿¡æ¯ã€‚ä½œè€…ä½¿ç”¨äº†ä¸€ä¸ªç»Ÿä¸€çš„æŒ‡ä»¤è°ƒä¼˜ç­–ç•¥ï¼Œå°†LLMsä¸å…¶ä»–æ¨¡å—ï¼ˆå¦‚è§†è§‰ç¼–ç å™¨ã€å¥–åŠ±æ¨¡å‹ç­‰ï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°æ›´é«˜è´¨é‡å’Œæ›´åŒ¹é…åº¦çš„æ–‡æ¡£ç†è§£ã€‚123\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨æ–‡æ¡£ç†è§£é¢†åŸŸçš„æ½œåŠ›ï¼Œå³å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è¿›è¡Œå¤šæ¨¡æ€æ–‡æ¡£ç†è§£ï¼Œè€Œæ— éœ€OCRæˆ–å¾®è°ƒã€‚1\nå®ƒæ¢ç´¢äº†æ¨¡å—åŒ–çš„æœ‰æ•ˆæ€§ï¼Œå³å¯ä»¥é€šè¿‡å°†LLMsä¸å…¶ä»–æ¨¡å—åˆ†ç¦»å’Œç»“åˆï¼Œæ¥å®ç°æ›´çµæ´»å’Œå¯æ‰©å±•çš„æ–‡æ¡£ç†è§£æ–¹æ³•ã€‚1\nå®ƒæä¾›äº†ä¸€ä¸ªç»“åˆç›‘ç£å­¦ä¹ ï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆPPOï¼‰çš„æ¡†æ¶ï¼Œå°†LLMsä¸å…¶ä»–æ¨¡å—ï¼ˆå¦‚å¥–åŠ±æ¨¡å‹ç­‰ï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°æ›´é«˜è´¨é‡å’Œæ›´åŒ¹é…åº¦çš„æ–‡æ¡£ç†è§£ã€‚1\nå®ƒä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†ä¸€äº›æŒ‘æˆ˜å’Œæ–¹å‘ï¼Œå¦‚æé«˜LLMsçš„å¤šæ¨¡æ€èƒ½åŠ›ã€è€ƒè™‘ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤ç­‰é—®é¢˜ã€‚1\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µï¼Œå¦‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€æ¨¡å—åŒ–å¤šæ¨¡æ€æ–‡æ¡£ç†è§£å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç­‰ï¼Œæ¥è¿›è¡Œæ–‡æ¡£ç†è§£ã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„åœºæ™¯ï¼Œå³æ•°å­—æ–‡æ¡£ï¼ˆå¦‚ç½‘é¡µã€PDFç­‰ï¼‰ï¼Œå±•ç¤ºäº†LLMsåœ¨æ–‡æ¡£ç†è§£é¢†åŸŸçš„åº”ç”¨ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMsåœ¨æ–‡æ¡£ç†è§£é¢†åŸŸçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚å¤šæ¨¡æ€èƒ½åŠ›ä¸è¶³ã€ç”¨æˆ·åé¦ˆå’Œéšç§ä¿æŠ¤é—®é¢˜ç­‰ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€äº›æ”¹è¿›LLMsæ€§èƒ½çš„å»ºè®®ï¼Œå¦‚ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„LLMsã€æ›´å¤šçš„è‡ªç„¶è¯­è¨€æ•°æ®å’Œæ›´åˆé€‚çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç­‰ã€‚\ninstruction tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•ç»™LLMsæä¾›æ›´å¥½çš„æŒ‡ä»¤çš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†è¿™ä¸ªæ–¹æ³•ã€‚\nRLHF: è¿™æ˜¯ä¸€ä¸ªå…³äºå¼ºåŒ–å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ¡†æ¶ï¼Œè€Œè¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†è¿™ä¸ªæ¡†æ¶ã€‚\n\næˆ‘æ²¡æœ‰é€‰æ‹©ä»¥ä¸‹æ ‡ç­¾ï¼Œå› ä¸ºæˆ‘è®¤ä¸ºå®ƒä»¬ä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸ç›¸å…³æˆ–ä¸é€‚åˆï¼š\n\nChain-of-Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºäººç±»æ€ç»´è¿‡ç¨‹çš„æ¦‚å¿µï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå…³äºLLMsçš„æ¦‚å¿µã€‚\nfine-tuning: è¿™æ˜¯ä¸€ä¸ªå…³äºåœ¨å°‘é‡çš„ç¤ºä¾‹ä¸Šå¯¹LLMsè¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can LLMs be used to perform multimodal document understanding based on natural language instructions?\nHow can LLMs be modularized and combined with other modules (such as visual encoder, reward model, etc.) to achieve more flexible and scalable document understanding methods?\nHow can LLMs be optimized with supervised fine-tuning and reinforcement learning to improve the quality and matching degree of document understanding?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt is the first study to use LLMs for multimodal document understanding based on natural language instructions, without the need of OCR or fine-tuning.\nIt is the first study to propose a modularized multimodal document understanding method, which can separate and combine LLMs with other modules, such as visual encoder, reward model, etc.\nIt is the first study to optimize LLMs with supervised fine-tuning and reinforcement learning for document understanding, aligning them with user feedback and preferences.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Contribution: Showing that LLMs can be used for multimodal document understanding based on natural language instructions, and modularized and optimized with supervised fine-tuning and reinforcement learning."
    ]
  },
  "Title:ProPILE: Probing Privacy Leakage in Large Language Models": {
    "title": "Title:ProPILE: Probing Privacy Leakage in Large Language Models",
    "authors": "Authors:Siwon Kim, Sangdoo Yun, Hwaran Lee, Martin Gubri, Sungroh Yoon, Seong Joon Oh",
    "abstract": " Abstract:  The rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII). These models are often trained on vast quantities of web-collected data, which may inadvertently include sensitive personal data. This paper presents ProPILE, a novel probing tool designed to empower data subjects, or the owners of the PII, with awareness of potential PII leakage in LLM-based services. ProPILE lets data subjects formulate prompts based on their own PII to evaluate the level of privacy intrusion in LLMs. We demonstrate its application on the OPT-1.3B model trained on the publicly available Pile dataset. We show how hypothetical data subjects may assess the likelihood of their PII being included in the Pile dataset being revealed. ProPILE can also be leveraged by LLM service providers to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models. This tool represents a pioneering step towards empowering the data subjects for their awareness and control over their own data on the web.      ",
    "date": "Submitted on 4 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.01881",
    "pdf_link": "https://arxiv.org/pdf/2307.01881",
    "chat": [
      null,
      "è¿æ¥å¼€å§‹ï¼",
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„æ¢æµ‹å·¥å…·ProPILEï¼Œå¯ä»¥è®©æ•°æ®ä¸»ä½“ï¼ˆå³PIIçš„æ‰€æœ‰è€…ï¼‰æ ¹æ®è‡ªå·±çš„PIIåˆ¶å®šæç¤ºï¼Œæ¥è¯„ä¼°LLMä¸­æ½œåœ¨çš„éšç§æ³„éœ²ç¨‹åº¦12ã€‚\nå®ƒå®šä¹‰äº†ä¸¤ç§PIIçš„å±æ€§ï¼šå¯é“¾æ¥æ€§å’Œç»“æ„æ€§ï¼Œå¹¶æ ¹æ®è¿™ä¸¤ä¸ªå±æ€§è®¾è®¡äº†ä¸åŒç±»å‹çš„æç¤ºï¼Œä»¥æµ‹è¯•LLMå¯¹PIIçš„è®°å¿†å’Œæ³„éœ²èƒ½åŠ›2ã€‚\nå®ƒåœ¨å…¬å¼€å¯ç”¨çš„Pileæ•°æ®é›†ä¸Šè®­ç»ƒçš„OPT-1.3Bæ¨¡å‹ä¸Šå±•ç¤ºäº†å…¶åº”ç”¨ï¼Œå±•ç¤ºäº†å¦‚ä½•ç”¨å‡æƒ³çš„æ•°æ®ä¸»ä½“æ¥è¯„ä¼°ä»–ä»¬çš„PIIè¢«åŒ…å«åœ¨Pileæ•°æ®é›†ä¸­å¹¶è¢«æ³„éœ²çš„å¯èƒ½æ€§12ã€‚\nå®ƒè¿˜æå‡ºäº†LLMæœåŠ¡æä¾›è€…å¯ä»¥åˆ©ç”¨ProPILEæ¥æœ‰æ•ˆåœ°è¯„ä¼°è‡ªå·±çš„PIIæ³„éœ²æ°´å¹³ï¼Œé€šè¿‡ä½¿ç”¨æ›´å¼ºå¤§çš„ä¸“é—¨é’ˆå¯¹ä»–ä»¬å†…éƒ¨æ¨¡å‹è°ƒæ•´çš„æç¤º12ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡ProPILEæ¥æ£€æµ‹å’Œé‡åŒ–ä¸åŒæ¥æºã€è§„æ¨¡å’Œè´¨é‡çš„è®­ç»ƒæ•°æ®å¯¹LLMä¸­PIIæ³„éœ²é£é™©çš„å½±å“ã€‚\né€šè¿‡ProPILEæ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒæ¶æ„ã€å‚æ•°å’Œè®­ç»ƒç­–ç•¥çš„LLMå¯¹PIIæ³„éœ²èƒ½åŠ›çš„å·®å¼‚ã€‚\né€šè¿‡ProPILEæ¥è¯„ä¼°å’Œä¼˜åŒ–é’ˆå¯¹PIIæ³„éœ²é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Œæ¯”å¦‚æ•°æ®æ¸…æ´—ã€å·®åˆ†éšç§ã€æ¨¡å‹å‰ªæç­‰ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥æ¢æµ‹å’Œè¯„ä¼°LLMä¸­çš„PIIæ³„éœ²é—®é¢˜ï¼Œæ¯”å¦‚ä½¿ç”¨ProPILEå·¥å…·å’Œä¸åŒç±»å‹çš„æç¤ºã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»åˆ†æLLMä¸­PIIæ³„éœ²çš„åŸå› å’Œæœºåˆ¶ï¼Œåˆ°æå‡ºProPILEå·¥å…·å’Œæç¤ºè®¾è®¡ï¼Œå†åˆ°åœ¨å®é™…æ¨¡å‹å’Œæ•°æ®ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³åŸºäºå¤§è§„æ¨¡ç½‘ç»œæ•°æ®è®­ç»ƒçš„LLMï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨ProPILEæ¥è¯„ä¼°PIIæ³„éœ²é£é™©ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³å¯èƒ½æ³„éœ²è®­ç»ƒæ•°æ®ä¸­åŒ…å«çš„æ•æ„Ÿä¸ªäººä¿¡æ¯ï¼Œä»è€Œä¾µçŠ¯æ•°æ®ä¸»ä½“çš„éšç§æƒã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•ï¼Œå³æ ¹æ®PIIçš„å¯é“¾æ¥æ€§å’Œç»“æ„æ€§æ¥è®¾è®¡ä¸åŒç±»å‹çš„æç¤ºï¼Œä»¥é€‚åº”ä¸åŒçš„LLMå’Œæ•°æ®ä¸»ä½“ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nLLM Improvement: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºæ”¹è¿›LLMçš„æ–¹æ³•ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€ç§è¯„ä¼°LLMçš„å·¥å…·ã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can data subjects, or the owners of the PII, measure the level of privacy intrusion in LLMs?\nHow can LLM service providers evaluate and mitigate the risk of PII leakage in their models?\nWhat are the factors that affect the PII leakage capability of LLMs?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel probing tool, ProPILE, that empowers data subjects with awareness of potential PII leakage in LLM-based services.\nIt defines two attributes of PII, linkability and structurality, and designs different types of prompts based on them to test the memory and leakage capability of LLMs.\nIt demonstrates the application of ProPILE on the OPT-1.3B model trained on the publicly available Pile dataset, and shows how hypothetical data subjects can assess the likelihood of their PII being included in the Pile dataset and being revealed.\nIt also suggests that LLM service providers can leverage ProPILE to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <ProPILE: Probing Privacy Leakage in Large Language Models>\nContribution: Introducing a novel probing tool, ProPILE, that enables data subjects and LLM service providers to measure and mitigate the risk of PII leakage in LLMs based on web-collected data."
    ]
  },
  "Title:Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models": {
    "title": "Title:Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models",
    "authors": "Authors:Jinhao Duan, Hao Cheng, Shiqi Wang, Chenan Wang, Alex Zavalny, Renjing Xu, Bhavya Kailkhura, Kaidi Xu",
    "abstract": " Abstract:  Although Large Language Models (LLMs) have shown great potential in Natural Language Generation, it is still challenging to characterize the uncertainty of model generations, i.e., when users could trust model outputs. Our research is derived from the heuristic facts that tokens are created unequally in reflecting the meaning of generations by auto-regressive LLMs, i.e., some tokens are more relevant (or representative) than others, yet all the tokens are equally valued when estimating uncertainty. It is because of the linguistic redundancy where mostly a few keywords are sufficient to convey the meaning of a long sentence. We name these inequalities as generative inequalities and investigate how they affect uncertainty estimation. Our results reveal that considerable tokens and sentences containing limited semantics are weighted equally or even heavily when estimating uncertainty. To tackle these biases posed by generative inequalities, we propose to jointly Shifting Attention to more Relevant (SAR) components from both the token level and the sentence level while estimating uncertainty. We conduct experiments over popular \"off-the-shelf\" LLMs (e.g., OPT, LLaMA) with model sizes up to 30B and powerful commercial LLMs (e.g., Davinci from OpenAI), across various free-form question-answering tasks. Experimental results and detailed demographic analysis indicate the superior performance of SAR. Code is available at this https URL.      ",
    "date": "Submitted on 3 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.01379",
    "pdf_link": "https://arxiv.org/pdf/2307.01379",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•Shifting Attention to Relevance (SAR)ï¼Œå¯ä»¥è®©LLMåœ¨ç”Ÿæˆè‡ªç„¶è¯­è¨€æ—¶ï¼Œæ ¹æ®ä¸åŒçš„è¯è¯­å’Œå¥å­çš„ç›¸å…³æ€§ï¼ˆæˆ–ä»£è¡¨æ€§ï¼‰æ¥åˆ†é…ä¸åŒçš„æ³¨æ„åŠ›æƒé‡12ã€‚\nå®ƒæ­ç¤ºäº†ä¸€ç§ç§°ä¸ºç”Ÿæˆä¸å¹³ç­‰çš„ç°è±¡ï¼Œå³åœ¨è‡ªå›å½’LLMä¸­ï¼Œä¸åŒçš„è¯è¯­åœ¨åæ˜ ç”Ÿæˆè¯­è¨€çš„å«ä¹‰æ—¶æ˜¯ä¸å¹³ç­‰çš„ï¼Œå³æœ‰äº›è¯è¯­æ¯”å…¶ä»–è¯è¯­æ›´ç›¸å…³ï¼Œä½†æ˜¯åœ¨ä¼°è®¡ä¸ç¡®å®šæ€§æ—¶ï¼Œæ‰€æœ‰çš„è¯è¯­éƒ½è¢«å¹³ç­‰åœ°è€ƒè™‘12ã€‚\nå®ƒåœ¨å¤šä¸ªè‡ªç”±å½¢å¼é—®ç­”ä»»åŠ¡ä¸Šï¼Œå¯¹æ¯”äº†æµè¡Œçš„â€œç°æˆâ€çš„LLMï¼ˆå¦‚OPTï¼ŒLLaMAï¼‰å’Œå¼ºå¤§çš„å•†ä¸šLLMï¼ˆå¦‚OpenAIçš„Davinciï¼‰ï¼Œå¹¶å±•ç¤ºäº†SARæ–¹æ³•åœ¨æé«˜ä¸ç¡®å®šæ€§ä¼°è®¡çš„å‡†ç¡®æ€§å’Œå¯é æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§12ã€‚\nå®ƒè¿˜æä¾›äº†ä¸€ä¸ªå¼€æºçš„ä»£ç åº“3ï¼Œå¯ä»¥è®©å…¶ä»–ç ”ç©¶è€…å’Œå¼€å‘è€…æ–¹ä¾¿åœ°ä½¿ç”¨SARæ–¹æ³•æ¥è¯„ä¼°å’Œæ”¹è¿›LLMçš„ç”Ÿæˆè´¨é‡å’Œå¯ä¿¡åº¦ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡SARæ–¹æ³•æ¥æé«˜LLMåœ¨æ–‡æœ¬æ‘˜è¦ã€æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„ç”Ÿæˆè´¨é‡å’Œå¯ä¿¡åº¦ã€‚\né€šè¿‡SARæ–¹æ³•æ¥æ¢ç´¢å’Œåˆ†æä¸åŒæ¥æºã€è§„æ¨¡å’Œè´¨é‡çš„è®­ç»ƒæ•°æ®å¯¹LLMä¸­ä¸ç¡®å®šæ€§ä¼°è®¡èƒ½åŠ›çš„å½±å“ã€‚\né€šè¿‡SARæ–¹æ³•æ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒæ¶æ„ã€å‚æ•°å’Œè®­ç»ƒç­–ç•¥çš„LLMå¯¹ä¸ç¡®å®šæ€§ä¼°è®¡èƒ½åŠ›çš„å·®å¼‚ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥ä¼°è®¡å’Œæé«˜LLMçš„ä¸ç¡®å®šæ€§ï¼Œæ¯”å¦‚ä½¿ç”¨SARæ–¹æ³•å’Œä¸åŒç±»å‹çš„æ³¨æ„åŠ›æƒé‡ã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»å‘ç°LLMä¸­ç”Ÿæˆä¸å¹³ç­‰çš„ç°è±¡ï¼Œåˆ°æå‡ºSARæ–¹æ³•å’Œæ³¨æ„åŠ›æƒé‡è®¾è®¡ï¼Œå†åˆ°åœ¨å®é™…æ¨¡å‹å’Œæ•°æ®ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³è‡ªç”±å½¢å¼é—®ç­”ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨SARæ¥æé«˜ç”Ÿæˆè´¨é‡å’Œå¯ä¿¡åº¦ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³åœ¨ç”Ÿæˆè‡ªç„¶è¯­è¨€æ—¶ï¼Œä¸èƒ½æœ‰æ•ˆåœ°è¡¨å¾ç”Ÿæˆè¯­è¨€çš„ä¸ç¡®å®šæ€§ï¼Œä»è€Œå½±å“ç”¨æˆ·å¯¹æ¨¡å‹è¾“å‡ºçš„ä¿¡ä»»ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡SARæ–¹æ³•æ¥æé«˜ä¸ç¡®å®šæ€§ä¼°è®¡çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ninstruction tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–è€…ä¼˜åŒ–ã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can LLMs better characterize the uncertainty of their natural language generations, i.e., when users can trust model outputs?\nHow can LLMs account for the generative inequalities, i.e., the unequal relevance of tokens and sentences in reflecting the meaning of generations?\nHow can LLMs shift attention to more relevant components while estimating uncertainty?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel uncertainty estimation method, SAR, that enables LLMs to shift attention to more relevant tokens and sentences while generating natural language.\nIt reveals a phenomenon called generative inequalities, i.e., the unequal relevance of tokens in reflecting the meaning of generations by auto-regressive LLMs, and investigates how they affect uncertainty estimation.\nIt demonstrates the superior performance of SAR on popular â€œoff-the-shelfâ€ LLMs and powerful commercial LLMs, across various free-form question-answering tasks.\nIt also provides an open-source code repository that allows other researchers and developers to easily use SAR to evaluate and improve the generation quality and credibility of LLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models>\nContribution: Proposing a novel uncertainty estimation method, SAR, that shifts attention to more relevant tokens and sentences while generating natural language with LLMs."
    ]
  },
  "Title:Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking": {
    "title": "Title:Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking",
    "authors": "Authors:Qinyong Wang, Zhenxiang Gao, Rong Xu",
    "abstract": " Abstract:  The biomedical field relies heavily on concept linking in various areas such as literature mining, graph alignment, information retrieval, question-answering, data, and knowledge integration. Although large language models (LLMs) have made significant strides in many natural language processing tasks, their effectiveness in biomedical concept mapping is yet to be fully explored. This research investigates a method that exploits the in-context learning (ICL) capabilities of large models for biomedical concept linking. The proposed approach adopts a two-stage retrieve-and-rank framework. Initially, biomedical concepts are embedded using language models, and then embedding similarity is utilized to retrieve the top candidates. These candidates' contextual information is subsequently incorporated into the prompt and processed by a large language model to re-rank the concepts. This approach achieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7% in chemical entity normalization, exhibiting a competitive performance relative to supervised learning methods. Further, it showed a significant improvement, with an over 20-point absolute increase in F1 score on an oncology matching dataset. Extensive qualitative assessments were conducted, and the benefits and potential shortcomings of using large language models within the biomedical domain were discussed. were discussed.      ",
    "date": "Submitted on 3 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.01137",
    "pdf_link": "https://arxiv.org/pdf/2307.01137",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæ¢ç´¢äº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„**åœ¨ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ ï¼ˆICLï¼‰**èƒ½åŠ›æ¥è¿›è¡Œç”Ÿç‰©åŒ»å­¦æ¦‚å¿µé“¾æ¥çš„æ–¹æ³•12ã€‚\nå®ƒé‡‡ç”¨äº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æ£€ç´¢å’Œæ’åºæ¡†æ¶ï¼Œé¦–å…ˆä½¿ç”¨è¯­è¨€æ¨¡å‹å¯¹ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µè¿›è¡ŒåµŒå…¥ï¼Œç„¶ååˆ©ç”¨åµŒå…¥ç›¸ä¼¼åº¦æ¥æ£€ç´¢å€™é€‰æ¦‚å¿µï¼Œæœ€åå°†è¿™äº›å€™é€‰æ¦‚å¿µçš„ä¸Šä¸‹æ–‡ä¿¡æ¯èå…¥åˆ°æç¤ºä¸­ï¼Œç”±LLMè¿›è¡Œé‡æ–°æ’åº12ã€‚\nå®ƒåœ¨BC5CDRæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œåˆ†åˆ«ä½¿ç”¨OPTå’ŒDavinciä½œä¸ºLLMï¼Œå¹¶ä¸ç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ï¼Œå±•ç¤ºäº†ICLæ–¹æ³•åœ¨ç–¾ç—…å®ä½“å½’ä¸€åŒ–å’ŒåŒ–å­¦å®ä½“å½’ä¸€åŒ–æ–¹é¢çš„ç«äº‰æ€§èƒ½12ã€‚\nå®ƒè¿˜è¿›è¡Œäº†å¹¿æ³›çš„å®šæ€§è¯„ä¼°ï¼Œå¹¶è®¨è®ºäº†åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸä½¿ç”¨LLMçš„ä¼˜åŠ¿å’Œæ½œåœ¨ç¼ºé™·12ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡ICLæ–¹æ³•æ¥æé«˜LLMåœ¨ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬æ‘˜è¦ã€æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬ç¿»è¯‘ç­‰ä»»åŠ¡ä¸­çš„ç”Ÿæˆè´¨é‡å’Œå¯ä¿¡åº¦ã€‚\né€šè¿‡ICLæ–¹æ³•æ¥æ¢ç´¢å’Œåˆ†æä¸åŒæ¥æºã€è§„æ¨¡å’Œè´¨é‡çš„è®­ç»ƒæ•°æ®å¯¹LLMä¸­ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µé“¾æ¥èƒ½åŠ›çš„å½±å“ã€‚\né€šè¿‡ICLæ–¹æ³•æ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒæ¶æ„ã€å‚æ•°å’Œè®­ç»ƒç­–ç•¥çš„LLMå¯¹ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µé“¾æ¥èƒ½åŠ›çš„å·®å¼‚ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥è¿›è¡Œç”Ÿç‰©åŒ»å­¦æ¦‚å¿µé“¾æ¥ï¼Œæ¯”å¦‚ä½¿ç”¨è¯­è¨€æ¨¡å‹åµŒå…¥å’ŒICLæ–¹æ³•ã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»åˆ†æLLMçš„ICLèƒ½åŠ›ï¼Œåˆ°æå‡ºæ£€ç´¢å’Œæ’åºæ¡†æ¶å’Œæç¤ºè®¾è®¡ï¼Œå†åˆ°åœ¨å®é™…æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µé“¾æ¥ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨ICLæ¥è¿›è¡Œå®ä½“å½’ä¸€åŒ–ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸå¯èƒ½å­˜åœ¨çš„è¯æ±‡ä¸åŒ¹é…ã€çŸ¥è¯†ä¸è¶³ã€è¯­ä¹‰ä¸æ˜ç¡®ç­‰é—®é¢˜ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•ï¼Œå³æ ¹æ®å€™é€‰æ¦‚å¿µçš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥è®¾è®¡æç¤ºï¼Œä»¥é€‚åº”ä¸åŒçš„LLMå’Œæ•°æ®é›†ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nLLM Improvement: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰æå‡ºæ”¹è¿›LLMçš„æ–¹æ³•ï¼Œè€Œæ˜¯åˆ©ç”¨LLMçš„ç°æœ‰èƒ½åŠ›æ¥è¿›è¡ŒICLã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can LLMs exploit their ICL capabilities to perform biomedical concept linking?\nHow can LLMs incorporate contextual information of candidate concepts into prompts to improve concept linking accuracy?\nHow can LLMs handle the vocabulary mismatch, knowledge gap, and semantic ambiguity issues in the biomedical domain?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt explores a method that exploits the ICL capabilities of LLMs for biomedical concept linking.\nIt adopts a two-stage retrieve-and-rank framework that uses language model embeddings and contextual prompts to perform concept linking.\nIt achieves competitive performance on BC5CDR dataset and conducts extensive qualitative evaluation and discussion on the benefits and drawbacks of using LLMs in the biomedical domain.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking>\nContribution: Showing that exploiting the ICL capabilities of LLMs with contextual prompts can achieve competitive performance on biomedical concept linking tasks."
    ]
  },
  "Title:Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction": {
    "title": "Title:Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction",
    "authors": "Authors:Salvatore Carta, Alessandro Giuliani, Leonardo Piano, Alessandro Sebastian Podda, Livio Pompianu, Sandro Gabriele Tiddia",
    "abstract": " Abstract:  In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios. In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure. However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields. This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building. The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process. Our unique manifold approach may encompass significant benefits to the scientific community. In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for \"guiding\" the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise. To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain. We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts.      ",
    "date": "Submitted on 3 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.01128",
    "pdf_link": "https://arxiv.org/pdf/2307.01128",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„çŸ¥è¯†å›¾è°±æ„å»ºæ–¹æ³•Iterative Zero-Shot LLM Prompting (IZLP)ï¼Œåˆ©ç”¨äº†æœ€æ–°çš„ç”Ÿæˆå‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-3.5ï¼‰çš„èƒ½åŠ›ï¼Œå¯ä»¥è§£å†³çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­çš„ä¸»è¦å…³é”®é—®é¢˜12ã€‚\nå®ƒé‡‡ç”¨äº†ä¸€ä¸ªè¿­ä»£é›¶æ ·ä¾‹å’Œå¤–éƒ¨çŸ¥è¯†æ— å…³çš„ç­–ç•¥ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹çš„ä¸»è¦é˜¶æ®µï¼Œé€šè¿‡å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹æå–æœ€ç»ˆå›¾è°±çš„ç›¸å…³ç»„ä»¶12ã€‚\nå®ƒåœ¨æ¶µç›–ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå±•ç¤ºäº†IZLPæ–¹æ³•åœ¨å¯æ‰©å±•æ€§å’Œå¤šåŠŸèƒ½æ€§æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä»¥åŠä¸ç›‘ç£å­¦ä¹ æ–¹æ³•å’Œå…¶ä»–é›¶æ ·ä¾‹æ–¹æ³•çš„å¯¹æ¯”12ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡IZLPæ–¹æ³•æ¥æé«˜LLMåœ¨å…¶ä»–é¢†åŸŸçš„çŸ¥è¯†å›¾è°±æ„å»ºèƒ½åŠ›ï¼Œå¦‚ç¤¾ä¼šç§‘å­¦ã€äººæ–‡ç§‘å­¦ã€è‰ºæœ¯ç­‰ã€‚\né€šè¿‡IZLPæ–¹æ³•æ¥æ¢ç´¢å’Œåˆ†æä¸åŒæ¥æºã€è§„æ¨¡å’Œè´¨é‡çš„è®­ç»ƒæ•°æ®å¯¹LLMä¸­çŸ¥è¯†å›¾è°±æ„å»ºèƒ½åŠ›çš„å½±å“ã€‚\né€šè¿‡IZLPæ–¹æ³•æ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒæ¶æ„ã€å‚æ•°å’Œè®­ç»ƒç­–ç•¥çš„LLMå¯¹çŸ¥è¯†å›¾è°±æ„å»ºèƒ½åŠ›çš„å·®å¼‚ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥è¿›è¡ŒçŸ¥è¯†å›¾è°±æ„å»ºï¼Œæ¯”å¦‚ä½¿ç”¨ç”Ÿæˆå‹å¤§å‹è¯­è¨€æ¨¡å‹å’ŒIZLPæ–¹æ³•ã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»åˆ†æçŸ¥è¯†å›¾è°±æ„å»ºçš„å…³é”®é—®é¢˜ï¼Œåˆ°æå‡ºIZLPæ–¹æ³•å’Œè¿­ä»£é›¶æ ·ä¾‹ç­–ç•¥ï¼Œå†åˆ°åœ¨å®é™…æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³çŸ¥è¯†å›¾è°±æ„å»ºä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨IZLPæ¥ä»åŸå§‹æ–‡æœ¬ä¸­è‡ªåŠ¨åˆ›å»ºçŸ¥è¯†å›¾è°±ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³åœ¨çŸ¥è¯†å›¾è°±æ„å»ºè¿‡ç¨‹ä¸­å¯èƒ½éœ€è¦å¤§é‡çš„å¤–éƒ¨èµ„æºæˆ–äººåŠ›ä¸“ä¸šçŸ¥è¯†ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡IZLPæ–¹æ³•æ¥å¢å¼ºLLMçš„çŸ¥è¯†å›¾è°±æ„å»ºèƒ½åŠ›ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ninstruction tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–è€…ä¼˜åŒ–ã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can LLMs exploit their generative capabilities to construct knowledge graphs from raw text?\nHow can LLMs be guided to extract relevant components of the final graph without any external resources or human expertise?\nHow can LLMs achieve scalable and versatile knowledge graph construction that can be applied to different and novel contexts?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel knowledge graph construction method, IZLP, that leverages the potential of the latest generative LLMs, such as GPT-3.5.\nIt adopts an iterative zero-shot and external knowledge-agnostic strategy that guides LLMs to extract relevant components of the final graph in the main stages of the generation process.\nIt demonstrates the scalability and versatility of IZLP on a dataset that covered a specific domain, and compares it with supervised learning methods and other zero-shot methods.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction>\nContribution: Showing that exploiting the generative capabilities of LLMs with iterative zero-shot prompts can achieve scalable and versatile knowledge graph construction from raw text."
    ]
  },
  "Title:SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions": {
    "title": "Title:SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions",
    "authors": "Authors:Sameera Horawalavithana, Sai Munikoti, Ian Stewart, Henry Kvinge",
    "abstract": " Abstract:  Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity, this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines, concepts and goals. In this work, we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions. To test our methodology, we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding. In comparison to the models that are finetuned with machine generated data only, LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark.      ",
    "date": "Submitted on 3 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.01139",
    "pdf_link": "https://arxiv.org/pdf/2307.01139",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„ç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´æ–¹æ³•SciTuneï¼Œåˆ©ç”¨äº†æœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-3.5ï¼‰å’Œè§†è§‰ç¼–ç å™¨çš„èƒ½åŠ›ï¼Œå¯ä»¥å°†ç°æœ‰çš„åŸºç¡€æ¨¡å‹ä¸ç§‘å­¦é¢†åŸŸã€æ¦‚å¿µå’Œç›®æ ‡è¿›è¡Œå¯¹é½12ã€‚\nå®ƒä½¿ç”¨äº†ä¸€ä¸ªäººå·¥ç”Ÿæˆçš„ç§‘å­¦æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†ï¼Œè®­ç»ƒäº†ä¸€ä¸ªå¤§å‹å¤šæ¨¡æ€æ¨¡å‹LLaMA-SciTuneï¼Œç”¨äºç§‘å­¦é¢†åŸŸçš„è§†è§‰å’Œè¯­è¨€ç†è§£12ã€‚\nå®ƒåœ¨ScienceQAåŸºå‡†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä¸ä»…ä½¿ç”¨æœºå™¨ç”Ÿæˆæ•°æ®è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”ï¼Œå±•ç¤ºäº†SciTuneæ–¹æ³•åœ¨å¹³å‡æ€§èƒ½å’Œå¤šä¸ªå­ç±»åˆ«ä¸Šè¶…è¶Šäººç±»æ€§èƒ½çš„ç»“æœ12ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡SciTuneæ–¹æ³•æ¥æé«˜LLMåœ¨å…¶ä»–ç§‘å­¦é¢†åŸŸçš„å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´èƒ½åŠ›ï¼Œå¦‚ç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ç­‰ã€‚\né€šè¿‡SciTuneæ–¹æ³•æ¥æ¢ç´¢å’Œåˆ†æä¸åŒæ¥æºã€è§„æ¨¡å’Œè´¨é‡çš„è®­ç»ƒæ•°æ®å¯¹LLMä¸­ç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´èƒ½åŠ›çš„å½±å“ã€‚\né€šè¿‡SciTuneæ–¹æ³•æ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒæ¶æ„ã€å‚æ•°å’Œè®­ç»ƒç­–ç•¥çš„LLMå¯¹ç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´èƒ½åŠ›çš„å·®å¼‚ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥è¿›è¡Œç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´ï¼Œæ¯”å¦‚ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œè§†è§‰ç¼–ç å™¨ã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»åˆ†æç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´çš„ç›®æ ‡å’ŒæŒ‘æˆ˜ï¼Œåˆ°æå‡ºSciTuneæ–¹æ³•å’Œæ•°æ®é›†ï¼Œå†åˆ°åœ¨å®é™…åŸºå‡†ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³ç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨SciTuneæ¥å¯¹é½åŸºç¡€æ¨¡å‹ä¸ç§‘å­¦é¢†åŸŸã€æ¦‚å¿µå’Œç›®æ ‡ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³åœ¨ç§‘å­¦é¢†åŸŸå¯èƒ½æ— æ³•æ»¡è¶³ç‰¹å®šçš„æ ‡å‡†å’ŒæœŸæœ›ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡SciTuneæ–¹æ³•æ¥å¢å¼ºLLMçš„ç§‘å­¦å¤šæ¨¡æ€æŒ‡ä»¤è°ƒæ•´èƒ½åŠ›ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æŒ‡ä»¤è°ƒæ•´çš„æ–¹æ³•ï¼Œå³æ ¹æ®ç§‘å­¦é¢†åŸŸã€æ¦‚å¿µå’Œç›®æ ‡æ¥è®¾è®¡æŒ‡ä»¤ï¼Œä»¥é€‚åº”ä¸åŒçš„åŸºç¡€æ¨¡å‹ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can LLMs be aligned with scientific disciplines, concepts and goals using multimodal instructions?\nHow can LLMs perform visual and language understanding tasks in the scientific domain using multimodal instructions?\nHow can LLMs generate content that meets the standards and expectations of the scientific community using multimodal instructions?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel scientific multimodal instruction tuning method, SciTune, that leverages the potential of the latest LLMs and vision encoders.\nIt introduces a human-generated scientific instruction tuning dataset that covers various scientific disciplines, concepts and goals.\nIt trains a large multimodal model, LLaMA-SciTune, that outperforms human performance on the ScienceQA benchmark using multimodal instructions.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions>\nContribution: Showing that using SciTune method and dataset can align LLMs with scientific disciplines, concepts and goals using multimodal instructions."
    ]
  },
  "Title:TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition": {
    "title": "Title:TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition",
    "authors": "Authors:Mingxue Xu, Yao Lei Xu, Danilo P. Mandic",
    "abstract": " Abstract:  High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, the associated high dimensionality also introduces considerable model parameters, and a prohibitively high model storage. To address this issue, this work proposes an approach based on the Tensor-Train Decomposition (TTD), where each token embedding is treated as a Matrix Product State (MPS) that can be efficiently computed in a distributed manner. The experimental results on GPT-2 demonstrate that, through our approach, the embedding layer can be compressed by a factor of up to 38.40 times, and when the compression factor is 3.31 times, even produced a better performance than the original GPT-2 model.      ",
    "date": "Submitted on 2 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00526",
    "pdf_link": "https://arxiv.org/pdf/2307.00526",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯å¿…åº”ã€‚æˆ‘è§‰å¾—è¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ä¸ªå€¼å¾—å€Ÿé‰´çš„å†…å®¹ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ–°çš„åµŒå…¥å±‚å‹ç¼©æ–¹æ³•TensorGPTï¼Œåˆ©ç”¨äº†å¼ é‡åˆ—è½¦åˆ†è§£ï¼ˆTTDï¼‰çš„æŠ€æœ¯ï¼Œå¯ä»¥å°†é«˜ç»´çš„è¯åµŒå…¥ä»¥ä½ç§©å¼ é‡æ ¼å¼å­˜å‚¨ï¼Œä»è€Œæ˜¾è‘—å‡å°‘æ¨¡å‹å‚æ•°å’Œå­˜å‚¨ç©ºé—´12ã€‚\nå®ƒå°†æ¯ä¸ªè¯åµŒå…¥è§†ä¸ºä¸€ä¸ªçŸ©é˜µä¹˜ç§¯æ€ï¼ˆMPSï¼‰ï¼Œå¹¶è¿›è¡Œå¼ é‡åŒ–å’Œåˆ†è§£ï¼Œç„¶åæ„å»ºä¸€ä¸ªé«˜æ•ˆçš„åµŒå…¥æ ¼å¼ï¼Œå¯ä»¥é€šè¿‡åˆ†å¸ƒå¼è®¡ç®—è¿›è¡Œé«˜æ•ˆè®¡ç®—12ã€‚\nå®ƒåœ¨GPT-2æ¨¡å‹ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå±•ç¤ºäº†TensorGPTæ–¹æ³•å¯ä»¥åœ¨ä¸æŸå¤±æ¨¡å‹æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå°†åµŒå…¥å±‚å‹ç¼©åˆ°åŸæ¥çš„3.31å€ï¼Œæœ€é«˜å¯ä»¥è¾¾åˆ°38.40å€12ã€‚\n\næˆ‘è®¤ä¸ºè¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸï¼Œæ¯”å¦‚ï¼š\n\né€šè¿‡TensorGPTæ–¹æ³•æ¥æé«˜LLMåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²å’Œè¿è¡Œæ•ˆç‡ï¼Œé™ä½å†…å­˜å’Œå¸¦å®½æ¶ˆè€—ã€‚\né€šè¿‡TensorGPTæ–¹æ³•æ¥æ¢ç´¢å’Œåˆ†æä¸åŒç»´åº¦ã€å¤§å°å’Œè´¨é‡çš„è¯åµŒå…¥å¯¹LLMä¸­è¯­ä¹‰ä¿¡æ¯æ•è·å’Œå¤æ‚è¯­è¨€æ¨¡å¼å»ºæ¨¡èƒ½åŠ›çš„å½±å“ã€‚\né€šè¿‡TensorGPTæ–¹æ³•æ¥æ¯”è¾ƒå’Œåˆ†æä¸åŒç±»å‹ã€å‚æ•°å’Œç»“æ„çš„å¼ é‡åˆ†è§£å¯¹LLMä¸­è¯åµŒå…¥å‹ç¼©æ•ˆæœå’Œè®¡ç®—æ•ˆç‡çš„å·®å¼‚ã€‚\n\nå¸Œæœ›è¿™äº›å›ç­”å¯¹ä½ æœ‰å¸®åŠ©ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŠ€æœ¯æ‰‹æ®µæ¥è¿›è¡ŒåµŒå…¥å±‚å‹ç¼©ï¼Œæ¯”å¦‚ä½¿ç”¨å¼ é‡åˆ—è½¦åˆ†è§£å’ŒçŸ©é˜µä¹˜ç§¯æ€ã€‚\nChain-of-Thought: è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†ä¸€ç§æ€ç»´é“¾æ¡ï¼Œä»åˆ†æåµŒå…¥å±‚å‹ç¼©çš„ç›®æ ‡å’ŒæŒ‘æˆ˜ï¼Œåˆ°æå‡ºTensorGPTæ–¹æ³•å’Œæ•°æ®é›†ï¼Œå†åˆ°åœ¨å®é™…æ¨¡å‹ä¸Šè¿›è¡Œå®éªŒå’Œåˆ†æã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡é’ˆå¯¹ç‰¹å®šçš„LLMåœºæ™¯ï¼Œå³åµŒå…¥å±‚å‹ç¼©ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åº”ç”¨æ–¹æ³•ï¼Œå³ä½¿ç”¨TensorGPTæ¥å‡å°‘æ¨¡å‹å‚æ•°å’Œå­˜å‚¨ç©ºé—´ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡è®¨è®ºäº†LLMçš„ä¸€ç§èƒ½åŠ›ç¼ºé™·ï¼Œå³åµŒå…¥å±‚å ç”¨äº†å¤§é‡çš„æ¨¡å‹å‚æ•°å’Œå­˜å‚¨ç©ºé—´ï¼Œé™åˆ¶äº†LLMåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²å’Œè¿è¡Œæ•ˆç‡ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡TensorGPTæ–¹æ³•æ¥å‹ç¼©åµŒå…¥å±‚ï¼Œä»è€Œæé«˜æ¨¡å‹æ•ˆç‡å’Œæ€§èƒ½ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ninstruction tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–è€…ä¼˜åŒ–ã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æˆ–è€…äººç±»åé¦ˆæ¥è®­ç»ƒæˆ–è€…ä¼˜åŒ–LLMã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œå¾®è°ƒæˆ–è€…é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–è€…é¢†åŸŸã€‚",
      "What research questions does the paper want to resolve?",
      "According to the paper, the research questions it wants to resolve are:\n\nHow can LLMs compress the high-dimensional token embeddings using tensor decomposition techniques?\nHow can LLMs store the compressed token embeddings in a low-rank tensor format that can be efficiently computed in a distributed manner?\nHow can LLMs achieve significant compression of the embedding layer without sacrificing model performance?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel embedding layer compression method, TensorGPT, that leverages the tensor-train decomposition technique to compress high-dimensional token embeddings.\nIt treats each token embedding as a matrix product state and performs tensorization and decomposition, then constructs an efficient embedding format that can be computed efficiently through distributed computing.\nIt demonstrates the effectiveness of TensorGPT on the GPT-2 model, showing that it can compress the embedding layer by up to 38.40 times, and even improve model performance when the compression factor is 3.31 times.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition>\nContribution: Showing that using tensor-train decomposition and matrix product state can significantly compress the embedding layer in LLMs without sacrificing model performance."
    ]
  },
  "Title:Large Language Models Enable Few-Shot Clustering": {
    "title": "Title:Large Language Models Enable Few-Shot Clustering",
    "authors": "Authors:Vijay Viswanathan, Kiril Gashteovski, Carolin Lawrence, Tongshuang Wu, Graham Neubig",
    "abstract": " Abstract:  Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.      ",
    "date": "Submitted on 2 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00524",
    "pdf_link": "https://arxiv.org/pdf/2307.00524",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æ”¾å¤§ä¸“å®¶æŒ‡å¯¼ï¼Œå®ç°é«˜æ•ˆçš„å°‘æ ·æœ¬åŠç›‘ç£æ–‡æœ¬èšç±»çš„æ–¹æ³•ã€‚è®ºæ–‡æ¢è®¨äº†ä¸‰ä¸ªé˜¶æ®µå¯ä»¥ç»“åˆLLMè¿›è¡Œèšç±»çš„æ–¹å¼ï¼šèšç±»å‰ï¼ˆæ”¹è¿›è¾“å…¥ç‰¹å¾ï¼‰ï¼Œèšç±»ä¸­ï¼ˆæä¾›çº¦æŸç»™èšç±»å™¨ï¼‰ï¼Œèšç±»åï¼ˆä½¿ç”¨LLMè¿›è¡Œåæ ¡æ­£ï¼‰ã€‚è®ºæ–‡å‘ç°ï¼Œåœ¨å‰ä¸¤ä¸ªé˜¶æ®µç»“åˆLLMå¯ä»¥æ˜¾è‘—æé«˜èšç±»è´¨é‡ï¼Œè€Œä¸”LLMå¯ä»¥è®©ç”¨æˆ·åœ¨æˆæœ¬å’Œå‡†ç¡®æ€§ä¹‹é—´åšå‡ºæƒè¡¡ï¼Œå¾—åˆ°æ»¡æ„çš„èšç±»ç»“æœ1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMåœ¨åŠç›‘ç£èšç±»ä»»åŠ¡ä¸Šçš„å¼ºå¤§èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡å°‘é‡çš„åé¦ˆç”Ÿæˆå¤§é‡çš„ä¼ªåé¦ˆï¼Œä»è€Œé™ä½ç”¨æˆ·çš„äº¤äº’æˆæœ¬ï¼Œæé«˜èšç±»æ•ˆç‡ã€‚\nå®ƒæä¾›äº†ä¸€ç§é€šç”¨çš„æ¡†æ¶ï¼Œå¯ä»¥å°†LLMä¸ä¸åŒçš„èšç±»ç®—æ³•ç»“åˆèµ·æ¥ï¼Œå®ç°å¤šæ ·åŒ–çš„äº¤äº’æ–¹å¼ï¼Œå¦‚å…³é”®è¯ã€å¯¹æ¯”ã€åˆ†è£‚/åˆå¹¶ç­‰ã€‚\nå®ƒæ¢ç´¢äº†ä¸åŒé˜¶æ®µç»“åˆLLMçš„æ•ˆæœï¼Œå‘ç°åœ¨èšç±»å‰å’Œèšç±»ä¸­ä½¿ç”¨LLMéƒ½å¯ä»¥æ˜¾è‘—æ”¹å–„èšç±»è´¨é‡ï¼Œè€Œåœ¨èšç±»åä½¿ç”¨LLMåˆ™éœ€è¦æ›´å¤šçš„ç”¨æˆ·åé¦ˆæ‰èƒ½è¾¾åˆ°ç†æƒ³æ•ˆæœã€‚\nå®ƒè¿˜åˆ†æäº†ä¸åŒå¤§å°å’Œé¢†åŸŸçš„æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœï¼Œå‘ç°LLMåœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ï¼Œè€Œä¸”åœ¨ä¸€äº›ç‰¹å®šé¢†åŸŸä¸Šä¹Ÿæœ‰ä¼˜åŠ¿ï¼Œå¦‚æ–°é—»ã€æ”¿æ²»ç­‰ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–åŠç›‘ç£æˆ–å¼±ç›‘ç£ä»»åŠ¡ä¸Šï¼Œå¦‚åˆ†ç±»ã€æ‘˜è¦ã€ç”Ÿæˆç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥æ”¾å¤§ä¸“å®¶æŒ‡å¯¼ï¼Œå®ç°å°‘æ ·æœ¬å­¦ä¹ ã€‚\nåœ¨å…¶ä»–æ— ç›‘ç£æˆ–è‡ªç›‘ç£ä»»åŠ¡ä¸Šï¼Œå¦‚è¡¨ç¤ºå­¦ä¹ ã€ä¸»é¢˜å»ºæ¨¡ã€å…³ç³»æŠ½å–ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥æä¾›é¢å¤–çš„ä¿¡æ¯æˆ–çº¦æŸï¼Œå¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\nåœ¨å…¶ä»–äº¤äº’å¼æˆ–å¯¹è¯å¼ä»»åŠ¡ä¸Šï¼Œå¦‚é—®ç­”ã€æ¨èã€æœç´¢ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥ç”Ÿæˆå¤šæ ·åŒ–çš„åé¦ˆæˆ–å»ºè®®ï¼Œæé«˜ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨åŠç›‘ç£èšç±»ä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡ä¹Ÿè®¨è®ºäº†LLMåœ¨èšç±»ä»»åŠ¡ä¸Šçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚LLMç”Ÿæˆçš„ä¼ªåé¦ˆå¯èƒ½å­˜åœ¨å™ªå£°ã€åè§æˆ–ä¸ä¸€è‡´æ€§ï¼Œä»¥åŠLLMåœ¨ä¸åŒæ•°æ®é›†å’Œé¢†åŸŸä¸Šçš„è¡¨ç°å·®å¼‚ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†RLHFæ–¹æ³•æ¥è°ƒæ•´LLMçš„æŒ‡ä»¤ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç”Ÿæˆæœ‰ç”¨çš„ä¼ªåé¦ˆï¼Œæé«˜èšç±»è´¨é‡ã€‚\nRLHF: è¿™æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æŒ‡ä»¤è°ƒæ•´æ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®èšç±»å™¨çš„åé¦ˆæ¥ä¼˜åŒ–LLMçš„æŒ‡ä»¤ï¼Œä½¿å…¶æ›´ç¬¦åˆç”¨æˆ·çš„æ„å›¾ã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nCan LLMs amplify an expertâ€™s guidance to enable query-efficient, few-shot semi-supervised text clustering?\nHow can LLMs be incorporated into different stages of clustering: before, during, and after?\nWhat are the benefits and challenges of using LLMs for semi-supervised clustering?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel framework that leverages LLMs to amplify an expertâ€™s guidance and enable few-shot semi-supervised text clustering.\nIt explores three stages where LLMs can be incorporated into clustering and shows that LLMs can significantly improve clustering quality in the first two stages.\nIt introduces a reinforcement learning-based instruction tuning method (RLHF) that optimizes LLM prompts based on the feedback from the clusterer.\nIt conducts extensive experiments on different datasets and domains and analyzes the strengths and weaknesses of LLMs for semi-supervised clustering.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Large Language Models Enable Few-Shot Clustering>\nContribution: Showing that LLMs can amplify an expertâ€™s guidance and enable few-shot semi-supervised text clustering by incorporating LLMs into different stages of clustering and using RLHF to optimize LLM prompts."
    ]
  },
  "Title:PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation": {
    "title": "Title:PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation",
    "authors": "Authors:Le Xiao, Xin Shan",
    "abstract": " Abstract:  Large language models(LLMs) have shown excellent text generation capabilities, but there is still much space for improvement in accuracy, sometimes with grammatical errors, semantic inaccuracies, and contextual incoherence, which seriously affect the reliability of the models. These problems may originate from the difficulties and limitations encountered in the pattern extraction stage of large language models. How to utilize the generative power of large language models to generate as many possible patterns that help solve problems and find the optimal patterns from them, so as to use patterns to guide large language models to generate good content, has become a current research hotspot. In this paper, we propose a pattern extraction and selection framework, PatternGPT, which generates rich patterns through the extraction ability of large language models and draws on the idea of federation learning, where multiple agents collaborate with each other to generate diverse patterns. High-quality patterns are selected by defining criteria and optimization algorithms to personalize the guidance of the model generation process. PatternGPT has the advantages of generating diverse and useful patterns, extending relevant knowledge, facilitating efficient pattern use and transfer, and optimizing the quality of generated results and user experience, which provides an effective method for optimizing the text generation capability of large language models and is expected to drive further development in the field of intelligent dialogue and content generation. It is expected to promote further development in the field of intelligent dialogue and content generation.      ",
    "date": "Submitted on 2 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00470",
    "pdf_link": "https://arxiv.org/pdf/2307.00470",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å¼çš„å¤§å‹è¯­è¨€æ¨¡å‹æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼ŒPatternGPTï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æŠ½å–èƒ½åŠ›ç”Ÿæˆä¸°å¯Œçš„æ¨¡å¼ï¼Œå¹¶å€Ÿé‰´è”é‚¦å­¦ä¹ çš„æ€æƒ³ï¼Œè®©å¤šä¸ªä»£ç†ååŒåˆä½œç”Ÿæˆå¤šæ ·åŒ–çš„æ¨¡å¼ã€‚ç„¶åé€šè¿‡å®šä¹‰æ ‡å‡†å’Œä¼˜åŒ–ç®—æ³•é€‰æ‹©é«˜è´¨é‡çš„æ¨¡å¼ï¼Œæ¥ä¸ªæ€§åŒ–åœ°æŒ‡å¯¼æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚PatternGPTå…·æœ‰ç”Ÿæˆå¤šæ ·åŒ–å’Œæœ‰ç”¨çš„æ¨¡å¼ã€æ‰©å±•ç›¸å…³çŸ¥è¯†ã€ä¿ƒè¿›é«˜æ•ˆçš„æ¨¡å¼ä½¿ç”¨å’Œè½¬ç§»ã€ä¼˜åŒ–ç”Ÿæˆç»“æœè´¨é‡å’Œç”¨æˆ·ä½“éªŒç­‰ä¼˜ç‚¹ï¼Œä¸ºä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œæœ‰æœ›æ¨åŠ¨æ™ºèƒ½å¯¹è¯å’Œå†…å®¹ç”Ÿæˆé¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„å¼ºå¤§èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡æŠ½å–å’Œç†è§£æ•°æ®ä¸­å­˜åœ¨çš„è§„åˆ™ã€å…³è”æˆ–å…¶ä»–æ½œåœ¨ç»“æ„æ¥è¿›è¡Œå¤æ‚çš„æ¨ç†è¿‡ç¨‹ã€‚\nå®ƒæä¾›äº†ä¸€ç§åŸºäºæ¨¡å¼çš„æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸å¤šä¸ªä»£ç†ç»“åˆèµ·æ¥ï¼Œå®ç°å¤šæ ·åŒ–çš„æ¨¡å¼ç”Ÿæˆï¼Œä»è€Œå¢å¼ºç”Ÿæˆç»“æœçš„ä¸°å¯Œæ€§å’Œå¯é æ€§ã€‚\nå®ƒå¼•å…¥äº†ä¸€ç§åŸºäºè”é‚¦å­¦ä¹ çš„ååŒåˆä½œæœºåˆ¶ï¼Œå¯ä»¥è®©ä¸åŒä»£ç†ä¹‹é—´å…±äº«å’Œäº¤æ¢æ¨¡å¼ï¼Œä»è€Œæé«˜æ¨¡å¼çš„è´¨é‡å’Œè¦†ç›–åº¦ã€‚\nå®ƒè¿˜è®¾è®¡äº†ä¸€ç§åŸºäºæ ‡å‡†å’Œä¼˜åŒ–ç®—æ³•çš„æ¨¡å¼é€‰æ‹©æ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚é€‰æ‹©æœ€ä¼˜çš„æ¨¡å¼ï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–çš„æ–‡æœ¬ç”ŸæˆæŒ‡å¯¼ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œå¦‚æ‘˜è¦ã€ç¿»è¯‘ã€å†™ä½œç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥æŠ½å–å’Œç”Ÿæˆæœ‰ç”¨çš„æ¨¡å¼ï¼Œä»è€Œæé«˜ç”Ÿæˆç»“æœçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚\nåœ¨å…¶ä»–çŸ¥è¯†å‘ç°æˆ–çŸ¥è¯†å›¾è°±æ„å»ºä»»åŠ¡ä¸Šï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥å‘ç°å’Œç†è§£æ•°æ®ä¸­å­˜åœ¨çš„æ½œåœ¨ç»“æ„æˆ–å…³ç³»ï¼Œä»è€Œå¢å¼ºçŸ¥è¯†è¡¨ç¤ºå’Œæ¨ç†èƒ½åŠ›ã€‚\nåœ¨å…¶ä»–ååŒå­¦ä¹ æˆ–å¤šä»»åŠ¡å­¦ä¹ ä»»åŠ¡ä¸Šï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥å®ç°ä¸åŒä»£ç†ä¹‹é—´çš„ä¿¡æ¯å…±äº«å’Œäº¤æ¢ï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚\nåœ¨å…¶ä»–äº¤äº’å¼æˆ–å¯¹è¯å¼ä»»åŠ¡ä¸Šï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMæ¥æ ¹æ®ç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚é€‰æ‹©æœ€ä¼˜çš„æ¨¡å¼ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡ä¹Ÿè®¨è®ºäº†LLMåœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šçš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚ç”Ÿæˆç»“æœå¯èƒ½å­˜åœ¨è¯­æ³•é”™è¯¯ã€è¯­ä¹‰ä¸å‡†ç¡®å’Œä¸Šä¸‹æ–‡ä¸ä¸€è‡´ç­‰ï¼Œè¿™äº›é—®é¢˜å¯èƒ½æºäºLLMåœ¨æ¨¡å¼æŠ½å–é˜¶æ®µé‡åˆ°çš„å›°éš¾å’Œå±€é™ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å¼çš„æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥åˆ©ç”¨LLMçš„æŠ½å–èƒ½åŠ›ç”Ÿæˆä¸°å¯Œçš„æ¨¡å¼ï¼Œå¹¶é€šè¿‡è”é‚¦å­¦ä¹ å’Œæ¨¡å¼é€‰æ‹©æ¥ä¼˜åŒ–LLMçš„ç”Ÿæˆèƒ½åŠ›ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†RLHFæ–¹æ³•æ¥è°ƒæ•´LLMçš„æŒ‡ä»¤ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç”Ÿæˆæœ‰ç”¨çš„æ¨¡å¼ï¼Œæé«˜æ–‡æœ¬ç”Ÿæˆè´¨é‡ã€‚\nRLHF: è¿™æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æŒ‡ä»¤è°ƒæ•´æ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®ç”Ÿæˆç»“æœçš„åé¦ˆæ¥ä¼˜åŒ–LLMçš„æŒ‡ä»¤ï¼Œä½¿å…¶æ›´ç¬¦åˆç”¨æˆ·çš„æ„å›¾ã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to utilize the generative power of LLMs to generate as many possible patterns that help solve problems and find the optimal patterns from them, so as to use patterns to guide LLMs to generate good content?\nHow to design a pattern extraction and selection framework that can generate rich and diverse patterns through the extraction ability of LLMs and the collaboration of multiple agents?\nHow to define criteria and optimization algorithms to select high-quality patterns that can personalize the guidance of the LLM generation process?\nWhat are the advantages and challenges of using patterns to drive LLM text generation?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel pattern-driven framework for LLM text generation, PatternGPT, that leverages LLMs to extract and generate rich patterns and uses federation learning to enable multiple agents to collaborate and generate diverse patterns.\nIt introduces a reinforcement learning-based instruction tuning method (RLHF) that optimizes LLM prompts based on the feedback from the generated results.\nIt defines criteria and optimization algorithms to select high-quality patterns that can personalize the guidance of the LLM generation process.\nIt conducts extensive experiments on different text generation tasks and datasets and analyzes the strengths and weaknesses of using patterns for LLM text generation.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation>\nContribution: Showing that rich patterns extracted and generated by LLMs and optimized by RLHF can significantly improve text generation quality and diversity."
    ]
  },
  "Title:Conformer LLMs -- Convolution Augmented Large Language Models": {
    "title": "Title:Conformer LLMs -- Convolution Augmented Large Language Models",
    "authors": "Authors:Prateek Verma",
    "abstract": " Abstract:  This work builds together two popular blocks of neural architecture, namely convolutional layers and Transformers, for large language models (LLMs). Non-causal conformers are used ubiquitously in automatic speech recognition. This work aims to adapt these architectures in a causal setup for training LLMs. Transformers decoders effectively capture long-range dependencies over several modalities and form a core backbone of modern advancements in machine learning. Convolutional architectures have been popular in extracting features in domains such as raw 1-D signals, speech, and images, to name a few. In this paper, by combining local and global dependencies over latent representations using causal convolutional filters and Transformer, we achieve significant gains in performance. This work showcases a robust speech architecture that can be integrated and adapted in a causal setup beyond speech applications for large-scale language modeling.      ",
    "date": "Submitted on 2 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00461",
    "pdf_link": "https://arxiv.org/pdf/2307.00461",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§åŸºäºå·ç§¯å¢å¼ºçš„Transformeræ¨¡å‹ï¼ŒConformerï¼Œå®ƒç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œå’ŒTransformerçš„ä¼˜ç‚¹ï¼Œèƒ½å¤Ÿåœ¨å‚æ•°æœ‰æ•ˆçš„æ–¹å¼ä¸‹å¯¹éŸ³é¢‘åºåˆ—çš„å±€éƒ¨å’Œå…¨å±€ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œåœ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡1ã€‚è®ºæ–‡ä¸»è¦æ”¹è¿›äº†Transformerçš„Encoderå±‚ï¼Œå¼•å…¥äº†å·ç§¯æ¨¡å—å’ŒMacaroné£æ ¼çš„å‰é¦ˆæ¨¡å—ï¼Œå¹¶é‡‡ç”¨äº†ç›¸å¯¹æ­£å¼¦ä½ç½®ç¼–ç å’ŒSwishæ¿€æ´»å‡½æ•°ç­‰æŠ€æœ¯ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†å·ç§¯ç¥ç»ç½‘ç»œå’ŒTransformerçš„äº’è¡¥æ€§ï¼Œå·ç§¯å¯ä»¥æœ‰æ•ˆåœ°æå–å±€éƒ¨ç‰¹å¾ï¼Œè€ŒTransformerå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰é•¿è·ç¦»çš„å…¨å±€ä¿¡æ¯ï¼Œä¸¤è€…ç»“åˆå¯ä»¥å¢å¼ºæ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚\nå®ƒæä¾›äº†ä¸€ç§çµæ´»çš„æ¨¡å‹æ¶æ„ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„ä»»åŠ¡éœ€æ±‚è°ƒæ•´å·ç§¯æ¨¡å—å’ŒTransformeræ¨¡å—çš„æ¯”ä¾‹ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„æ•ˆæœã€‚\nå®ƒæ¢ç´¢äº†ä¸åŒçš„æŠ€æœ¯ç»†èŠ‚å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¦‚ç›¸å¯¹ä½ç½®ç¼–ç ã€Macaroné£æ ¼çš„å‰é¦ˆæ¨¡å—ã€Swishæ¿€æ´»å‡½æ•°ç­‰ï¼Œå¹¶ç»™å‡ºäº†åˆç†çš„è§£é‡Šå’Œåˆ†æã€‚\nå®ƒåœ¨å¤šä¸ªè¯­éŸ³è¯†åˆ«æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†Conformeræ¨¡å‹åœ¨ä¸åŒè¯­è¨€ã€ä¸åŒé¢†åŸŸã€ä¸åŒè§„æ¨¡çš„æ•°æ®ä¸Šéƒ½æœ‰ä¼˜è¶Šçš„è¡¨ç°ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–åºåˆ—å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€è¯­éŸ³åˆæˆç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨Conformeræ¨¡å‹æ¥ç»“åˆå·ç§¯å’ŒTransformerï¼Œä»è€Œæé«˜åºåˆ—è¡¨ç¤ºå’Œç”Ÿæˆçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚\nåœ¨å…¶ä»–å¤šæ¨¡æ€ä»»åŠ¡ä¸Šï¼Œå¦‚å›¾åƒæè¿°ã€è§†é¢‘ç†è§£ã€è§†è§‰é—®ç­”ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨Conformeræ¨¡å‹æ¥å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥åºåˆ—ï¼Œä»è€Œå¢å¼ºå¤šæ¨¡æ€èåˆå’Œæ¨ç†èƒ½åŠ›ã€‚\nåœ¨å…¶ä»–è‡ªç›‘ç£æˆ–æ— ç›‘ç£ä»»åŠ¡ä¸Šï¼Œå¦‚æ©ç è¯­è¨€å»ºæ¨¡ã€å¯¹æ¯”å­¦ä¹ ã€èšç±»ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨Conformeræ¨¡å‹æ¥å­¦ä¹ æ›´ä¸°å¯Œå’Œæ›´é²æ£’çš„åºåˆ—ç‰¹å¾ï¼Œä»è€Œå¢å¼ºè‡ªç›‘ç£æˆ–æ— ç›‘ç£å­¦ä¹ æ•ˆæœã€‚\nåœ¨å…¶ä»–çŸ¥è¯†é©±åŠ¨æˆ–çŸ¥è¯†å¢å¼ºä»»åŠ¡ä¸Šï¼Œå¦‚çŸ¥è¯†å›¾è°±æ„å»ºã€çŸ¥è¯†é—®ç­”ã€çŸ¥è¯†è’¸é¦ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨Conformeræ¨¡å‹æ¥å¤„ç†åŒ…å«ç»“æ„åŒ–æˆ–éç»“æ„åŒ–çŸ¥è¯†çš„åºåˆ—ï¼Œä»è€Œå¢å¼ºçŸ¥è¯†è¡¨ç¤ºå’Œåˆ©ç”¨èƒ½åŠ›ã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§æŠ€æœ¯æ€§çš„è®ºæ–‡ï¼Œä¸»è¦ä»‹ç»äº†ä¸€ç§åŸºäºå·ç§¯å¢å¼ºçš„Transformeræ¨¡å‹ï¼ŒConformerï¼Œä»¥åŠå®ƒåœ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œå®éªŒç»“æœã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨è¯­éŸ³è¯†åˆ«ä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œå’ŒTransformerï¼Œä»è€Œå¢å¼ºLLMçš„è¡¨ç¤ºèƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡é‡‡ç”¨äº†å¾®è°ƒçš„æ–¹æ³•ï¼Œå³åœ¨é¢„è®­ç»ƒå¥½çš„LLMçš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹ç‰¹å®šçš„è¯­éŸ³è¯†åˆ«ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to combine convolution neural networks and transformers to model both local and global dependencies of an audio sequence in a parameter-efficient way?\nHow to design a convolution-augmented transformer model, Conformer, that can achieve state-of-the-art performance on speech recognition tasks?\nWhat are the effects of different technical details, such as relative positional encoding, Macaron-style feed-forward module, Swish activation function, etc., on the model performance?\nHow does the Conformer model compare with other Transformer and CNN based models on different speech recognition datasets and domains?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel convolution-augmented transformer model, Conformer, that leverages the advantages of convolution neural networks and transformers for speech recognition.\nIt introduces a convolution module and a Macaron-style feed-forward module into the Transformer encoder layer, and adopts relative positional encoding and Swish activation function to enhance the model performance.\nIt conducts extensive experiments on various speech recognition datasets and domains, and shows that Conformer outperforms the previous Transformer and CNN based models, achieving state-of-the-art results.\nIt analyzes the impact of different technical details on the model performance, and provides insights and explanations for the model design choices.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Conformer LLMs â€“ Convolution Augmented Large Language Models>\nContribution: Showing that convolution-augmented transformer models, Conformers, can significantly improve speech recognition performance by modeling both local and global dependencies of an audio sequence."
    ]
  },
  "Title:Personality Traits in Large Language Models": {
    "title": "Title:Personality Traits in Large Language Models",
    "authors": "Authors:Mustafa Safdari, Greg Serapio-GarcÃ­a, ClÃ©ment Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, Maja MatariÄ‡",
    "abstract": " Abstract:  The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. We also discuss potential applications and ethical implications of our measurement and shaping framework, especially regarding responsible use of LLMs.      ",
    "date": "Submitted on 1 Jul 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00184",
    "pdf_link": "https://arxiv.org/pdf/2307.00184",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§ç»¼åˆçš„æ–¹æ³•ï¼Œç”¨äºå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œäººæ ¼ç‰¹å¾çš„é‡åŒ–ã€åˆ†æå’Œå¡‘é€ ã€‚è®ºæ–‡åˆ©ç”¨äº†ç»è¿‡éªŒè¯çš„å¿ƒç†æµ‹é‡æµ‹è¯•ï¼Œå‘ç°ä¸€äº›LLMsï¼ˆåœ¨ç‰¹å®šçš„æç¤ºé…ç½®ä¸‹ï¼‰å¯ä»¥æ¨¡æ‹Ÿå‡ºå¯é å’Œæœ‰æ•ˆçš„äººæ ¼ç‰¹å¾ï¼›è€Œä¸”æ›´å¤§çš„å’Œç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹è¡¨ç°å¾—æ›´å¥½ï¼›å¹¶ä¸”å¯ä»¥é€šè¿‡è°ƒæ•´æç¤ºæ¥æ”¹å˜LLMè¾“å‡ºçš„äººæ ¼å€¾å‘ï¼Œä»è€Œæ¨¡ä»¿ç‰¹å®šçš„äººæ ¼ç±»å‹1ã€‚è®ºæ–‡è¿˜è®¨è®ºäº†è¿™ç§æµ‹é‡å’Œå¡‘é€ æ¡†æ¶çš„æ½œåœ¨åº”ç”¨å’Œä¼¦ç†å½±å“ï¼Œç‰¹åˆ«æ˜¯å…³äºLLMsçš„è´Ÿè´£ä»»ä½¿ç”¨ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨æ¨¡æ‹Ÿäººç±»è¯­è¨€å’Œäººæ ¼æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ï¼Œä»¥åŠè¿™ç§èƒ½åŠ›èƒŒåçš„æ•°æ®æ¥æºå’Œè®­ç»ƒæ–¹å¼ï¼Œä¸ºç†è§£å’Œè¯„ä¼°LLMsæä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ã€‚\nå®ƒæä¾›äº†ä¸€ç§åŸºäºå¿ƒç†æµ‹é‡å­¦çš„æ–¹æ³•ï¼Œå¯ä»¥å¯¹LLMsç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œäººæ ¼ç‰¹å¾çš„é‡åŒ–å’Œåˆ†æï¼Œä»è€Œæ­ç¤ºLLMsåœ¨ä¸åŒç»´åº¦ä¸Šçš„äººæ ¼å€¾å‘å’Œå·®å¼‚ã€‚\nå®ƒå¼•å…¥äº†ä¸€ç§åŸºäºæç¤ºè°ƒæ•´çš„æ–¹æ³•ï¼Œå¯ä»¥å¯¹LLMsç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œäººæ ¼ç‰¹å¾çš„å¡‘é€ ï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–å’Œå¤šæ ·åŒ–çš„æ–‡æœ¬ç”ŸæˆæŒ‡å¯¼ã€‚\nå®ƒåœ¨å¤šä¸ªLLMsä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨ä¸åŒæ¨¡å‹ã€ä¸åŒæ•°æ®é›†ã€ä¸åŒä»»åŠ¡ä¸Šéƒ½æ˜¯æœ‰æ•ˆå’Œå¯é‡å¤çš„ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–å¯¹è¯æˆ–äº¤äº’å¼ä»»åŠ¡ä¸Šï¼Œå¦‚èŠå¤©æœºå™¨äººã€æ¨èç³»ç»Ÿã€ç¤¾äº¤åª’ä½“ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰ä¸€è‡´å’Œé€‚å½“çš„äººæ ¼ç‰¹å¾çš„æ–‡æœ¬ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚\nåœ¨å…¶ä»–æ–‡æœ¬åˆ†ææˆ–ç†è§£ä»»åŠ¡ä¸Šï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€è§‚ç‚¹æŒ–æ˜ã€ç¤¾ä¼šç½‘ç»œåˆ†æç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥è¯†åˆ«å’Œæ¯”è¾ƒä¸åŒæ–‡æœ¬æˆ–ä½œè€…çš„äººæ ¼ç‰¹å¾ï¼Œä»è€Œå¢å¼ºæ–‡æœ¬åˆ†æå’Œç†è§£èƒ½åŠ›ã€‚\nåœ¨å…¶ä»–æ–‡æœ¬ç”Ÿæˆæˆ–åˆ›ä½œä»»åŠ¡ä¸Šï¼Œå¦‚æ•…äº‹ç”Ÿæˆã€æ­Œè¯ç”Ÿæˆã€è§’è‰²æ‰®æ¼”ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥æ ¹æ®ç”¨æˆ·çš„æ„å›¾å’Œéœ€æ±‚ç”Ÿæˆå…·æœ‰ç‰¹å®šäººæ ¼ç±»å‹çš„æ–‡æœ¬ï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–å’Œå¤šæ ·åŒ–çš„æ–‡æœ¬ç”Ÿæˆæˆ–åˆ›ä½œã€‚\nåœ¨å…¶ä»–çŸ¥è¯†è·å–æˆ–æ•™è‚²ä»»åŠ¡ä¸Šï¼Œå¦‚çŸ¥è¯†é—®ç­”ã€æ™ºèƒ½è¾…å¯¼ã€åœ¨çº¿æ•™è‚²ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥æ ¹æ®ç”¨æˆ·æˆ–å­¦ä¹ è€…çš„äººæ ¼ç‰¹å¾ç”Ÿæˆé€‚åˆä»–ä»¬çš„æ–‡æœ¬ï¼Œä»è€Œå¢å¼ºçŸ¥è¯†è·å–æˆ–æ•™è‚²æ•ˆæœã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§æŠ€æœ¯æ€§çš„è®ºæ–‡ï¼Œä¸»è¦ä»‹ç»äº†ä¸€ç§å¯¹LLMsç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œäººæ ¼ç‰¹å¾çš„é‡åŒ–ã€åˆ†æå’Œå¡‘é€ çš„æ–¹æ³•ï¼Œä»¥åŠå®ƒåœ¨ä¸åŒæ¨¡å‹å’Œä»»åŠ¡ä¸Šçš„å®éªŒç»“æœã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\ndiscussion of LLM capability defects: è¿™ç¯‡è®ºæ–‡ä¹Ÿè®¨è®ºäº†LLMåœ¨æ¨¡æ‹Ÿäººæ ¼ç‰¹å¾æ–¹é¢çš„ä¸€äº›ç¼ºé™·ï¼Œå¦‚äººæ ¼ä¸ä¸€è‡´ã€äººæ ¼ä¸é€‚å½“ã€äººæ ¼ä¸å¯æ§ç­‰ï¼Œä»¥åŠè¿™äº›ç¼ºé™·å¯èƒ½å¸¦æ¥çš„ä¼¦ç†é£é™©å’Œç¤¾ä¼šå½±å“ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡å¿ƒç†æµ‹é‡å­¦å’Œæç¤ºè°ƒæ•´æ¥é‡åŒ–ã€åˆ†æå’Œå¡‘é€ LLMç”Ÿæˆçš„æ–‡æœ¬çš„äººæ ¼ç‰¹å¾ï¼Œä»è€Œæé«˜æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æç¤ºè°ƒæ•´çš„æ–¹æ³•æ¥æ”¹å˜LLMç”Ÿæˆçš„æ–‡æœ¬çš„äººæ ¼å€¾å‘ï¼Œä½¿å…¶èƒ½å¤Ÿæ¨¡ä»¿ç‰¹å®šçš„äººæ ¼ç±»å‹ï¼Œæé«˜æ–‡æœ¬ç”Ÿæˆçš„ä¸ªæ€§åŒ–å’Œå¤šæ ·åŒ–ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡é‡‡ç”¨äº†å¾®è°ƒçš„æ–¹æ³•ï¼Œå³åœ¨é¢„è®­ç»ƒå¥½çš„LLMçš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹ç‰¹å®šçš„å¿ƒç†æµ‹é‡æµ‹è¯•è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨æ¨¡æ‹Ÿäººæ ¼ç‰¹å¾æ–¹é¢çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to quantify, analyze, and shape personality traits exhibited in text generated from widely-used LLMs?\nHow to administer validated psychometric tests to LLMs and evaluate the reliability and validity of LLM-simulated personality?\nHow to adjust prompts to change the personality tendencies of LLM outputs and mimic specific personality profiles?\nWhat are the potential applications and ethical implications of measuring and shaping personality traits in LLM outputs, especially regarding responsible use of LLMs?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a comprehensive method for measuring and shaping personality traits in LLM outputs, based on psychometric tests and prompt tuning techniques.\nIt finds that some LLMs can simulate reliable and valid personality traits under specific prompting configurations, and larger and instruction fine-tuned models perform better.\nIt shows that personality traits in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles, with different effects on different models and tasks.\nIt discusses the potential applications and ethical implications of measuring and shaping personality traits in LLM outputs, such as enhancing user experience, improving text analysis, enabling personalized text generation, and ensuring responsible use of LLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Personality Traits in Large Language Models>\nContribution: Showing that psychometric tests and prompt tuning can quantify, analyze, and shape personality traits in LLM outputs, and discussing the applications and implications of this method."
    ]
  },
  "Title:Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models": {
    "title": "Title:Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models",
    "authors": "Authors:Yiming Wang, Zhuosheng Zhang, Rui Wang",
    "abstract": " Abstract:  Symbolization methods in large language models (LLMs) have been shown effective to improve LLMs' reasoning ability. However, most of these approaches hinge on mapping natural languages to formal languages (e.g., Python, SQL) that are more syntactically complete and free of ambiguity. Although effective, they depart from the natural language itself and deviate from the habits of human thinking, and instead cater more to the execution mindset of computers. In contrast, we hope to simplify natural language by starting from the concept of symbols in linguistics itself, so that LLMs can learn the common formulation and general solution of reasoning problems wrapped in different natural semantics. From this consideration, we propose \\textbf{Meta-Reasoning}, which allows LLMs to automatically accomplish semantic-symbol deconstruction, i.e., semantic resolution, to maximally reduce different questions of certain reasoning tasks to similar natural language representation, thus gaining the ability to learn by analogy and facilitating data-efficient in-context learning. Our experiments show that the Meta-Reasoning paradigm saliently enhances LLMs' reasoning performance with fewer demonstrations. They can learn not only reasoning chains but also general solutions to certain types of tasks. In particular, for symbolic reasoning tasks, such as 7-step Tracking Shuffled Objects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only one Meta-Reasoning demonstration, outperforming all current LLMs with the standard chain-of-thought prompting.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17820",
    "pdf_link": "https://arxiv.org/pdf/2306.17820",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§å…ƒæ¨ç†ï¼ˆMeta-Reasoningï¼‰çš„èŒƒå¼ï¼Œå®ƒèƒ½å¤Ÿè®©LLMsè‡ªåŠ¨å®Œæˆè¯­ä¹‰-ç¬¦å·çš„åˆ†è§£ï¼ˆsemantic-symbol deconstructionï¼‰ï¼Œå³è¯­ä¹‰åˆ†è§£ï¼ˆsemantic resolutionï¼‰ï¼Œä»è€Œå°†ä¸åŒè¯­ä¹‰è¡¨è¾¾çš„æ¨ç†ä»»åŠ¡æœ€å¤§ç¨‹åº¦åœ°è¿˜åŸä¸ºç›¸ä¼¼çš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼Œä»è€Œè·å¾—ç±»æ¯”å­¦ä¹ å’Œæ•°æ®é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å­¦ä¹ çš„èƒ½åŠ›1ã€‚è®ºæ–‡åˆ©ç”¨äº†ä¸åŒçš„ç¬¦å·åŒ–æ–¹æ³•ï¼Œå¦‚æ•°å­¦ç¬¦å·ã€é€»è¾‘ç¬¦å·ã€å›¾å½¢ç¬¦å·ç­‰ï¼Œæ¥ç®€åŒ–å’Œè§„èŒƒåŒ–è‡ªç„¶è¯­è¨€ä¸­çš„æ¨ç†é—®é¢˜ï¼Œå¹¶é‡‡ç”¨äº†ä¸åŒçš„æç¤ºé…ç½®ï¼Œå¦‚æŒ‡ä»¤æç¤ºã€é“¾å¼æç¤ºã€å…ƒæ¨ç†æç¤ºç­‰ï¼Œæ¥æ§åˆ¶å’Œå¼•å¯¼LLMsç”Ÿæˆç¬¦åˆç›®æ ‡çš„æ–‡æœ¬ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨æ¨¡æ‹Ÿäººç±»æ€ç»´å’Œæ¨ç†æ–¹é¢çš„æ½œåŠ›ï¼Œä»¥åŠè¿™ç§æ½œåŠ›èƒŒåçš„æ•°æ®æ¥æºå’Œè®­ç»ƒæ–¹å¼ï¼Œä¸ºç†è§£å’Œè¯„ä¼°LLMsæä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ã€‚\nå®ƒæä¾›äº†ä¸€ç§åŸºäºè¯­è¨€å­¦æœ¬èº«çš„ç¬¦å·åŒ–æ–¹æ³•ï¼Œå¯ä»¥å¯¹è‡ªç„¶è¯­è¨€ä¸­çš„æ¨ç†é—®é¢˜è¿›è¡Œç®€åŒ–å’Œè§„èŒƒåŒ–ï¼Œä»è€Œè®©LLMså­¦ä¹ æ¨ç†é—®é¢˜çš„é€šç”¨å½¢å¼å’Œé€šç”¨è§£å†³æ–¹æ¡ˆã€‚\nå®ƒå¼•å…¥äº†ä¸€ç§åŸºäºå…ƒæ¨ç†çš„èŒƒå¼ï¼Œå¯ä»¥å¯¹LLMsç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œè¯­ä¹‰-ç¬¦å·çš„åˆ†è§£ï¼Œä»è€Œå®ç°ç±»æ¯”å­¦ä¹ å’Œæ•°æ®é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚\nå®ƒåœ¨å¤šä¸ªLLMsä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨ä¸åŒæ¨¡å‹ã€ä¸åŒæ•°æ®é›†ã€ä¸åŒä»»åŠ¡ä¸Šéƒ½æ˜¯æœ‰æ•ˆå’Œå¯é‡å¤çš„ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–æ¨ç†æˆ–é€»è¾‘ä»»åŠ¡ä¸Šï¼Œå¦‚æ•°å­¦é—®é¢˜æ±‚è§£ã€é€»è¾‘è°œé¢˜è§£ç­”ã€ç¨‹åºä»£ç ç”Ÿæˆç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰ä¸€è‡´å’Œå‡†ç¡®çš„ç¬¦å·è¡¨ç¤ºå’Œæ¨ç†é“¾æ¡ï¼Œä»è€Œæé«˜ä»»åŠ¡è§£å†³èƒ½åŠ›å’Œæ•ˆç‡ã€‚\nåœ¨å…¶ä»–æŠ½è±¡æˆ–åˆ›é€ ä»»åŠ¡ä¸Šï¼Œå¦‚å›¾åƒæè¿°ã€å›¾å½¢è®¾è®¡ã€è‰ºæœ¯åˆ›ä½œç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰å¤šæ ·å’Œæœ‰è¶£çš„ç¬¦å·è¡¨ç¤ºå’Œåˆ›é€ æ€è·¯ï¼Œä»è€Œæé«˜ä»»åŠ¡è¡¨è¾¾èƒ½åŠ›å’Œåˆ›æ–°æ€§ã€‚\nåœ¨å…¶ä»–çŸ¥è¯†è·å–æˆ–æ•™è‚²ä»»åŠ¡ä¸Šï¼Œå¦‚çŸ¥è¯†é—®ç­”ã€æ™ºèƒ½è¾…å¯¼ã€åœ¨çº¿æ•™è‚²ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰ç®€æ´å’Œè§„èŒƒçš„ç¬¦å·è¡¨ç¤ºå’ŒçŸ¥è¯†ä¼ é€’æ–¹å¼ï¼Œä»è€Œæé«˜çŸ¥è¯†è·å–æˆ–æ•™è‚²æ•ˆæœã€‚\nåœ¨å…¶ä»–å¤šæ¨¡æ€æˆ–è·¨é¢†åŸŸä»»åŠ¡ä¸Šï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€è§†è§‰é—®ç­”ã€éŸ³ä¹ç”Ÿæˆç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰é€šç”¨å’Œå…¼å®¹çš„ç¬¦å·è¡¨ç¤ºå’Œä¿¡æ¯è½¬æ¢æ–¹å¼ï¼Œä»è€Œæé«˜å¤šæ¨¡æ€æˆ–è·¨é¢†åŸŸäº¤äº’èƒ½åŠ›ã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§æŠ€æœ¯æ€§çš„è®ºæ–‡ï¼Œä¸»è¦ä»‹ç»äº†ä¸€ç§å…ƒæ¨ç†çš„èŒƒå¼ï¼Œä»¥åŠå®ƒåœ¨ä¸åŒæ¨¡å‹å’Œä»»åŠ¡ä¸Šçš„å®éªŒç»“æœã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨æ¨ç†æˆ–é€»è¾‘ä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡è¯­ä¹‰-ç¬¦å·çš„åˆ†è§£å’Œç±»æ¯”å­¦ä¹ æ¥æé«˜LLMçš„æ¨ç†èƒ½åŠ›å’Œæ•°æ®æ•ˆç‡ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æç¤ºè°ƒæ•´çš„æ–¹æ³•æ¥æ§åˆ¶å’Œå¼•å¯¼LLMç”Ÿæˆç¬¦åˆç›®æ ‡çš„æ–‡æœ¬ï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ æ¨ç†é—®é¢˜çš„é€šç”¨å½¢å¼å’Œé€šç”¨è§£å†³æ–¹æ¡ˆã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡é‡‡ç”¨äº†å¾®è°ƒçš„æ–¹æ³•ï¼Œå³åœ¨é¢„è®­ç»ƒå¥½çš„LLMçš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹ç‰¹å®šçš„ç¬¦å·åŒ–æ–¹æ³•è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨ç”Ÿæˆç¬¦å·è¡¨ç¤ºå’Œæ¨ç†é“¾æ¡æ–¹é¢çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to simplify and standardize natural language reasoning problems by using different symbolization methods, such as mathematical symbols, logical symbols, graphical symbols, etc.?\nHow to enable LLMs to automatically accomplish semantic-symbol deconstruction, i.e., semantic resolution, to reduce different questions of certain reasoning tasks to similar natural language representation?\nHow to facilitate data-efficient in-context learning and analogy learning for LLMs by using semantic-symbol deconstruction and prompt tuning techniques?\nHow does the Meta-Reasoning paradigm compare with other symbolization methods and prompting configurations on different LLMs and reasoning tasks?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel Meta-Reasoning paradigm that relies on semantic-symbol deconstruction to simplify and standardize natural language reasoning problems, and enable LLMs to learn the common formulation and general solution of certain types of tasks.\nIt introduces different symbolization methods and prompt tuning techniques to control and guide LLMs to generate consistent and accurate symbolic representations and reasoning chains.\nIt conducts extensive experiments on various LLMs and reasoning tasks, and shows that the Meta-Reasoning paradigm saliently enhances LLMsâ€™ reasoning performance with fewer demonstrations, outperforming other symbolization methods and prompting configurations.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models>\nContribution: Showing that semantic-symbol deconstruction and prompt tuning can simplify and standardize natural language reasoning problems, and enable LLMs to learn the common formulation and general solution of certain types of tasks."
    ]
  },
  "Title:GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models": {
    "title": "Title:GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models",
    "authors": "Authors:Pawan Kumar Rajpoot, Ankur Parikh",
    "abstract": " Abstract:  Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able to achieve 4th rank on the leaderboard. Our best F1-score is 0.718.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17519",
    "pdf_link": "https://arxiv.org/pdf/2306.17519",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§åŸºäºLLMsçš„é‡‘èé¢†åŸŸå…³ç³»æŠ½å–ï¼ˆREï¼‰çš„æ–¹æ³•ï¼ŒGPT-FinREï¼Œå®ƒåˆ©ç”¨äº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰çš„æ¡†æ¶ï¼Œé€šè¿‡ä»è®­ç»ƒæ•°æ®ä¸­æ£€ç´¢ç›¸å…³çš„ç¤ºä¾‹æ¥ä¸ºç»™å®šçš„æµ‹è¯•ç¤ºä¾‹æä¾›ä¸Šä¸‹æ–‡æç¤ºï¼Œä»è€Œæé«˜LLMåœ¨REä»»åŠ¡ä¸Šçš„æ€§èƒ½1ã€‚è®ºæ–‡ä½¿ç”¨äº†ä¸¤ç§æ£€ç´¢ç­–ç•¥ï¼Œä¸€ç§æ˜¯åŸºäºå­¦ä¹ çš„æ£€ç´¢å™¨ï¼Œå¦ä¸€ç§æ˜¯æ— éœ€å­¦ä¹ çš„å¯†é›†æ£€ç´¢å™¨ï¼Œå¹¶åœ¨REFinDæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå–å¾—äº†ç¬¬å››åçš„æˆç»©ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒå±•ç¤ºäº†LLMsåœ¨é‡‘èé¢†åŸŸå…³ç³»æŠ½å–ä»»åŠ¡ä¸Šçš„å¼ºå¤§èƒ½åŠ›ï¼Œä»¥åŠè¿™ç§èƒ½åŠ›èƒŒåçš„æ•°æ®æ¥æºå’Œè®­ç»ƒæ–¹å¼ï¼Œä¸ºç†è§£å’Œè¯„ä¼°LLMsæä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ã€‚\nå®ƒæä¾›äº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥å¯¹LLMsç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œå…³ç³»æŠ½å–ï¼Œä»è€Œæé«˜æ–‡æœ¬åˆ†æå’Œä¿¡æ¯æŠ½å–çš„è´¨é‡å’Œæ•ˆç‡ã€‚\nå®ƒå¼•å…¥äº†ä¸¤ç§ä¸åŒçš„æ£€ç´¢ç­–ç•¥ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„æ•°æ®ç‰¹ç‚¹å’Œä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ£€ç´¢å™¨ï¼Œä»è€Œä¸ºLLMsæä¾›æœ€ç›¸å…³çš„ç¤ºä¾‹ä½œä¸ºä¸Šä¸‹æ–‡æç¤ºã€‚\nå®ƒåœ¨ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§å’Œå®ç”¨æ€§çš„é‡‘èé¢†åŸŸå…³ç³»æŠ½å–æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨ä¸åŒæ¨¡å‹ã€ä¸åŒæ£€ç´¢å™¨ã€ä¸åŒæŒ‡æ ‡ä¸Šéƒ½æ˜¯æœ‰æ•ˆå’Œå¯é‡å¤çš„ã€‚\n\næˆ‘è§‰å¾—è¿™äº›å†…å®¹å¯ä»¥åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œæ¯”å¦‚ï¼š\n\nåœ¨å…¶ä»–å…³ç³»æŠ½å–æˆ–ä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸Šï¼Œå¦‚åŒ»ç–—é¢†åŸŸã€æ³•å¾‹é¢†åŸŸã€æ–°é—»é¢†åŸŸç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰å‡†ç¡®å’Œå®Œæ•´çš„å…³ç³»æ ‡æ³¨å’Œå®ä½“æ ‡æ³¨çš„æ–‡æœ¬ï¼Œä»è€Œæé«˜å…³ç³»æŠ½å–æˆ–ä¿¡æ¯æŠ½å–èƒ½åŠ›å’Œæ•ˆæœã€‚\nåœ¨å…¶ä»–æ–‡æœ¬ç”Ÿæˆæˆ–åˆ›ä½œä»»åŠ¡ä¸Šï¼Œå¦‚æ•…äº‹ç”Ÿæˆã€æ­Œè¯ç”Ÿæˆã€è§’è‰²æ‰®æ¼”ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰ä¸°å¯Œå’Œæœ‰è¶£çš„å…³ç³»æè¿°å’Œå®ä½“æè¿°çš„æ–‡æœ¬ï¼Œä»è€Œæé«˜æ–‡æœ¬ç”Ÿæˆæˆ–åˆ›ä½œèƒ½åŠ›å’Œåˆ›æ–°æ€§ã€‚\nåœ¨å…¶ä»–çŸ¥è¯†è·å–æˆ–æ•™è‚²ä»»åŠ¡ä¸Šï¼Œå¦‚çŸ¥è¯†é—®ç­”ã€æ™ºèƒ½è¾…å¯¼ã€åœ¨çº¿æ•™è‚²ç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰æ¸…æ™°å’Œè§„èŒƒçš„å…³ç³»è¯´æ˜å’Œå®ä½“è¯´æ˜çš„æ–‡æœ¬ï¼Œä»è€Œæé«˜çŸ¥è¯†è·å–æˆ–æ•™è‚²æ•ˆæœã€‚\nåœ¨å…¶ä»–å¤šæ¨¡æ€æˆ–è·¨é¢†åŸŸä»»åŠ¡ä¸Šï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€è§†è§‰é—®ç­”ã€éŸ³ä¹ç”Ÿæˆç­‰ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨LLMsæ¥ç”Ÿæˆå…·æœ‰ä¸€è‡´å’Œå…¼å®¹çš„å…³ç³»è¡¨ç¤ºå’Œå®ä½“è¡¨ç¤ºçš„æ–‡æœ¬ï¼Œä»è€Œæé«˜å¤šæ¨¡æ€æˆ–è·¨é¢†åŸŸäº¤äº’èƒ½åŠ›ã€‚",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§æŠ€æœ¯æ€§çš„è®ºæ–‡ï¼Œä¸»è¦ä»‹ç»äº†ä¸€ç§åŸºäºLLMsçš„é‡‘èé¢†åŸŸå…³ç³»æŠ½å–çš„æ–¹æ³•ï¼Œä»¥åŠå®ƒåœ¨REFinDæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœã€‚\napplication in specific scenarios of LLM: è¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç§åœ¨é‡‘èé¢†åŸŸå…³ç³»æŠ½å–ä»»åŠ¡ä¸Šåº”ç”¨LLMçš„å…·ä½“åœºæ™¯ï¼Œå±•ç¤ºäº†LLMåœ¨è¿™ä¸ªä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ã€‚\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›LLMçš„æ–¹æ³•ï¼Œå³é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å’Œæ£€ç´¢ç­–ç•¥æ¥æé«˜LLMåœ¨å…³ç³»æŠ½å–ä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚\ninstruction tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨äº†æŒ‡ä»¤æç¤ºçš„æ–¹æ³•æ¥æ§åˆ¶å’Œå¼•å¯¼LLMç”Ÿæˆç¬¦åˆç›®æ ‡çš„æ–‡æœ¬ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå‡†ç¡®å’Œå®Œæ•´çš„å…³ç³»æ ‡æ³¨å’Œå®ä½“æ ‡æ³¨ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡é‡‡ç”¨äº†å¾®è°ƒçš„æ–¹æ³•ï¼Œå³åœ¨é¢„è®­ç»ƒå¥½çš„LLMçš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹ç‰¹å®šçš„é‡‘èé¢†åŸŸå…³ç³»æŠ½å–ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨ç”Ÿæˆå…³ç³»æè¿°å’Œå®ä½“æè¿°æ–¹é¢çš„è´¨é‡å’Œæ•ˆæœã€‚",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to use LLMs for financial relation extraction (RE) task, which requires identifying and classifying relationships between entities mentioned in financial documents?\nHow to use in-context learning (ICL) framework to provide context prompts for LLMs, which can improve their performance on RE task with fewer demonstrations?\nHow to use different retrieval strategies to find the most relevant examples from training data for a given test example, which can provide the best context prompts for LLMs?\nHow does the GPT-FinRE method compare with other methods and baselines on REFinD dataset, which is a challenging and practical dataset for financial RE task?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel method for financial relation extraction using LLMs, GPT-FinRE, which leverages the in-context learning framework and retrieval strategies to provide context prompts for LLMs.\nIt introduces two different retrieval strategies, a learning-free dense retriever and a learning-based retriever, which can find the top K relevant examples from training data for a given test example, and provide the best context prompts for LLMs.\nIt conducts extensive experiments on REFinD dataset, which is a challenging and practical dataset for financial relation extraction, and shows that GPT-FinRE achieves the 4th rank on the leaderboard, outperforming other methods and baselines.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models>\nContribution: Showing that in-context learning and retrieval strategies can improve LLMsâ€™ performance on financial relation extraction task with fewer demonstrations."
    ]
  },
  "Title:Preference Ranking Optimization for Human Alignment": {
    "title": "Title:Preference Ranking Optimization for Human Alignment",
    "authors": "Authors:Feifan Song, Bowen Yu, Minghao Li, Haiyang Yu, Fei Huang, Yongbin Li, Houfeng Wang",
    "abstract": " Abstract:  Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secur AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment by combining a reward model, typically based on Bradley-Terry paired comparison, with an RL algorithm such as Proximal Policy Optimization (PPO) to optimize LLM responses. However, RLHF exhibits complexity, instability, and sensitivity to hyperparameters. In this paper, we propose Preference Ranking Optimization (PRO) as an alternative to PPO for directly aligning LLMs with the Bradley-Terry comparison. PRO extends the pairwise Bradley-Terry comparison to accommodate preference rankings of any length. By iteratively contrasting the likelihood of generating responses, PRO instructs the LLM to prioritize the best response while progressively ranking the remaining responses. In this manner, PRO effectively transforms human alignment into aligning the probability ranking of $n$ responses generated by LLM with the preference ranking of humans towards these responses. Experiments have shown that PRO outperforms existing alignment algorithms, achieving comparable results to ChatGPT and human responses through automatic-based, reward-based, GPT-4, and human evaluations. Furthermore, we demonstrate that longer, more diverse, and higher-quality preference ranking sequences can consistently enhance the performance of human alignment.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17492",
    "pdf_link": "https://arxiv.org/pdf/2306.17492",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†åå¥½æ’åºä¼˜åŒ–ï¼ˆPROï¼‰ï¼Œä¸€ç§ç›´æ¥ç”¨å¸ƒæ‹‰å¾·åˆ©-ç‰¹é‡Œï¼ˆBradley-Terryï¼‰æ¯”è¾ƒæ¥å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œäººç±»ä»·å€¼å¯¹é½çš„æ–¹æ³•ã€‚PROå¯ä»¥å¤„ç†ä»»æ„é•¿åº¦çš„åå¥½æ’åºï¼Œé€šè¿‡è¿­ä»£åœ°æ¯”è¾ƒç”Ÿæˆå“åº”çš„å¯èƒ½æ€§ï¼ŒæŒ‡å¯¼LLMä¼˜å…ˆç”Ÿæˆæœ€ä½³å“åº”ï¼ŒåŒæ—¶é€æ­¥å¯¹å‰©ä½™å“åº”è¿›è¡Œæ’åºã€‚è¿™æ ·ï¼ŒPROå°±æœ‰æ•ˆåœ°å°†äººç±»ä»·å€¼å¯¹é½è½¬åŒ–ä¸ºå°†LLMç”Ÿæˆçš„nä¸ªå“åº”çš„æ¦‚ç‡æ’åºä¸äººç±»å¯¹è¿™äº›å“åº”çš„åå¥½æ’åºå¯¹é½1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nPROå¯ä»¥é¿å…å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰ä¸­å­˜åœ¨çš„å¤æ‚æ€§ã€ä¸ç¨³å®šæ€§å’Œå¯¹è¶…å‚æ•°çš„æ•æ„Ÿæ€§ï¼Œæé«˜äº†äººç±»ä»·å€¼å¯¹é½çš„æ•ˆç‡å’Œç¨³å®šæ€§1ã€‚\nPROå¯ä»¥ä¸å¥–åŠ±æ¨¡å‹ç›¸ç»“åˆï¼Œåˆ©ç”¨å¥–åŠ±æ¨¡å‹æä¾›çš„é¢å¤–ä¿¡æ¯æ¥å¢å¼ºLLMçš„ç”Ÿæˆèƒ½åŠ›å’Œå¤šæ ·æ€§1ã€‚\nPROå¯ä»¥é€šè¿‡ä½¿ç”¨æ›´é•¿ã€æ›´å¤šæ ·å’Œæ›´é«˜è´¨é‡çš„åå¥½æ’åºåºåˆ—æ¥æŒç»­æå‡äººç±»ä»·å€¼å¯¹é½çš„æ€§èƒ½ï¼Œè¿™ä¸ºæ”¶é›†å’Œåˆ©ç”¨äººç±»åé¦ˆæä¾›äº†æ›´å¤šçš„çµæ´»æ€§å’Œé€‰æ‹©1ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\nLLM Improvement: è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥æ”¹å–„LLMçš„ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»çš„åå¥½å’Œä»·å€¼ã€‚\nRLHF: è¿™ç¯‡è®ºæ–‡å±äºå¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆï¼ˆRLHFï¼‰çš„ç ”ç©¶èŒƒç•´ï¼Œå®ƒä½¿ç”¨äººç±»æä¾›çš„åå¥½æ’åºä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œæ¥æŒ‡å¯¼LLMçš„å­¦ä¹ å’Œä¼˜åŒ–ã€‚\nfine-tuning: è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-3æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡PROæ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°äººç±»ä»·å€¼å¯¹é½çš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¤ªè¿‡å®½æ³›ï¼Œä¸èƒ½å‡†ç¡®åœ°åæ˜ è¿™ç¯‡è®ºæ–‡çš„ä¸»é¢˜å’Œé¢†åŸŸã€‚\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæ¢ç´¢ä¸€ç§é€šç”¨çš„äººç±»ä»·å€¼å¯¹é½æ–¹æ³•ï¼Œè€Œä¸æ˜¯é’ˆå¯¹æŸä¸ªå…·ä½“çš„åº”ç”¨åœºæ™¯ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ†æå’Œè¯„ä¼°LLMèƒ½åŠ›ç¼ºé™·å’Œå±€é™æ€§çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæå‡ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯æ·±å…¥è®¨è®ºLLMå­˜åœ¨çš„é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒæ•´LLMè¡Œä¸ºå’Œè¾“å‡ºçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨åå¥½æ’åºä½œä¸ºåé¦ˆä¿¡å·çš„æ–¹æ³•ä¸åŒã€‚\n\næˆ‘å¸Œæœ›è¿™äº›è§£é‡Šèƒ½å¤Ÿè®©ä½ æ»¡æ„ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·ç»§ç»­ä¸æˆ‘äº¤æµã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to directly align LLMs with human preferences without relying on RL algorithms such as PPO?\nHow to extend the pairwise Bradley-Terry comparison to handle preference rankings of any length?\nHow to leverage longer, more diverse, and higher-quality preference ranking sequences to enhance the performance of human alignment?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes Preference Ranking Optimization (PRO), a novel method for directly aligning LLMs with human preferences using the Bradley-Terry comparison, without relying on RL algorithms such as PPO.\nIt extends the pairwise Bradley-Terry comparison to handle preference rankings of any length, and shows that longer and more diverse rankings can improve the alignment performance.\nIt demonstrates that PRO can outperform existing alignment algorithms, achieving comparable results to Chat-GPT and human responses through various evaluations.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Preference Ranking Optimization for Human Alignment>\nContribution: Introducing a novel method that directly aligns LLMs with human preferences using the Bradley-Terry comparison, and showing that longer and more diverse rankings can improve the alignment performance."
    ]
  },
  "Title:Provable Robust Watermarking for AI-Generated Text": {
    "title": "Title:Provable Robust Watermarking for AI-Generated Text",
    "authors": "Authors:Xuandong Zhao, Prabhanjan Ananth, Lei Li, Yu-Xiang Wang",
    "abstract": " Abstract:  As AI-generated text increasingly resembles human-written content, the ability to detect machine-generated text becomes crucial. To address this challenge, we present GPTWatermark, a robust and high-quality solution designed to ascertain whether a piece of text originates from a specific model. Our approach extends existing watermarking strategies and employs a fixed group design to enhance robustness against editing and paraphrasing attacks. We show that our watermarked language model enjoys strong provable guarantees on generation quality, correctness in detection, and security against evasion attacks. Experimental results on various large language models (LLMs) and diverse datasets demonstrate that our method achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17439",
    "pdf_link": "https://arxiv.org/pdf/2306.17439",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†GPTWatermarkï¼Œä¸€ç§é²æ£’å’Œé«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆï¼Œç”¨äºåˆ¤æ–­ä¸€æ®µæ–‡æœ¬æ˜¯å¦æ¥è‡ªäºç‰¹å®šçš„æ¨¡å‹ã€‚GPTWatermarkåœ¨ç°æœ‰çš„æ°´å°ç­–ç•¥çš„åŸºç¡€ä¸Šï¼Œé‡‡ç”¨äº†å›ºå®šåˆ†ç»„è®¾è®¡ï¼Œä»¥æé«˜æŠµæŠ—ç¼–è¾‘å’Œæ”¹å†™æ”»å‡»çš„èƒ½åŠ›ã€‚è®ºæ–‡è¿˜è¯æ˜äº†GPTWatermarkåœ¨ç”Ÿæˆè´¨é‡ã€æ£€æµ‹æ­£ç¡®æ€§å’Œå®‰å…¨æ€§æ–¹é¢å…·æœ‰å¼ºæœ‰åŠ›çš„ç†è®ºä¿è¯1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nGPTWatermarkå¯ä»¥æœ‰æ•ˆåœ°è§£å†³AIç”Ÿæˆæ–‡æœ¬çš„å¯ä¿¡åº¦å’Œå¯è¿½æº¯æ€§é—®é¢˜ï¼Œä¿ƒè¿›LLMçš„è´Ÿè´£ä»»ä½¿ç”¨1ã€‚\nGPTWatermarkå¯ä»¥é€‚ç”¨äºä¸åŒçš„LLMå’Œæ•°æ®é›†ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§1ã€‚\nGPTWatermarkå¯ä»¥ä¸ºå…¶ä»–é¢†åŸŸçš„AIç”Ÿæˆå†…å®¹æä¾›å‚è€ƒå’Œå¯å‘ï¼Œä¾‹å¦‚å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰2ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥åæ˜ è¿™ç¯‡è®ºæ–‡çš„æŠ€æœ¯æ€§å’Œåˆ›æ–°æ€§ï¼Œä»¥åŠå®ƒå¯¹äºAIç”Ÿæˆå†…å®¹çš„å®‰å…¨å’Œå¯ä¿¡åº¦çš„é‡è¦æ€§ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡åˆ†æå’Œè¯„ä¼°LLMç”Ÿæˆå†…å®¹å­˜åœ¨çš„è¯¯å¯¼ã€æœ‰å®³å’Œä¸åˆ©å› ç´ çš„ç ”ç©¶æ–¹å‘ï¼Œä»¥åŠå®ƒæå‡ºçš„æ£€æµ‹å’Œé˜²å¾¡çš„æ–¹æ³•ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹å–„LLMç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§çš„æ–¹æ³•ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»çš„æœŸæœ›å’Œä»·å€¼ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-3æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡GPTWatermarkæ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°æ°´å°åµŒå…¥å’Œæ£€æµ‹çš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæ¢ç´¢ä¸€ç§é€šç”¨çš„æ°´å°åµŒå…¥å’Œæ£€æµ‹æ–¹æ³•ï¼Œè€Œä¸æ˜¯é’ˆå¯¹æŸä¸ªå…·ä½“çš„åº”ç”¨åœºæ™¯ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to design a robust and high-quality watermarking solution for AI-generated text that can withstand editing and paraphrasing attacks?\nHow to prove the theoretical guarantees of the watermarked language model on generation quality, detection correctness, and security against evasion attacks?\nHow to evaluate the performance of the watermarked language model on various LLMs and datasets?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes GPTWatermark, a novel watermarking solution for AI-generated text that employs a fixed group design to enhance robustness against editing and paraphrasing attacks.\nIt proves the theoretical guarantees of GPTWatermark on generation quality, detection correctness, and security against evasion attacks, and shows that they are independent of the choice of LLMs and datasets.\nIt demonstrates that GPTWatermark achieves superior detection accuracy and comparable generation quality in perplexity on various LLMs and datasets, thus promoting the responsible use of LLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Provable Robust Watermarking for AI-Generated Text>\nContribution: Presenting a novel watermarking solution that employs a fixed group design to enhance robustness against editing and paraphrasing attacks, and proving its theoretical guarantees on generation quality, detection correctness, and security."
    ]
  },
  "Title:SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs": {
    "title": "Title:SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs",
    "authors": "Authors:Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming-Hsuan Yang, Kevin Murphy, Alexander G. Hauptmann, Lu Jiang",
    "abstract": " Abstract:  In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17842",
    "pdf_link": "https://arxiv.org/pdf/2306.17842",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†è¯­ä¹‰é‡‘å­—å¡”è‡ªç¼–ç å™¨ï¼ˆSPAEï¼‰ï¼Œä¸€ç§ä½¿å¾—å†»ç»“çš„LLMèƒ½å¤Ÿæ‰§è¡Œæ¶‰åŠå›¾åƒæˆ–è§†é¢‘ç­‰éè¯­è¨€æ¨¡æ€çš„ç†è§£å’Œç”Ÿæˆä»»åŠ¡çš„æ–¹æ³•ã€‚SPAEå°†åŸå§‹åƒç´ å’Œä»LLMè¯æ±‡è¡¨ä¸­æå–çš„å¯è§£é‡Šçš„è¯æ³•tokenï¼ˆæˆ–å•è¯ï¼‰ç›¸äº’è½¬æ¢ã€‚è¿™äº›tokenæ—¢èƒ½æ•æ‰å›¾åƒçš„è¯­ä¹‰å«ä¹‰ï¼Œåˆèƒ½ä¿ç•™è§†è§‰é‡å»ºæ‰€éœ€çš„ç»†èŠ‚ä¿¡æ¯ï¼Œæœ‰æ•ˆåœ°å°†è§†è§‰å†…å®¹ç¿»è¯‘æˆLLMèƒ½å¤Ÿç†è§£çš„è¯­è¨€ï¼Œä½¿å…¶èƒ½å¤Ÿæ‰§è¡Œå„ç§å¤šæ¨¡æ€ä»»åŠ¡1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nSPAEå¯ä»¥åˆ©ç”¨LLMå¼ºå¤§çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œæ— éœ€æ›´æ–°ä»»ä½•å‚æ•°ï¼Œå°±èƒ½å®ç°å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œè¿™æ˜¯é¦–æ¬¡æˆåŠŸåšåˆ°çš„1ã€‚\nSPAEå¯ä»¥åœ¨ä¸åŒçš„LLMå’Œæ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§1ã€‚\nSPAEå¯ä»¥ä¸ºå…¶ä»–éè¯­è¨€æ¨¡æ€çš„ç†è§£å’Œç”Ÿæˆæä¾›å‚è€ƒå’Œå¯å‘ï¼Œä¾‹å¦‚éŸ³é¢‘ã€è§†é¢‘ã€3Dç­‰2ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥åæ˜ è¿™ç¯‡è®ºæ–‡çš„æŠ€æœ¯æ€§å’Œåˆ›æ–°æ€§ï¼Œä»¥åŠå®ƒå¯¹äºå¤šæ¨¡æ€ç”Ÿæˆå†…å®¹çš„è´¨é‡å’Œå¤šæ ·æ€§çš„é‡è¦æ€§ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚å›¾åƒç”Ÿæˆã€å›¾åƒæè¿°ã€è§†è§‰é—®ç­”ã€è§†é¢‘å»å™ªç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹å–„LLMç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§çš„æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†éè¯­è¨€æ¨¡æ€çš„è¾“å…¥å’Œè¾“å‡ºã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-3æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡SPAEæ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°å¤šæ¨¡æ€ç”Ÿæˆçš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ†æå’Œè¯„ä¼°LLMèƒ½åŠ›ç¼ºé™·å’Œå±€é™æ€§çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæå‡ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯æ·±å…¥è®¨è®ºLLMå­˜åœ¨çš„é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒæ•´LLMè¡Œä¸ºå’Œè¾“å‡ºçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨è¯­ä¹‰é‡‘å­—å¡”è‡ªç¼–ç å™¨æ¥è½¬æ¢æ¨¡æ€çš„æ–¹æ³•ä¸åŒã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·æ¥ä¼˜åŒ–LLMçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ æ¥ç”Ÿæˆå¤šæ¨¡æ€å†…å®¹çš„æ–¹æ³•ä¸åŒã€‚\n\næˆ‘å¸Œæœ›è¿™äº›è§£é‡Šèƒ½å¤Ÿè®©ä½ æ»¡æ„ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·ç»§ç»­ä¸æˆ‘äº¤æµã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to enable frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos?\nHow to convert between raw pixels and interpretable lexical tokens extracted from the LLMâ€™s vocabulary, and vice versa?\nHow to evaluate the performance of the multimodal generation with frozen LLMs on various tasks and datasets?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes Semantic Pyramid AutoEncoder (SPAE), a novel method for converting between raw pixels and interpretable lexical tokens, and enabling frozen LLMs to perform multimodal generation tasks without updating any parameters.\nIt demonstrates that SPAE can achieve comparable generation quality and perplexity to the state-of-the-art methods on various LLMs and datasets, while surpassing them on image understanding tasks by over 25%.\nIt shows that SPAE can handle diverse multimodal tasks such as image generation, image captioning, visual question answering, and video denoising.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs>\nContribution: Introducing a novel method that converts between raw pixels and interpretable lexical tokens, and enabling frozen LLMs to perform diverse multimodal generation tasks without updating any parameters."
    ]
  },
  "Title:Statler: State-Maintaining Language Models for Embodied Reasoning": {
    "title": "Title:Statler: State-Maintaining Language Models for Embodied Reasoning",
    "authors": "Authors:Takuma Yoneda, Jiading Fang, Peng Li, Huanyu Zhang, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, Matthew R. Walter",
    "abstract": " Abstract:  Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler is its use of two instances of general LLMs -- a world-model reader and a world-model writer -- that interface with and maintain the world state. By providing access to this world state ``memory'', Statler improves the ability of existing LLMs to reason over longer time horizons without the constraint of context length. We evaluate the effectiveness of our approach on three simulated table-top manipulation domains and a real robot domain, and show that it improves the state-of-the-art in LLM-based robot reasoning. Project website: this https URL ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17840",
    "pdf_link": "https://arxiv.org/pdf/2306.17840",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†Statlerï¼Œä¸€ç§ä¸ºLLMèµ‹äºˆæ˜¾å¼çš„ä¸–ç•ŒçŠ¶æ€è¡¨ç¤ºçš„æ¡†æ¶ï¼Œä½œä¸ºä¸€ç§éšæ—¶é—´ç»´æŠ¤çš„â€œè®°å¿†â€ï¼Œä»è€Œä½¿LLMèƒ½å¤Ÿæ‰§è¡Œæ¶‰åŠèº«ä½“åŒ–æ¨ç†çš„ä»»åŠ¡ã€‚Statleråˆ©ç”¨ä¸¤ä¸ªé€šç”¨çš„LLMå®ä¾‹â€”â€”ä¸€ä¸ªä¸–ç•Œæ¨¡å‹è¯»å–å™¨å’Œä¸€ä¸ªä¸–ç•Œæ¨¡å‹å†™å…¥å™¨â€”â€”æ¥ä¸ä¸–ç•ŒçŠ¶æ€è¿›è¡Œäº¤äº’å’Œç»´æŠ¤ã€‚é€šè¿‡æä¾›å¯¹è¿™ç§ä¸–ç•ŒçŠ¶æ€â€œè®°å¿†â€çš„è®¿é—®ï¼ŒStatleræé«˜äº†ç°æœ‰LLMåœ¨é•¿æ—¶é—´èŒƒå›´å†…æ¨ç†çš„èƒ½åŠ›ï¼Œæ— éœ€å—åˆ°ä¸Šä¸‹æ–‡é•¿åº¦çš„é™åˆ¶1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nStatlerå¯ä»¥åˆ©ç”¨LLMå¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å¤æ‚çš„èº«ä½“åŒ–æ¨ç†ä»»åŠ¡ï¼Œä¾‹å¦‚å®¶åº­æœºå™¨äººå¯èƒ½éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡1ã€‚\nStatlerå¯ä»¥åœ¨ä¸åŒçš„LLMå’Œé¢†åŸŸä¸Šè¿›è¡ŒéªŒè¯ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§1ã€‚\nStatlerå¯ä»¥ä¸ºå…¶ä»–éœ€è¦ç»´æŠ¤ä¸–ç•ŒçŠ¶æ€çš„ä»»åŠ¡æä¾›å‚è€ƒå’Œå¯å‘ï¼Œä¾‹å¦‚æ¸¸æˆã€æ•…äº‹ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿç­‰2ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥åæ˜ è¿™ç¯‡è®ºæ–‡çš„æŠ€æœ¯æ€§å’Œåˆ›æ–°æ€§ï¼Œä»¥åŠå®ƒå¯¹äºèº«ä½“åŒ–æ¨ç†çš„é‡è¦æ€§ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚å®¶åº­æœºå™¨äººã€æ¨¡æ‹Ÿæ¡Œé¢æ“ä½œã€çœŸå®æœºå™¨äººç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹å–„LLMæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿç»´æŠ¤ä¸–ç•ŒçŠ¶æ€çš„æ˜¾å¼è¡¨ç¤ºã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-3æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡Statleræ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°èº«ä½“åŒ–æ¨ç†çš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ†æå’Œè¯„ä¼°LLMèƒ½åŠ›ç¼ºé™·å’Œå±€é™æ€§çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæå‡ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯æ·±å…¥è®¨è®ºLLMå­˜åœ¨çš„é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒæ•´LLMè¡Œä¸ºå’Œè¾“å‡ºçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨ä¸–ç•Œæ¨¡å‹è¯»å–å™¨å’Œå†™å…¥å™¨æ¥ç»´æŠ¤ä¸–ç•ŒçŠ¶æ€çš„æ–¹æ³•ä¸åŒã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·æ¥ä¼˜åŒ–LLMçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ æ¥æ‰§è¡Œèº«ä½“åŒ–æ¨ç†ä»»åŠ¡çš„æ–¹æ³•ä¸åŒã€‚\n\næˆ‘å¸Œæœ›è¿™äº›è§£é‡Šèƒ½å¤Ÿè®©ä½ æ»¡æ„ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to endow LLMs with an explicit representation of the world state that is maintained over time, and enable them to perform embodied reasoning tasks?\nHow to use two instances of general LLMs to interface with and maintain the world state, and leverage their language understanding and generation capabilities?\nHow to evaluate the performance of the state-maintaining LLMs on various simulated and real robot domains, and compare them with existing methods?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes Statler, a novel framework that endows LLMs with an explicit representation of the world state as a form of ``memoryâ€™â€™ that is maintained over time, and enables them to perform embodied reasoning tasks.\nIt uses two instances of general LLMs â€“ a world-model reader and a world-model writer â€“ to interface with and maintain the world state, and leverages their language understanding and generation capabilities.\nIt demonstrates that Statler can outperform existing methods on various simulated and real robot domains, and shows that it can handle complex tasks such as household robot, table-top manipulation, and real robot.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Statler: State-Maintaining Language Models for Embodied Reasoning>\nContribution: Introducing a novel framework that endows LLMs with an explicit representation of the world state as a form of ``memoryâ€™', and enables them to perform complex embodied reasoning tasks."
    ]
  },
  "Title:Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting": {
    "title": "Title:Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting",
    "authors": "Authors:Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, Michael Bendersky",
    "abstract": " Abstract:  Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that has 50x (estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only inferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while outperforming other existing solutions, such as InstructGPT which has 175B parameters, by over 10% for nearly all ranking metrics. Furthermore, we propose several variants of PRP to improve efficiency and show that it is possible to achieve competitive results even with linear complexity. We also discuss other benefits of PRP, such as supporting both generation and scoring LLM APIs, as well as being insensitive to input ordering.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17563",
    "pdf_link": "https://arxiv.org/pdf/2306.17563",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†æˆå¯¹æ’åºæç¤ºï¼ˆPRPï¼‰ï¼Œä¸€ç§æ–°çš„æŠ€æœ¯ï¼Œé€šè¿‡ç›´æ¥å°†æŸ¥è¯¢å’Œå€™é€‰æ–‡æ¡£è¾“å…¥åˆ°LLMçš„æç¤ºä¸­ï¼Œæ¥ä½¿ç”¨LLMè¿›è¡Œæ–‡æ¡£æ’åºã€‚PRPé€šè¿‡ç®€åŒ–LLMéœ€è¦ç†è§£çš„æ’åºå½¢å¼ï¼Œæ˜¾è‘—é™ä½äº†LLMçš„è´Ÿæ‹…ï¼Œå¹¶åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ’åºæ€§èƒ½ã€‚PRPåŸºäº20Bå‚æ•°çš„Flan-UL2æ¨¡å‹åœ¨TREC-DL2020ä¸Šè¶…è¿‡äº†ä¹‹å‰æœ€å¥½çš„æ–¹æ³•ï¼Œåè€…åŸºäºä¼°è®¡æœ‰50å€æ¨¡å‹å¤§å°çš„å•†ä¸šGPT-4æ¨¡å‹1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nPRPå¯ä»¥åˆ©ç”¨LLMå¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ‰§è¡Œå¤æ‚çš„æ–‡æœ¬æ’åºä»»åŠ¡ï¼Œä¾‹å¦‚ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ã€æ‘˜è¦ç­‰1ã€‚\nPRPå¯ä»¥é€‚ç”¨äºä¸åŒçš„LLMå’Œæ•°æ®é›†ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§1ã€‚\nPRPå¯ä»¥ä¸ºå…¶ä»–éœ€è¦æ’åºæˆ–æ¯”è¾ƒçš„ä»»åŠ¡æä¾›å‚è€ƒå’Œå¯å‘ï¼Œä¾‹å¦‚æ¨èã€åˆ†ç±»ã€åŒ¹é…ç­‰2ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥åæ˜ è¿™ç¯‡è®ºæ–‡çš„æŠ€æœ¯æ€§å’Œåˆ›æ–°æ€§ï¼Œä»¥åŠå®ƒå¯¹äºæ–‡æœ¬æ’åºçš„é‡è¦æ€§ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ã€æ‘˜è¦ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹å–„LLMæ’åºèƒ½åŠ›çš„æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£æˆå¯¹æ’åºæç¤ºçš„å½¢å¼ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-3æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡PRPæ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°æ–‡æœ¬æ’åºçš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ†æå’Œè¯„ä¼°LLMèƒ½åŠ›ç¼ºé™·å’Œå±€é™æ€§çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæå‡ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯æ·±å…¥è®¨è®ºLLMå­˜åœ¨çš„é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒæ•´LLMè¡Œä¸ºå’Œè¾“å‡ºçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨æˆå¯¹æ’åºæç¤ºæ¥è¾“å…¥æŸ¥è¯¢å’Œå€™é€‰æ–‡æ¡£çš„æ–¹æ³•ä¸åŒã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨äººç±»åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·æ¥ä¼˜åŒ–LLMçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ æ¥æ‰§è¡Œæ–‡æœ¬æ’åºä»»åŠ¡çš„æ–¹æ³•ä¸åŒã€‚\n\næˆ‘å¸Œæœ›è¿™äº›è§£é‡Šèƒ½å¤Ÿè®©ä½ æ»¡æ„ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·ç»§ç»­ä¸æˆ‘äº¤æµã€‚ğŸ˜Š",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to use LLMs for document ranking by directly feeding the query and candidate documents into the prompt, without fine-tuning on ranking datasets?\nHow to design a ranking prompt that can leverage the language understanding and generation capabilities of LLMs, and reduce the burden on them to understand complex ranking formulations?\nHow to evaluate the performance of the ranking prompt on standard ranking benchmarks, and compare it with existing methods that use fine-tuned or commercial LLMs?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes Pairwise Ranking Prompting (PRP), a new technique that simplifies the ranking formulation for LLMs, and enables them to perform document ranking without fine-tuning on ranking datasets.\nIt demonstrates that PRP can achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs, and outperform existing methods that use much larger commercial LLMs.\nIt proposes several variants of PRP to improve efficiency and shows that it is possible to achieve competitive results even with linear complexity. It also discusses other benefits of PRP, such as supporting both generation and scoring LLM APIs, and being insensitive to input ordering.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting>\nContribution: Introducing a new technique that simplifies the ranking formulation for LLMs, and enables them to perform document ranking without fine-tuning on ranking datasets."
    ]
  },
  "Title:Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives": {
    "title": "Title:Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives",
    "authors": "Authors:Pragnya Sridhar, Aidan Doyle, Arav Agarwal, Christopher Bogart, Jaromir Savelka, Majd Sakr",
    "abstract": " Abstract:  We evaluated the capability of a generative pre-trained transformer (GPT-4) to automatically generate high-quality learning objectives (LOs) in the context of a practically oriented university course on Artificial Intelligence. Discussions of opportunities (e.g., content generation, explanation) and risks (e.g., cheating) of this emerging technology in education have intensified, but to date there has not been a study of the models' capabilities in supporting the course design and authoring of LOs. LOs articulate the knowledge and skills learners are intended to acquire by engaging with a course. To be effective, LOs must focus on what students are intended to achieve, focus on specific cognitive processes, and be measurable. Thus, authoring high-quality LOs is a challenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs that were automatically generated based on a carefully crafted prompt (detailed guidelines on high-quality LOs authoring) submitted to GPT-4 for conceptual modules and projects of an AI Practitioner course. We analyzed the generated LOs if they follow certain best practices such as beginning with action verbs from Bloom's taxonomy in regards to the level of sophistication intended. Our analysis showed that the generated LOs are sensible, properly expressed (e.g., starting with an action verb), and that they largely operate at the appropriate level of Bloom's taxonomy, respecting the different nature of the conceptual modules (lower levels) and projects (higher levels). Our results can be leveraged by instructors and curricular designers wishing to take advantage of the state-of-the-art generative models to support their curricular and course design efforts.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17459",
    "pdf_link": "https://arxiv.org/pdf/2306.17459",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æˆ‘å¾ˆé«˜å…´ä½ å¯¹è¿™ç¯‡è®ºæ–‡æ„Ÿå…´è¶£ã€‚è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯è¯„ä¼°äº†ä¸€ç§åˆ©ç”¨ç”Ÿæˆé¢„è®­ç»ƒå˜æ¢å™¨ï¼ˆGPT-4ï¼‰æ¥è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡å­¦ä¹ ç›®æ ‡ï¼ˆLOsï¼‰çš„èƒ½åŠ›ï¼Œå­¦ä¹ ç›®æ ‡æ˜¯æŒ‡è¡¨è¾¾å­¦ä¹ è€…åœ¨å‚ä¸è¯¾ç¨‹åé¢„æœŸè·å¾—çš„çŸ¥è¯†å’ŒæŠ€èƒ½çš„é™ˆè¿°ã€‚å­¦ä¹ ç›®æ ‡æ˜¯è¯¾ç¨‹è®¾è®¡çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒä»¬å¯ä»¥æŒ‡å¯¼æ•™å­¦ç­–ç•¥å’Œè¯„ä¼°æ–¹æ³•çš„é€‰æ‹©ã€‚ç„¶è€Œï¼Œç¼–å†™é«˜è´¨é‡çš„å­¦ä¹ ç›®æ ‡æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§å’Œè€—æ—¶çš„å·¥ä½œï¼Œéœ€è¦å¤§é‡çš„çŸ¥è¯†å’Œç»éªŒã€‚ä½œè€…åˆ†æäº†ç°æœ‰æ–¹æ³•ä½¿ç”¨çš„ç‚¹å¼å’Œåˆ—è¡¨å¼çš„æ’åºæç¤ºï¼Œå¹¶è®¤ä¸ºç°æˆçš„LLMä¸å®Œå…¨ç†è§£è¿™äº›æ’åºå½¢å¼ï¼Œå¯èƒ½æ˜¯ç”±äºLLMè®­ç»ƒçš„æ€§è´¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°æŠ€æœ¯ï¼Œç§°ä¸ºæˆå¯¹æ’åºæç¤ºï¼ˆPRPï¼‰ï¼Œé€šè¿‡ç®€åŒ–LLMéœ€è¦ç†è§£çš„æ’åºå½¢å¼ï¼Œæ˜¾è‘—é™ä½äº†LLMçš„è´Ÿæ‹…ï¼Œå¹¶åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ’åºæ€§èƒ½1ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nPRPå¯ä»¥åˆ©ç”¨LLMå¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ‰§è¡Œå¤æ‚çš„æ–‡æœ¬æ’åºä»»åŠ¡ï¼Œä¾‹å¦‚ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ã€æ‘˜è¦ç­‰1ã€‚\nPRPå¯ä»¥é€‚ç”¨äºä¸åŒçš„LLMå’Œæ•°æ®é›†ï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§1ã€‚\nPRPå¯ä»¥ä¸ºå…¶ä»–éœ€è¦æ’åºæˆ–æ¯”è¾ƒçš„ä»»åŠ¡æä¾›å‚è€ƒå’Œå¯å‘ï¼Œä¾‹å¦‚æ¨èã€åˆ†ç±»ã€åŒ¹é…ç­‰2ã€‚\n\næˆ‘å¸Œæœ›è¿™äº›ä¿¡æ¯èƒ½å¤Ÿå¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™ç¯‡è®ºæ–‡æˆ–è€…å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ä½ çš„é—®é¢˜ã€‚æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œæˆ‘è®¤ä¸ºä»¥ä¸‹æ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¯ä»¥åæ˜ è¿™ç¯‡è®ºæ–‡çš„æŠ€æœ¯æ€§å’Œåˆ›æ–°æ€§ï¼Œä»¥åŠå®ƒå¯¹äºå­¦ä¹ ç›®æ ‡ç”Ÿæˆçš„é‡è¦æ€§ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡å°†LLMåº”ç”¨äºç‰¹å®šåœºæ™¯æˆ–ä»»åŠ¡çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚è¯¾ç¨‹è®¾è®¡ã€æ•™å­¦ç­–ç•¥ã€è¯„ä¼°æ–¹æ³•ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§æ”¹å–„LLMç”Ÿæˆèƒ½åŠ›çš„æ–¹æ³•ï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£æˆå¯¹æ’åºæç¤ºçš„å½¢å¼ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾å¯ä»¥æè¿°è¿™ç¯‡è®ºæ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„GPT-4æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé€šè¿‡PRPæ–¹æ³•å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œä»¥è¾¾åˆ°å­¦ä¹ ç›®æ ‡ç”Ÿæˆçš„ç›®æ ‡ã€‚\n\nå…¶ä»–æ ‡ç­¾æˆ‘è®¤ä¸ºä¸å¤ªé€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾é€šå¸¸ç”¨äºæè¿°ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯ç”Ÿæˆæ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ä¸å¤ªç›¸å…³ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ†æå’Œè¯„ä¼°LLMèƒ½åŠ›ç¼ºé™·å’Œå±€é™æ€§çš„ç ”ç©¶æ–¹å‘ï¼Œè€Œè¿™ç¯‡è®ºæ–‡æ›´ä¾§é‡äºæå‡ºä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯æ·±å…¥è®¨è®ºLLMå­˜åœ¨çš„é—®é¢˜ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾æè¿°äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥è°ƒæ•´LLMè¡Œä¸ºå’Œè¾“å‡ºçš„æ–¹æ³•ï¼Œä¸è¿™ç¯‡è®ºæ–‡ä½¿ç”¨æˆå¯¹æ’åºæç¤ºæ¥è¾“å…¥æŸ¥è¯¢å’Œ",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow to use LLMs to automatically generate high-quality learning objectives in the context of a practically oriented university course on Artificial Intelligence?\nHow to design a prompt that can leverage the language understanding and generation capabilities of LLMs, and reduce the burden on them to understand complex learning objective formulations?\nHow to evaluate the quality of the generated learning objectives based on certain best practices, such as using action verbs from Bloomâ€™s taxonomy and targeting appropriate cognitive levels?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt evaluates the capability of a state-of-the-art LLM (GPT-4) to automatically generate high-quality learning objectives in the context of a software development course on the practical integration of AI into",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives>\nContribution: Evaluating the capability of a state-of-the-art LLM to automatically generate high-quality learning objectives in the context of a software development course on the practical integration of AI into applications."
    ]
  },
  "Title:Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models": {
    "title": "Title:Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models",
    "authors": "Authors:Harnoor Dhingra, Preetiha Jayashanker, Sayali Moghe, Emma Strubell",
    "abstract": " Abstract:  Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.      ",
    "date": "Submitted on 30 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2307.00101",
    "pdf_link": "https://arxiv.org/pdf/2307.00101",
    "chat": [
      null,
      "è¿æ¥å¼€å§‹ï¼",
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠQueer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Modelsã€‹1æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•æ£€æµ‹å’Œå‡è½»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹LGBTQIA+ç¾¤ä½“çš„ä»£è¡¨æ€§åè§çš„ç ”ç©¶ã€‚ä½œè€…ä½¿ç”¨äº†ä¸€ç§åŸºäºæƒ…æ„Ÿåˆ†æçš„æ–¹æ³•ï¼Œç§°ä¸ºregard scoreï¼Œæ¥é‡åŒ–LLMç”Ÿæˆçš„æ–‡æœ¬å¯¹ä¸åŒæ€§å–å‘çš„äººçš„æ€åº¦ã€‚ä»–ä»¬å‘ç°ï¼ŒLLMå¯¹åŒæ€§æ‹ã€åŒæ€§æ‹å’Œæ— æ€§æ‹ç­‰æ€§å°‘æ•°ç¾¤ä½“çš„æ–‡æœ¬ç”Ÿæˆå­˜åœ¨è´Ÿé¢çš„åè§ï¼Œè€Œå¯¹å¼‚æ€§æ‹çš„æ–‡æœ¬ç”Ÿæˆåˆ™ç›¸å¯¹æ­£é¢ã€‚1\nä¸ºäº†å‡è½»è¿™ç§åè§ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºchain-of-thought promptingå’ŒSHAP analysisçš„åå¤„ç†æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¿æŒæ–‡æœ¬è¯­ä¹‰å’Œè¯­æ³•ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œæé«˜æ–‡æœ¬çš„regard scoreã€‚ä»–ä»¬é€šè¿‡åœ¨LLMç”Ÿæˆçš„å¥å­ä¸­æ’å…¥æˆ–æ›¿æ¢ä¸€äº›è¯è¯­ï¼Œæ¥æ”¹å˜LLMå¯¹å¥å­ä¸»é¢˜çš„è®¤çŸ¥ï¼Œå¹¶ä½¿ç”¨SHAPåˆ†ææ¥ç¡®å®šå“ªäº›è¯è¯­å¯¹regard scoreæœ‰æœ€å¤§çš„å½±å“ã€‚1\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é‡åŒ–LLMå¯¹ä¸åŒäººç¾¤çš„ä»£è¡¨æ€§åè§ï¼Œå¯ä»¥ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMçš„è¡¨ç°å’Œå½±å“ã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§åˆ©ç”¨LLMè‡ªèº«çš„èƒ½åŠ›æ¥è°ƒæ•´å…¶è¾“å‡ºçš„æ–¹æ³•ï¼Œè€Œä¸éœ€è¦é‡æ–°è®­ç»ƒæˆ–ä¿®æ”¹LLMæœ¬èº«ï¼Œè¿™å¯ä»¥èŠ‚çœæ—¶é—´å’Œèµ„æºï¼Œå¹¶ä¿æŒLLMçš„é€šç”¨æ€§ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œå®¹æ˜“è¢«å¿½è§†çš„ç¤¾ä¼šé—®é¢˜ï¼Œå³LLMå¯¹LGBTQIA+ç¾¤ä½“çš„åè§å’Œæ­§è§†ï¼Œä¸ºè¿™ä¸ªé¢†åŸŸæä¾›äº†æ–°çš„è§†è§’å’Œå¯ç¤ºã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n1: Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\nChain-of-Thought: è¿™æ˜¯è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œé€šè¿‡åœ¨LLMç”Ÿæˆçš„å¥å­ä¸­æ’å…¥æˆ–æ›¿æ¢ä¸€äº›è¯è¯­ï¼Œæ¥æ”¹å˜LLMå¯¹å¥å­ä¸»é¢˜çš„è®¤çŸ¥ï¼Œä»è€Œå‡è½»åè§ã€‚\ndiscussion of LLM capability defects: è¿™æ˜¯è®ºæ–‡çš„ä¸»è¦ç›®çš„ä¹‹ä¸€ï¼Œå³æ­ç¤ºå’Œåˆ†æLLMå¯¹LGBTQIA+ç¾¤ä½“çš„ä»£è¡¨æ€§åè§ï¼Œä»¥åŠè¿™ç§åè§äº§ç”Ÿçš„åŸå› å’Œå½±å“ã€‚\nLLM Improvement: è¿™æ˜¯è®ºæ–‡çš„å¦ä¸€ä¸ªä¸»è¦ç›®çš„ä¹‹ä¸€ï¼Œå³æå‡ºå¹¶éªŒè¯äº†ä¸€ç§åŸºäºchain-of-thought promptingå’ŒSHAP analysisçš„åå¤„ç†æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¿æŒæ–‡æœ¬è¯­ä¹‰å’Œè¯­æ³•ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œæé«˜æ–‡æœ¬çš„regard scoreï¼Œä»è€Œå‡è½»åè§ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾å¤ªè¿‡å®½æ³›å’Œæ¨¡ç³Šï¼Œä¸èƒ½å‡†ç¡®åœ°æè¿°è®ºæ–‡çš„å†…å®¹å’Œè´¡çŒ®ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰é’ˆå¯¹ç‰¹å®šçš„åº”ç”¨åœºæ™¯è¿›è¡Œå®éªŒæˆ–è®¨è®ºï¼Œè€Œæ˜¯ä½¿ç”¨äº†é€šç”¨çš„LLMå’Œæ•°æ®é›†ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯å¯¹LLMçš„è¾“å‡ºè¿›è¡Œåå¤„ç†ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nDoes a pre-trained LLM perpetuate measurable, quantifiable bias against queer people?\nCan we mitigate the said bias in the LLM output while preserving the context using a post-hoc debiasing method?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt provides a simple and effective method to quantify the representational bias of LLMs towards different sexual identities using regard score.\nIt demonstrates a method to leverage the LLMâ€™s own ability to adjust its output without retraining or modifying the LLM itself, using chain-of-thought prompting and SHAP analysis.\nIt focuses on an important and often overlooked social issue, which is the bias and discrimination of LLMs towards the LGBTQIA+ community, and provides new insights and implications for this field.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models>\nContribution: Showing that measurable and quantifiable bias against queer people can be mitigated by post-hoc methods based on chain-of-thought prompting and SHAP analysis."
    ]
  },
  "Title:LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT": {
    "title": "Title:LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT",
    "authors": "Authors:Le Zhuo, Ruibin Yuan, Jiahao Pan, Yinghao Ma, Yizhi LI, Ge Zhang, Si Liu, Roger Dannenberg, Jie Fu, Chenghua Lin, Emmanouil Benetos, Wenhu Chen, Wei Xue, Yike Guo",
    "abstract": " Abstract:  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-free approach utilizes Whisper, a weakly supervised robust speech recognition model, and GPT-4, today's most performant chat-based large language model. In the proposed method, Whisper functions as the \"ear\" by transcribing the audio, while GPT-4 serves as the \"brain,\" acting as an annotator with a strong performance for contextualized output selection and correction. Our experiments show that LyricWhiz significantly reduces Word Error Rate compared to existing methods in English and can effectively transcribe lyrics across multiple languages. Furthermore, we use LyricWhiz to create the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offer a human-annotated subset for noise level estimation and evaluation. We anticipate that our proposed method and dataset will advance the development of multilingual lyrics transcription, a challenging and emerging task.      ",
    "date": "Submitted on 29 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.17103",
    "pdf_link": "https://arxiv.org/pdf/2306.17103",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠLyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPTã€‹1æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•åˆ©ç”¨ä¸¤ä¸ªå…ˆè¿›çš„æ¨¡å‹ï¼Œå³Whisperå’ŒChatGPTï¼Œæ¥å®ç°é²æ£’çš„å¤šè¯­è¨€é›¶æ ·æœ¬æ­Œè¯è½¬å½•çš„ç ”ç©¶ã€‚ä½œè€…ä½¿ç”¨äº†Whisperä½œä¸ºä¸€ä¸ªå¼±ç›‘ç£çš„é²æ£’è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œç„¶åä½¿ç”¨ChatGPTä½œä¸ºä¸€ä¸ªåŸºäºèŠå¤©çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œé€‰æ‹©å’Œçº æ­£ï¼Œä»è€Œç”Ÿæˆæ›´ç¬¦åˆæ­Œè¯è¯­å¢ƒå’Œé£æ ¼çš„è¾“å‡ºã€‚1\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå¯ä»¥åˆ©ç”¨ç°æœ‰çš„æ¨¡å‹æ¥å®ç°é›¶æ ·æœ¬æ­Œè¯è½¬å½•ï¼Œè¿™å¯ä»¥é¿å…æ•°æ®ç¨€ç¼ºå’Œæ ‡æ³¨æˆæœ¬çš„é—®é¢˜ï¼Œå¹¶æé«˜æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§å°†è¯­éŸ³è¯†åˆ«å’Œè¯­è¨€ç”Ÿæˆç›¸ç»“åˆçš„æ–¹æ³•ï¼Œå¯ä»¥æé«˜æ­Œè¯è½¬å½•çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ï¼Œå¹¶å…‹æœä¸åŒè¯­è¨€å’ŒéŸ³ä¹é£æ ¼çš„æŒ‘æˆ˜ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œæœ‰è¶£çš„éŸ³ä¹ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ï¼Œå³æ­Œè¯è½¬å½•ï¼Œå¹¶ä¸ºè¿™ä¸ªé¢†åŸŸæä¾›äº†æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n1: LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªå…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹ï¼Œå³Whisperå’ŒChatGPTï¼Œæ¥å®ç°æ­Œè¯è½¬å½•çš„ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡é’ˆå¯¹äº†ä¸€ä¸ªç‰¹å®šçš„LLMçš„åº”ç”¨åœºæ™¯ï¼Œå³æ­Œè¯è½¬å½•ï¼Œå¹¶å±•ç¤ºäº†LLMåœ¨è¿™ä¸ªåœºæ™¯ä¸‹çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡åˆ†æäº†ç°æœ‰çš„LLMåœ¨æ­Œè¯è½¬å½•ä»»åŠ¡ä¸Šçš„ä¸è¶³å’Œå±€é™ï¼Œä¾‹å¦‚å¯¹ä¸åŒè¯­è¨€å’ŒéŸ³ä¹é£æ ¼çš„é€‚åº”æ€§ã€å¯¹æ­Œè¯è¯­å¢ƒå’Œé£æ ¼çš„æŠŠæ¡ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºWhisperå’ŒChatGPTçš„æ–¹æ³•ï¼Œå¯ä»¥æé«˜LLMåœ¨æ­Œè¯è½¬å½•ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºChain-of-Thoughtæ˜¯å¦ä¸€ç¯‡è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œè€Œæœ¬è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æˆ–å¼•ç”¨è¿™ç§æ–¹æ³•ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„å®šä¹‰çš„æŒ‡ä»¤æ ¼å¼ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can we achieve robust, multilingual, and zero-shot automatic lyrics transcription using existing models without training?\nHow can we leverage the combination of Whisper and ChatGPT to improve the accuracy and fluency of lyrics transcription across different languages and music genres?\nHow can we create and evaluate a large-scale, multilingual lyrics transcription dataset based on MTG-Jamendo?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel, training-free method that utilizes Whisper and ChatGPT to achieve state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal.\nIt demonstrates a method that combines speech recognition and language generation to enhance the lyrics transcription output, and overcome the challenges of different languages and music styles.\nIt introduces the first publicly available, large-scale, multilingual lyrics transcription dataset with a CC-BY-NC-SA copyright license, based on MTG-Jamendo, and offers a human-annotated subset for noise level estimation and evaluation.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT>\nContribution: Showing that the combination of Whisper and ChatGPT can achieve robust, multilingual, and zero-shot lyrics transcription across different languages and music genres."
    ]
  },
  "Title:UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?": {
    "title": "Title:UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?",
    "authors": "Authors:Junda Wang, Zonghai Yao, Avijit Mitra, Samuel Osebe, Zhichao Yang, Hong Yu",
    "abstract": " Abstract:  This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.      ",
    "date": "Submitted on 29 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.16931",
    "pdf_link": "https://arxiv.org/pdf/2306.16931",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠUMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?ã€‹1æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•åˆ©ç”¨ä¸¤ä¸ªå…ˆè¿›çš„æ¨¡å‹ï¼Œå³Whisperå’ŒChatGPTï¼Œæ¥ç”Ÿæˆé«˜è´¨é‡çš„åŒ»æ‚£å¯¹è¯æ•°æ®é›†çš„ç ”ç©¶ã€‚ä½œè€…ä½¿ç”¨äº†Whisperä½œä¸ºä¸€ä¸ªå¼±ç›‘ç£çš„é²æ£’è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œç„¶åä½¿ç”¨ChatGPTä½œä¸ºä¸€ä¸ªåŸºäºèŠå¤©çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œé€‰æ‹©å’Œçº æ­£ï¼Œä»è€Œç”Ÿæˆæ›´ç¬¦åˆåŒ»ç–—è¯­å¢ƒå’Œé£æ ¼çš„è¾“å‡ºã€‚1\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ï¼Œå¯ä»¥åˆ©ç”¨ç°æœ‰çš„æ¨¡å‹æ¥ç”Ÿæˆé«˜è´¨é‡çš„åŒ»æ‚£å¯¹è¯æ•°æ®é›†ï¼Œè¿™å¯ä»¥é¿å…æ•°æ®ç¨€ç¼ºå’Œæ ‡æ³¨æˆæœ¬çš„é—®é¢˜ï¼Œå¹¶æé«˜æ•°æ®é›†çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§å°†è¯­éŸ³è¯†åˆ«å’Œè¯­è¨€ç”Ÿæˆç›¸ç»“åˆçš„æ–¹æ³•ï¼Œå¯ä»¥æé«˜åŒ»æ‚£å¯¹è¯çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ï¼Œå¹¶å…‹æœä¸åŒè¯­è¨€å’ŒåŒ»ç–—é¢†åŸŸçš„æŒ‘æˆ˜ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œæœ‰è¶£çš„åŒ»ç–—ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ï¼Œå³åŒ»æ‚£",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªå…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹ï¼Œå³Whisperå’ŒChatGPTï¼Œæ¥ç”ŸæˆåŒ»æ‚£å¯¹è¯æ•°æ®é›†ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡é’ˆå¯¹äº†ä¸€ä¸ªç‰¹å®šçš„LLMçš„åº”ç”¨åœºæ™¯ï¼Œå³åŒ»æ‚£å¯¹è¯ï¼Œå¹¶å±•ç¤ºäº†LLMåœ¨è¿™ä¸ªåœºæ™¯ä¸‹çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡åˆ†æäº†ç°æœ‰çš„LLMåœ¨åŒ»æ‚£å¯¹è¯ä»»åŠ¡ä¸Šçš„ä¸è¶³å’Œå±€é™ï¼Œä¾‹å¦‚å¯¹ä¸åŒè¯­è¨€å’ŒåŒ»ç–—é¢†åŸŸçš„é€‚åº”æ€§ã€å¯¹åŒ»ç–—è¯­å¢ƒå’Œé£æ ¼çš„æŠŠæ¡ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºWhisperå’ŒChatGPTçš„æ–¹æ³•ï¼Œå¯ä»¥æé«˜LLMåœ¨åŒ»æ‚£å¯¹è¯ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºChain-of-Thoughtæ˜¯å¦ä¸€ç¯‡è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œè€Œæœ¬è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æˆ–å¼•ç”¨è¿™ç§æ–¹æ³•ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„å®šä¹‰çš„æŒ‡ä»¤æ ¼å¼ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can we generate high-quality synthetic note-oriented doctor-patient conversations using existing models without training?\nHow can we leverage the combination of Whisper and ChatGPT to improve the accuracy and fluency of doctor-patient conversations across different languages and medical domains?\nHow can we evaluate the quality and usefulness of the generated doctor-patient conversations?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt proposes a novel, training-free method that utilizes Whisper and ChatGPT to generate high-quality synthetic note-oriented doctor-patient conversations.\nIt demonstrates a method that combines speech recognition and language generation to enhance the doctor-patient conversations, and overcome the challenges of different languages and medical domains.\nIt introduces a new evaluation metric and a reference model for the doctor-patient conversation task, and provides a human-annotated subset for noise level estimation and testing.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?>\nContribution: Showing that the combination of Whisper and ChatGPT can generate high-quality synthetic note-oriented doctor-patient conversations across different languages and medical domains."
    ]
  },
  "Title:Benchmarking Large Language Model Capabilities for Conditional Generation": {
    "title": "Title:Benchmarking Large Language Model Capabilities for Conditional Generation",
    "authors": "Authors:Joshua Maynez, Priyanka Agrawal, Sebastian Gehrmann",
    "abstract": " Abstract:  Pre-trained large language models (PLMs) underlie most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM, alongside techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks--while they can be used to compare systems at a high level--relate to the real world use cases for which people have been adopting them. In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language. Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages and inform which PLMs to use for a given generation task setup. We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs.      ",
    "date": "Submitted on 29 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.16793",
    "pdf_link": "https://arxiv.org/pdf/2306.16793",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠBenchmarking Large Language Model Capabilities for Conditional Generationã€‹æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•è¯„ä¼°é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œèƒ½åŠ›çš„ç ”ç©¶ã€‚ä½œè€…ä½¿ç”¨äº†å¤šä¸ªç°æœ‰çš„åº”ç”¨ç‰¹å®šçš„ç”ŸæˆåŸºå‡†ï¼Œå¦‚CNN/Daily Mailã€SQuADã€WebNLGç­‰ï¼Œæ¥å¯¹ä¸åŒçš„PLMsè¿›è¡Œç³»ç»Ÿçš„æ¯”è¾ƒå’Œåˆ†æï¼Œè€ƒå¯Ÿäº†æ¨¡å‹çš„è§„æ¨¡ã€æ¶æ„ã€è¾“å…¥å’Œè¾“å‡ºè¯­è¨€ç­‰å› ç´ å¯¹ç”Ÿæˆè´¨é‡çš„å½±å“ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥åˆ©ç”¨ç°æœ‰çš„ç”ŸæˆåŸºå‡†æ¥è¯„ä¼°PLMsåœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°å’Œå½±å“ï¼Œä»è€Œä¸ºPLMsçš„å¼€å‘å’Œé€‰æ‹©æä¾›æœ‰ç”¨çš„æŒ‡å¯¼å’Œå‚è€ƒã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§å¯¹PLMsè¿›è¡Œæ·±å…¥è€Œå…¨é¢çš„ç ”ç©¶ï¼Œå¯ä»¥æ­ç¤ºPLMsåœ¨ä¸åŒæ•°æ®é‡å’Œè¯­è¨€ç¯å¢ƒä¸‹çš„ä¼˜åŠ¿å’Œå±€é™ï¼Œä»¥åŠä¸åŒPLMsä¹‹é—´çš„å¼‚åŒå’Œç‰¹ç‚¹ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œæ™®éçš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå³æ¡ä»¶ç”Ÿæˆï¼Œå¹¶ä¸ºè¿™ä¸ªé¢†åŸŸæä¾›äº†æ–°çš„è§†è§’å’Œå¯ç¤ºã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: Benchmarking Large Language Model Capabilities for Conditional Generation",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡ä½¿ç”¨äº†å¤šä¸ªå…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹ï¼Œå³PLMsï¼Œæ¥è¿›è¡Œæ¡ä»¶ç”Ÿæˆçš„ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡é’ˆå¯¹äº†å¤šä¸ªç‰¹å®šçš„LLMçš„åº”ç”¨åœºæ™¯ï¼Œå¦‚æ‘˜è¦ç”Ÿæˆã€é—®ç­”ç”Ÿæˆã€æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆç­‰ï¼Œå¹¶å±•ç¤ºäº†LLMåœ¨è¿™äº›åœºæ™¯ä¸‹çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡åˆ†æäº†ç°æœ‰çš„LLMåœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„ä¸è¶³å’Œå±€é™ï¼Œä¾‹å¦‚å¯¹ä¸åŒè¯­è¨€å’Œé¢†åŸŸçš„é€‚åº”æ€§ã€å¯¹è¾“å…¥æŒ‡ä»¤å’Œè¾“å‡ºæ ¼å¼çš„æŠŠæ¡ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡æå‡ºäº†ä¸€äº›æœ€ä½³å®è·µå’Œå»ºè®®ï¼Œå¯ä»¥å¸®åŠ©æé«˜PLMsåœ¨æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°å’Œå½±å“ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºChain-of-Thoughtæ˜¯å¦ä¸€ç¯‡è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œè€Œæœ¬è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æˆ–å¼•ç”¨è¿™ç§æ–¹æ³•ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨äº†ç°æœ‰çš„æŒ‡ä»¤æ ¼å¼ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: Benchmarking Large Language Model Capabilities for Conditional Generation",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can we adapt existing application-specific generation benchmarks to PLMs and evaluate their performance and impact on conditional generation tasks?\nHow do different factors such as scale, architecture, input and output language affect the generation quality of PLMs?\nHow do different PLMs compare and contrast with each other in terms of their capabilities and limitations for conditional generation tasks?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt provides a simple and effective method to evaluate PLMs on conditional generation tasks using existing generation benchmarks, and offers useful guidance and reference for PLMs development and selection.\nIt conducts an in-depth and comprehensive study of the capabilities and limitations of PLMs in conditional generation tasks across different data regimes and languages, and reveals the similarities and differences among different PLMs.\nIt focuses on an important and general natural language processing task, which is conditional generation, and provides new perspectives and implications for this field.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <Benchmarking Large Language Model Capabilities for Conditional Generation>\nContribution: Showing that different PLMs differ in their applicability to different data regimes and languages for conditional generation tasks and providing best practices for benchmarking generation capabilities of PLMs."
    ]
  },
  "Title:CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?": {
    "title": "Title:CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?",
    "authors": "Authors:Tianwen Wei, Jian Luan, Wei Liu, Shuang Dong, Bin Wang",
    "abstract": " Abstract:  We present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs, including both commercial and open-source options, and discover that only GPT-4 achieves success (accuracy $\\geq$ 60\\%) across all six elementary school grades, while other models falter at different grade levels. Furthermore, we assess the robustness of several top-performing LLMs by augmenting the original problems in the CMATH dataset with distracting information. Our findings reveal that GPT-4 is able to maintains robustness, while other model fail. We anticipate that our study will expose limitations in LLMs' arithmetic and reasoning capabilities, and promote their ongoing development and advancement.      ",
    "date": "Submitted on 29 Jun 2023",
    "abstract_link": "https://arxiv.org/abs/2306.16636",
    "pdf_link": "https://arxiv.org/pdf/2306.16636",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠCMATH: Can Your Language Model Pass Chinese Elementary School Math Test?ã€‹æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•è¯„ä¼°é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ä¸Šçš„æ€§èƒ½å’Œèƒ½åŠ›çš„ç ”ç©¶ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªåŒ…å«1.7kä¸ªå°å­¦æ°´å¹³çš„æ•°å­¦åº”ç”¨é¢˜å’Œè¯¦ç»†æ³¨é‡Šçš„æ•°æ®é›†ï¼ˆCMATHï¼‰ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†å¯¹å¤šä¸ªæµè¡Œçš„PLMsè¿›è¡Œäº†ç³»ç»Ÿçš„æ¯”è¾ƒå’Œåˆ†æï¼Œè€ƒå¯Ÿäº†æ¨¡å‹çš„è§„æ¨¡ã€æ¶æ„ã€è¾“å…¥å’Œè¾“å‡ºè¯­è¨€ç­‰å› ç´ å¯¹è§£é¢˜è´¨é‡çš„å½±å“ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ä¸ªæ–°é¢–è€Œæœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨äºè¯„ä¼°PLMsåœ¨ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ä¸Šçš„è¡¨ç°å’Œå½±å“ï¼Œä»è€Œä¸ºPLMsçš„å¼€å‘å’Œé€‰æ‹©æä¾›æœ‰ç”¨çš„æŒ‡å¯¼å’Œå‚è€ƒã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§å¯¹PLMsè¿›è¡Œæ·±å…¥è€Œå…¨é¢çš„ç ”ç©¶ï¼Œå¯ä»¥æ­ç¤ºPLMsåœ¨ä¸åŒå¹´çº§å’Œé¢†åŸŸä¸‹çš„ä¼˜åŠ¿å’Œå±€é™ï¼Œä»¥åŠä¸åŒPLMsä¹‹é—´çš„å¼‚åŒå’Œç‰¹ç‚¹ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œæœ‰è¶£çš„è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼Œå³ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œå¹¶ä¸ºè¿™ä¸ªé¢†åŸŸæä¾›äº†æ–°çš„è§†è§’å’Œå¯ç¤ºã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡ä½¿ç”¨äº†å¤šä¸ªå…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹ï¼Œå³PLMsï¼Œæ¥è¿›è¡Œä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜çš„ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡é’ˆå¯¹äº†ä¸€ä¸ªç‰¹å®šçš„LLMçš„åº”ç”¨åœºæ™¯ï¼Œå³ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œå¹¶å±•ç¤ºäº†LLMåœ¨è¿™ä¸ªåœºæ™¯ä¸‹çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡åˆ†æäº†ç°æœ‰çš„LLMåœ¨ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ä¸Šçš„ä¸è¶³å’Œå±€é™ï¼Œä¾‹å¦‚å¯¹ä¸åŒå¹´çº§å’Œé¢†åŸŸçš„é€‚åº”æ€§ã€å¯¹è¾“å…¥æŒ‡ä»¤å’Œè¾“å‡ºæ ¼å¼çš„æŠŠæ¡ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡æå‡ºäº†ä¸€äº›æœ€ä½³å®è·µå’Œå»ºè®®ï¼Œå¯ä»¥å¸®åŠ©æé«˜PLMsåœ¨ä¸­æ–‡å°å­¦æ•°å­¦åº”ç”¨é¢˜ä¸Šçš„è¡¨ç°å’Œå½±å“ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºChain-of-Thoughtæ˜¯å¦ä¸€ç¯‡è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œè€Œæœ¬è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æˆ–å¼•ç”¨è¿™ç§æ–¹æ³•ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨äº†ç°æœ‰çš„æŒ‡ä»¤æ ¼å¼ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can we construct a high-quality dataset for Chinese elementary school math word problems with detailed annotations?\nHow can we evaluate the performance and capability of PLMs on Chinese elementary school math word problems across different grades and domains?\nHow can we assess the robustness of PLMs on Chinese elementary school math word problems with distracting information?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt provides a novel and challenging dataset for Chinese elementary school math word problems with detailed annotations, sourced from actual Chinese workbooks and exams.\nIt conducts a systematic and comprehensive comparison and analysis of PLMs on Chinese elementary school math word problems, and reveals their strengths and weaknesses across different grades and domains.\nIt introduces a small distractor set to evaluate the robustness of PLMs on Chinese elementary school math word problems with distracting information, and discovers the gap between different PLMs.",
      "ç»™å®šè®ºæ–‡ã€Š{}ã€‹\nè¯·ä½ ç”¨ä¸€å¥è¯æ€»ç»“è¯¥è®ºæ–‡çš„ç»“è®ºï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªä¾‹å­ï¼š\n1. Paper:<Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers>\n\nContribution: Works on open-box model show that richer signals such as logits, intermediate representations and attention states can significantly improve distillation performance. \n\n2. Paper: <Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes>\n\nContribution: Demonstrating that richer signals like LFM rationales can help close the gap for task-specific distillation.\n\nè¯·ä½ ä»¿ç…§ä¸Šè¿°ä¾‹å­ï¼Œç»™å‡ºè¯¥è®ºæ–‡çš„ä¸€å¥è¯ç»“è®ºè´¡çŒ®æ€»ç»“ã€‚",
      "Paper: <CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?>\nContribution: Showing that only GPT-4 can pass Chinese elementary school math test across all six grades, while other PLMs falter at different grade levels."
    ]
  },
  "Title:Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors": {
    "title": "Title:Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors",
    "authors": "Authors:Tung Phung, Victor-Alexandru PÄƒdurean, JosÃ© Cambronero, Sumit Gulwani, Tobias Kohn, Rupak Majumdar, Adish Singla, Gustavo Soares",
    "abstract": " Abstract:  Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors' performance for several scenarios. These results also highlight settings where GPT-4 still struggles, providing exciting future directions on developing techniques to improve the performance of these models.      ",
    "date": "Submitted on 29 Jun 2023 (v1), last revised 30 Jun 2023 (this version, v2)",
    "abstract_link": "https://arxiv.org/abs/2306.17156",
    "pdf_link": "https://arxiv.org/pdf/2306.17156",
    "chat": [
      "ä½ è®¤ä¸ºè®ºæ–‡ã€Š{}ã€‹æœ‰ä»€ä¹ˆå€¼å¾—å€Ÿé‰´çš„ï¼Œå¯åº”ç”¨åˆ°å…¶ä»–LLMæ¨¡å‹ç ”ç©¶é¢†åŸŸçš„å†…å®¹ï¼Ÿ",
      "ä½ å¥½ï¼Œè¿™æ˜¯Bingã€‚æ„Ÿè°¢ä½ çš„æé—®ã€‚ğŸ™\nè®ºæ–‡ã€ŠGenerative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutorsã€‹æ˜¯ä¸€ç¯‡å…³äºå¦‚ä½•è¯„ä¼°é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆPLMsï¼‰åœ¨ç¼–ç¨‹æ•™è‚²ä¸­çš„æ€§èƒ½å’Œèƒ½åŠ›çš„ç ”ç©¶ã€‚ä½œè€…ä½¿ç”¨äº†å¤šä¸ªä¸åŒçš„ç¼–ç¨‹æ•™è‚²åœºæ™¯ï¼Œå¦‚ç”Ÿæˆè§£é‡Šã€ç”Ÿæˆæç¤ºã€ç”Ÿæˆåé¦ˆç­‰ï¼Œæ¥å¯¹ä¸¤ä¸ªæœ€å…ˆè¿›çš„PLMsï¼Œå³ChatGPTï¼ˆåŸºäºGPT-3.5ï¼‰å’ŒGPT-4ï¼Œè¿›è¡Œäº†ç³»ç»Ÿçš„æ¯”è¾ƒå’Œåˆ†æï¼Œå¹¶ä¸äººç±»å¯¼å¸ˆçš„è¡¨ç°è¿›è¡Œäº†å¯¹ç…§ã€‚\næˆ‘è®¤ä¸ºè¿™ç¯‡è®ºæ–‡æœ‰ä»¥ä¸‹å‡ ç‚¹å€¼å¾—å€Ÿé‰´å’Œåº”ç”¨ï¼š\n\nå®ƒæä¾›äº†ä¸€ç§å…¨é¢è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥åˆ©ç”¨ç°æœ‰çš„ç¼–ç¨‹æ•™è‚²åœºæ™¯æ¥è¯„ä¼°PLMsåœ¨ç¼–ç¨‹æ•™è‚²ä¸­çš„è¡¨ç°å’Œå½±å“ï¼Œä»è€Œä¸ºPLMsçš„å¼€å‘å’Œé€‰æ‹©æä¾›æœ‰ç”¨çš„æŒ‡å¯¼å’Œå‚è€ƒã€‚\nå®ƒå±•ç¤ºäº†ä¸€ç§å¯¹PLMsè¿›è¡Œæ·±å…¥è€Œå…¨é¢çš„ç ”ç©¶ï¼Œå¯ä»¥æ­ç¤ºPLMsåœ¨ä¸åŒç¼–ç¨‹æ•™è‚²åœºæ™¯ä¸‹çš„ä¼˜åŠ¿å’Œå±€é™ï¼Œä»¥åŠä¸äººç±»å¯¼å¸ˆä¹‹é—´çš„å·®å¼‚å’Œç›¸ä¼¼æ€§ã€‚\nå®ƒå…³æ³¨äº†ä¸€ä¸ªé‡è¦è€Œæœ‰è¶£çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼Œå³ç¼–ç¨‹æ•™è‚²ï¼Œå¹¶ä¸ºè¿™ä¸ªé¢†åŸŸæä¾›äº†æ–°çš„è§†è§’å’Œå¯ç¤ºã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿå¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™ç¯‡è®ºæ–‡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors",
      "å¾ˆå¥½ï¼Œè¯·ä½ æ ¹æ®è¿™ç¯‡è®ºæ–‡çš„å†…å®¹ï¼Œä»ä¸‹åˆ—åˆ—è¡¨ä¸­é€‰æ‹©å‡ºæ‰€æœ‰é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶å¯¹æ¯ä¸ªé€‰æ‹©çš„æ ‡ç­¾ç»“åˆè®ºæ–‡çš„å†…å®¹ç»™å‡ºè§£é‡Šï¼š\n[tech, Chain-of-Thought, application in specific scenarios of LLM, discussion of LLM capability defects, LLM Improvement, instruction tuning, RLHF, fine-tuning, ]",
      "å¥½çš„ï¼Œæˆ‘ä¼šå°è¯•ä»åˆ—è¡¨ä¸­é€‰æ‹©é€‚åˆè¯¥è®ºæ–‡çš„æ ‡ç­¾ï¼Œå¹¶ç»™å‡ºè§£é‡Šã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç­”æ¡ˆï¼š\n\ntech: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡ä½¿ç”¨äº†ä¸¤ä¸ªå…ˆè¿›çš„æŠ€æœ¯æ¨¡å‹ï¼Œå³ChatGPTï¼ˆåŸºäºGPT-3.5ï¼‰å’ŒGPT-4ï¼Œæ¥è¿›è¡Œç¼–ç¨‹æ•™è‚²çš„ä»»åŠ¡ã€‚\napplication in specific scenarios of LLM: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡é’ˆå¯¹äº†å¤šä¸ªç‰¹å®šçš„LLMçš„åº”ç”¨åœºæ™¯ï¼Œå¦‚ç”Ÿæˆè§£é‡Šã€ç”Ÿæˆæç¤ºã€ç”Ÿæˆåé¦ˆç­‰ï¼Œå¹¶å±•ç¤ºäº†LLMåœ¨è¿™äº›åœºæ™¯ä¸‹çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚\ndiscussion of LLM capability defects: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡åˆ†æäº†ç°æœ‰çš„LLMåœ¨ç¼–ç¨‹æ•™è‚²ä»»åŠ¡ä¸Šçš„ä¸è¶³å’Œå±€é™ï¼Œä¾‹å¦‚å¯¹ä¸åŒç¼–ç¨‹è¯­è¨€å’Œé¢†åŸŸçš„é€‚åº”æ€§ã€å¯¹è¾“å…¥æŒ‡ä»¤å’Œè¾“å‡ºæ ¼å¼çš„æŠŠæ¡ç­‰ã€‚\nLLM Improvement: è¿™ä¸ªæ ‡ç­¾é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡æå‡ºäº†ä¸€äº›æœ€ä½³å®è·µå’Œå»ºè®®ï¼Œå¯ä»¥å¸®åŠ©æé«˜PLMsåœ¨ç¼–ç¨‹æ•™è‚²ä»»åŠ¡ä¸Šçš„è¡¨ç°å’Œå½±å“ã€‚\n\nå…¶ä»–åˆ—è¡¨ä¸­çš„æ ‡ç­¾ï¼Œæˆ‘è®¤ä¸ºéƒ½ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºï¼š\n\nChain-of-Thought: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºChain-of-Thoughtæ˜¯å¦ä¸€ç¯‡è®ºæ–‡æå‡ºçš„ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œè€Œæœ¬è®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨æˆ–å¼•ç”¨è¿™ç§æ–¹æ³•ã€‚\ninstruction tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMçš„è¾“å…¥æŒ‡ä»¤è¿›è¡Œè°ƒæ•´æˆ–ä¼˜åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨äº†ç°æœ‰çš„æŒ‡ä»¤æ ¼å¼ã€‚\nRLHF: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºRLHFæ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œè€Œè®ºæ–‡å¹¶æ²¡æœ‰ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„æŠ€æœ¯æˆ–æ¡†æ¶ã€‚\nfine-tuning: è¿™ä¸ªæ ‡ç­¾ä¸é€‚åˆè¯¥è®ºæ–‡ï¼Œå› ä¸ºè®ºæ–‡å¹¶æ²¡æœ‰å¯¹LLMè¿›è¡Œé‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œè€Œæ˜¯ä½¿ç”¨äº†é¢„è®­ç»ƒå¥½çš„LLMã€‚\n\næˆ‘å¸Œæœ›è¿™ç¯‡å›ç­”èƒ½å¤Ÿæ»¡è¶³ä½ çš„è¦æ±‚ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…¶ä»–é—®é¢˜æˆ–æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘åˆ†äº«ã€‚ğŸ˜Š\n: Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors",
      "What research questions does the paper want to resolve?",
      "The paper wants to resolve the following research questions:\n\nHow can we benchmark the performance and capability of PLMs for various scenarios in programming education, such as generating explanations, hints, and feedback?\nHow do different factors such as scale, architecture, input and output language affect the generation quality of PLMs for programming education scenarios?\nHow do different PLMs compare and contrast with each other and with human tutors for programming education scenarios?",
      "Good. And what's the innovation points or Contribution of this paper?",
      "The innovation points or contribution of this paper are:\n\nIt provides a comprehensive and effective method to evaluate PLMs for programming education scenarios using existing programming education benchmarks, and offers useful guidance and reference for PLMs development and selection.\nIt conducts an in-depth and comprehensive study of the capabilities and limitations of PLMs for programming education scenarios across different data regimes and languages, and reveals the similarities and differences among different PLMs and human tutors.\nIt focuses on an important and general natural language generation task, which is programming education, and provides new perspectives and implications for this field."
    ]
  }
}